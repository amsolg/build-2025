WEBVTT

00:00:00.283 --> 00:00:21.905
[ Music ]

00:00:21.930 --> 00:00:24.570
Voiceover: Please welcome
Principal Group Manager,

00:00:24.570 --> 00:00:26.880
Foundry, Seth Juarez.

00:00:26.880 --> 00:00:30.630
[ Music ] [ Applause ]

00:00:30.630 --> 00:00:31.830
Seth Juarez: How's
it going, everybody?

00:00:31.830 --> 00:00:33.150
[ Applause ]

00:00:33.150 --> 00:00:35.610
We hope you had a great
day one of Microsoft Build

00:00:35.610 --> 00:00:39.090
and are getting ready for an
equally exciting day here today.

00:00:39.090 --> 00:00:41.010
Scott Guthrie, Charles
Lamanna, Jay Parikh,

00:00:41.010 --> 00:00:44.070
and more will be taking the
stage here in just a couple

00:00:44.070 --> 00:00:45.960
of minutes to kick
off today's keynote

00:00:45.960 --> 00:00:48.300
and day two of Microsoft Build.

00:00:48.300 --> 00:00:49.860
Let's get fired up, huh?

00:00:49.860 --> 00:00:50.640
Did we have a good day one?

00:00:50.640 --> 00:00:51.510
[ Applause ]

00:00:51.510 --> 00:00:54.060
Remember, all of this content
is going to be available

00:00:54.060 --> 00:00:55.560
on demand in the coming days.

00:00:55.560 --> 00:00:58.440
So for anything you can't
attend, make a note of it

00:00:58.440 --> 00:01:00.540
and come back to it in just
a few days to catch up

00:01:00.540 --> 00:01:03.840
or rewatch all of the
content available to you.

00:01:03.840 --> 00:01:06.150
Just like yesterday, you can
watch Kadesha Kerr and I

00:01:06.150 --> 00:01:08.220
on the digital venue
right after the keynote

00:01:08.220 --> 00:01:11.730
where we will be backstage doing
interviews and showcasing demos

00:01:11.730 --> 00:01:14.700
that we build off of the
announcements from the keynotes

00:01:14.700 --> 00:01:16.830
and provide deep
dive conversations

00:01:16.830 --> 00:01:19.350
with a wide range of
developer friends.

00:01:19.350 --> 00:01:20.570
There's really a lot.

00:01:20.570 --> 00:01:21.530
All you have to do is stay

00:01:21.530 --> 00:01:23.780
on the digital venue
after the keynotes.

00:01:23.780 --> 00:01:26.450
Just like yesterday, anyone
here needing audio description

00:01:26.450 --> 00:01:28.310
or an assistive
listening device,

00:01:28.310 --> 00:01:30.890
please visit the assistive
listening desk right

00:01:30.890 --> 00:01:33.240
at the middle entry here
in the keynote room.

00:01:33.240 --> 00:01:35.190
We will also have
ASL interpreters

00:01:35.190 --> 00:01:37.140
and closed captioning
here in the room,

00:01:37.140 --> 00:01:39.330
so please make sure
you find a seat

00:01:39.330 --> 00:01:42.540
in the designated area
for the best view.

00:01:42.540 --> 00:01:44.250
Audio description,
ASL interpretation,

00:01:44.250 --> 00:01:47.940
and closed captioning are also
available for everyone online.

00:01:47.940 --> 00:01:51.210
Simply select their associated
toggles in the video player.

00:01:51.210 --> 00:01:53.310
Before we go, we want to
give a special shout-out

00:01:53.310 --> 00:01:54.780
to our featured partners.

00:01:54.780 --> 00:01:59.130
For those here in person, make
sure to visit the hub to connect

00:01:59.130 --> 00:02:02.340
with featured partners
like ARM, Docker, Elastic,

00:02:02.340 --> 00:02:05.550
and UiPath to discover how their
cutting-edge developer solutions

00:02:05.550 --> 00:02:08.190
can optimize your workflows
and enhance performance.

00:02:08.190 --> 00:02:11.430
And I know, I know, there's
still some really cool swag,

00:02:11.430 --> 00:02:14.190
and I haven't been over there
yet, so I really want to go.

00:02:14.190 --> 00:02:16.080
Here is just a sampling of
our featured partners

00:02:16.080 --> 00:02:18.750
that you can visit in
person while here on site.

00:02:18.750 --> 00:02:20.460
To connect with all of
our featured partners,

00:02:20.460 --> 00:02:22.500
please visit the featured
partner directory

00:02:22.500 --> 00:02:24.420
on the digital venue.

00:02:24.420 --> 00:02:26.580
Before I go, I ran into
an old pal backstage

00:02:26.580 --> 00:02:29.220
and thought it would be great
to get her out here to chat

00:02:29.220 --> 00:02:31.830
about yesterday and what
to expect from today.

00:02:31.830 --> 00:02:34.620
Give a loud round of applause
for our CBP of Data, AI,

00:02:34.620 --> 00:02:36.030
Digital Apps, Jessica Hawk.

00:02:36.030 --> 00:02:37.320
Jessica, come on out.

00:02:37.320 --> 00:02:40.020
[ Music ] [ Applause ]

00:02:40.020 --> 00:02:40.560
How's it going?

00:02:40.560 --> 00:02:41.710
Jessica Hawk: Hi, Seth.

00:02:43.050 --> 00:02:44.460
Seth Juarez: I'm excited
that you're here.

00:02:44.460 --> 00:02:45.480
I'm so glad.

00:02:45.480 --> 00:02:46.860
Jessica Hawk: I'm surprised
that you're here.

00:02:46.860 --> 00:02:48.840
I would have thought you'd
be out camping right now.

00:02:48.840 --> 00:02:55.230
Seth Juarez: Yeah, you know,
camping, for me, is too in-tents.

00:02:55.230 --> 00:02:55.890
Jessica Hawk: Uh-huh.

00:02:55.890 --> 00:02:58.440
This is what I deal with
all the time, you guys.

00:02:58.440 --> 00:02:59.460
I'm just kidding, Seth.

00:02:59.460 --> 00:03:01.440
I know for a fact you
would never miss Build.

00:03:01.440 --> 00:03:03.150
Seth Juarez: Oh,
no, I love Build.

00:03:03.150 --> 00:03:05.520
Jessica Hawk: Well, so a
lot was covered yesterday,

00:03:05.520 --> 00:03:07.890
and what I was going to
do for a minute here, guys,

00:03:07.890 --> 00:03:11.640
is effectively connect what you
heard from Satya in the morning

00:03:11.640 --> 00:03:13.260
to what you're about
to hear today.

00:03:13.260 --> 00:03:17.010
Today we're doing a new style
of a developer-oriented keynote

00:03:17.010 --> 00:03:18.630
where we're basically
taking all the great stuff

00:03:18.630 --> 00:03:22.080
that we announced yesterday and
getting into the details a bit.

00:03:22.080 --> 00:03:22.650
Seth Juarez: I love it.

00:03:22.650 --> 00:03:22.950
I love it.

00:03:22.950 --> 00:03:24.450
There's a lot of
agent stuff, right?

00:03:24.450 --> 00:03:25.590
Jessica Hawk:
Yeah, if I had to take

00:03:25.590 --> 00:03:27.540
one major takeaway
from yesterday,

00:03:27.540 --> 00:03:29.520
I would say we have
officially stepped

00:03:29.520 --> 00:03:32.790
into the era of AI agents.

00:03:32.790 --> 00:03:33.480
Seth Juarez: It's true.

00:03:33.480 --> 00:03:34.846
Jessica Hawk: And
there's major breakthroughs

00:03:34.871 --> 00:03:36.180
that have been happening

00:03:36.180 --> 00:03:37.650
over the last few years here.

00:03:37.650 --> 00:03:39.030
The systems are reasoning.

00:03:39.030 --> 00:03:40.170
They're connecting.

00:03:40.170 --> 00:03:42.120
And I'm a former developer.

00:03:42.120 --> 00:03:44.760
AI feels like it is
now working with us

00:03:44.760 --> 00:03:47.670
to help solve the problems,
get rid of the drudgery.

00:03:47.670 --> 00:03:50.430
And, frankly, software
is our art, right?

00:03:50.430 --> 00:03:52.770
And we're back to creating,
which is super exciting.

00:03:52.770 --> 00:03:52.830
Seth Juarez: Yeah.

00:03:52.830 --> 00:03:57.780
Look, every time I think AI in
my head, I just think, "Ai!"

00:03:57.780 --> 00:03:59.580
These are the jokes, people.

00:03:59.580 --> 00:04:00.690
What are we doing here?

00:04:00.690 --> 00:04:02.610
Come on.

00:04:02.610 --> 00:04:03.300
[ Laughter ]

00:04:03.300 --> 00:04:05.250
All right, now we're looking
ahead to another great keynote.

00:04:05.250 --> 00:04:06.090
What do we expect?

00:04:06.090 --> 00:04:07.200
Jessica Hawk: Well,
I think we're going

00:04:07.200 --> 00:04:08.790
to see a lot of
hands on keyboard.

00:04:08.790 --> 00:04:12.810
And I also think maybe
you're coming back out.

00:04:12.810 --> 00:04:13.440
Am I right about that?

00:04:13.440 --> 00:04:15.390
Seth Juarez: Yes, I may
have some fun stuff to do.

00:04:15.390 --> 00:04:16.950
So I'm pretty
excited about that.

00:04:16.950 --> 00:04:17.910
Jessica Hawk: All right,
should we get started?

00:04:17.910 --> 00:04:18.570
Seth Juarez: Let's do it.

00:04:18.570 --> 00:04:21.750
Let's get started on day
two of Microsoft Build.

00:04:21.750 --> 00:04:22.708
Let's do it.

00:04:22.733 --> 00:04:26.961
[ Applause ]

00:04:28.659 --> 00:04:32.250
[ Music ]

00:04:32.250 --> 00:04:33.900
Voiceover: For the
last 50 years,

00:04:33.900 --> 00:04:37.530
Microsoft has been
empowering developers.

00:04:37.530 --> 00:04:39.660
Speaker 1: Over 100
million Windows users.

00:04:39.660 --> 00:04:40.620
[ Applause ]

00:04:40.620 --> 00:04:41.970
Speaker 2: We have
reduced the time

00:04:41.970 --> 00:04:44.460
to build AI applications by 50%.

00:04:44.460 --> 00:04:46.800
Speaker 3: When a customer
comes to us to buy a vehicle,

00:04:46.800 --> 00:04:47.970
AI helps serve all

00:04:47.970 --> 00:04:49.770
that information up
at the right time.

00:04:49.770 --> 00:04:52.110
Speaker 4: This truly is a new
era for the legal industry.

00:04:52.110 --> 00:04:54.150
Voiceover: Microsoft Fabric
brings our data together

00:04:54.150 --> 00:04:55.770
in a single cohesive stack.

00:04:55.770 --> 00:04:58.740
Speaker 5: We created Hoppian,
agentic AI assistant.

00:04:58.740 --> 00:05:01.020
Voiceover: Now through the
transformational power of AI

00:05:01.020 --> 00:05:03.420
with GitHub Copilot,
Visual Studio Code,

00:05:03.420 --> 00:05:04.980
and Azure AI Foundry,

00:05:04.980 --> 00:05:07.620
every developer has the
power to shape the future.

00:05:07.620 --> 00:05:10.590
From cloud to client, the
data center to Windows.

00:05:10.590 --> 00:05:12.330
Speaker 6: Copilot changed
the way that we work.

00:05:12.330 --> 00:05:13.530
Speaker 7: We take
advantage of the latest

00:05:13.530 --> 00:05:15.480
and greatest models
through Azure Open AI.

00:05:15.480 --> 00:05:17.010
Speaker 8: We're unlocking
the full potential

00:05:17.010 --> 00:05:18.060
of agentic AI.

00:05:18.060 --> 00:05:19.470
Speaker 9: There aren't very
many arenas that account

00:05:19.470 --> 00:05:20.370
for the hard of hearing.

00:05:20.370 --> 00:05:21.570
Speaker 10: Most of
the heavy lifting,

00:05:21.570 --> 00:05:23.040
right in the boilerplate,
was just done.

00:05:23.040 --> 00:05:25.230
Speaker 11: AI will help us
change the world quicker.

00:05:25.230 --> 00:05:26.850
Voiceover: And we're
just getting started.

00:05:26.850 --> 00:05:29.010
[ Music ]

00:05:29.010 --> 00:05:32.734
Please welcome Executive
Vice President, CoreAI,

00:05:32.759 --> 00:05:34.318
Jay Parikh.

00:05:34.343 --> 00:05:41.705
[ Music ] [ Applause ]

00:05:41.730 --> 00:05:43.200
Jay Parikh: Good
morning, everyone.

00:05:43.200 --> 00:05:44.010
How was day one?

00:05:44.010 --> 00:05:45.365
Speaker 12: It was great.

00:05:45.390 --> 00:05:46.810
Yeah? That's awesome.

00:05:46.834 --> 00:05:47.346
[ Applause ]

00:05:47.370 --> 00:05:47.670
All right.

00:05:47.670 --> 00:05:49.260
Well, welcome to day two.

00:05:49.260 --> 00:05:52.530
My name is Jay, and I support
the new CoreAI team here

00:05:52.530 --> 00:05:53.820
at Microsoft.

00:05:53.820 --> 00:05:56.190
This is my very first
Build, so it's great

00:05:56.190 --> 00:05:58.140
to be here with you all.

00:05:58.140 --> 00:06:01.320
Now, I'm excited because
I've spent a lot of time

00:06:01.320 --> 00:06:06.420
in my career building infra,
tools, platform for developers.

00:06:06.420 --> 00:06:08.880
Soon after I started
at Microsoft last year,

00:06:08.880 --> 00:06:10.590
Satya and I were chatting,

00:06:10.590 --> 00:06:13.260
and we were discussing
what it would take

00:06:13.260 --> 00:06:16.560
to reimagine the end-to-end
developer experience

00:06:16.560 --> 00:06:19.980
for this new era of
AI applications.

00:06:19.980 --> 00:06:24.300
Now, with this in mind, we
formed the CoreAI team to focus

00:06:24.300 --> 00:06:29.160
on empowering every developer
to shape the future with AI.

00:06:29.160 --> 00:06:32.250
Now, this is a big,
ambitious vision,

00:06:32.250 --> 00:06:34.350
and we have a lot of work to do.

00:06:34.350 --> 00:06:36.930
But there are three
principles that guide us.

00:06:36.930 --> 00:06:41.970
First is that we need to force
ourselves to use AI-driven tools

00:06:41.970 --> 00:06:46.020
and platform instead of just
AI-assisted experiences.

00:06:46.020 --> 00:06:49.860
And we need to transform the
entire development experience,

00:06:49.860 --> 00:06:51.660
not just a part of it.

00:06:51.660 --> 00:06:55.740
And finally, we need to continue
to embrace openness and choice,

00:06:55.740 --> 00:07:00.240
given how fast the landscape
of AI is changing around us.

00:07:00.240 --> 00:07:02.310
Based on these principles,
today we're going

00:07:02.310 --> 00:07:06.780
to show you a complete set of
AI-powered tools for building

00:07:06.780 --> 00:07:10.680
on top of a full-stack
agent factory with security

00:07:10.680 --> 00:07:12.540
and trust baked right in,

00:07:12.540 --> 00:07:15.720
extending from the
cloud to the edge.

00:07:15.720 --> 00:07:19.440
Now, we're focused on this
because we want these tools

00:07:19.440 --> 00:07:22.410
and this factory to bring
back joy in building

00:07:22.410 --> 00:07:26.580
and operating your new
age of AI applications.

00:07:26.580 --> 00:07:28.920
We're going to make it
easier for you to build.

00:07:28.920 --> 00:07:31.110
We're going to make it
easier for you to test,

00:07:31.110 --> 00:07:34.740
for you to deploy, and for you
to monitor your applications.

00:07:34.740 --> 00:07:37.320
We want to help you
modernize your applications,

00:07:37.320 --> 00:07:40.590
and we also want to help
burn down tech debt.

00:07:40.590 --> 00:07:43.500
Now, why is this
important to us?

00:07:43.500 --> 00:07:47.910
Because as builders, our most
precious resource is time,

00:07:47.910 --> 00:07:50.130
and we want to give
you time back.

00:07:50.130 --> 00:07:54.480
So as I tell our team,
"Show more, talk less."

00:07:54.480 --> 00:07:57.240
Now, as an engineer, I
want to get in and start

00:07:57.240 --> 00:07:59.760
to understand how
to use these tools.

00:07:59.760 --> 00:08:03.720
So I'm going to jump
right in here to Copilot,

00:08:03.720 --> 00:08:05.460
and the first thing I'm
going to do is pop

00:08:05.460 --> 00:08:07.620
into immersive experience.

00:08:07.620 --> 00:08:10.410
Now, as a new member of the
team, well, let's start off

00:08:10.410 --> 00:08:13.230
with just something basic
that we all know how to do.

00:08:13.230 --> 00:08:18.270
So we want to see how Copilot
is going to help me ramp

00:08:18.270 --> 00:08:20.460
up in this new application.

00:08:20.460 --> 00:08:22.320
And I'm a new member of
the team, and I'm trying

00:08:22.320 --> 00:08:26.220
to learn context about what
this Build event's demo is

00:08:26.220 --> 00:08:27.870
that we're going to be
using throughout the course

00:08:27.870 --> 00:08:28.830
of the day.

00:08:28.830 --> 00:08:31.080
Now, this is what
Copilot returned.

00:08:31.080 --> 00:08:32.490
It's pretty basic.

00:08:32.490 --> 00:08:34.560
I think we can do a
little bit better.

00:08:34.560 --> 00:08:38.310
So I'm going to ask Copilot
to help me out here.

00:08:38.310 --> 00:08:40.860
Now, Copilot is
going to take this.

00:08:40.860 --> 00:08:43.470
I asked it to open up
a PR so that maybe

00:08:43.470 --> 00:08:48.000
when a new engineer joins
the team, it can actually --

00:08:48.000 --> 00:08:51.000
Copilot can actually help
create a new README file

00:08:51.000 --> 00:08:54.300
with instructions that actually
help me understand the code,

00:08:54.300 --> 00:08:58.560
understand the application, but
also provide setup instructions.

00:08:58.560 --> 00:09:02.250
So Copilot got to work here,
and I'm going to click on this

00:09:02.250 --> 00:09:04.530
to show you what it
started to work on here.

00:09:04.530 --> 00:09:07.560
So here's the new request
that it's working on.

00:09:07.560 --> 00:09:11.400
You can see that Copilot
started work on behalf of me.

00:09:11.400 --> 00:09:14.310
Now, it's going to take some
time to go pull this together.

00:09:14.310 --> 00:09:17.550
So this was helpful, and it's
a fast way for me to ramp

00:09:17.550 --> 00:09:20.310
up as being a new
person in the team.

00:09:20.310 --> 00:09:23.220
But let's dive into our
tools a little bit more

00:09:23.220 --> 00:09:25.170
so that we can show you
how to take these tools

00:09:25.170 --> 00:09:26.910
so that we can develop faster.

00:09:26.910 --> 00:09:29.490
And for that, I want to
welcome my colleague, Jessica.

00:09:29.490 --> 00:09:34.670
[ Applause ]

00:09:34.695 --> 00:09:35.416
Hi, Jessica.

00:09:35.441 --> 00:09:35.940
Jessica Deen: Hi.

00:09:35.940 --> 00:09:36.510
How's it going?

00:09:36.510 --> 00:09:37.565
Jay Parikh: Good. You?

00:09:37.590 --> 00:09:38.303
Jessica Deen: Doing great.

00:09:38.328 --> 00:09:38.868
Hi, everyone.

00:09:38.893 --> 00:09:39.450
Jay Parikh: Ready to get going?

00:09:39.450 --> 00:09:40.680
Jessica Deen: Yeah,
ready to do some stuff.

00:09:40.680 --> 00:09:42.660
Yep. Good morning, everyone.

00:09:42.660 --> 00:09:45.420
My name is Jessica,
and I'm a developer,

00:09:45.420 --> 00:09:47.550
which mostly means I spend a lot

00:09:47.550 --> 00:09:50.220
of time asking myself,
"Who broke this?"

00:09:50.220 --> 00:09:54.060
And then realizing it was me.

00:09:54.060 --> 00:09:57.150
Okay. I'm in VS Code, and
with the GitHub extension,

00:09:57.150 --> 00:10:00.570
I've got all my issues and
PRs right here in the editor,

00:10:00.570 --> 00:10:04.410
which is great until someone
decides that I'm the expert

00:10:04.410 --> 00:10:07.020
and creates the kind of
issue that looks simple

00:10:07.020 --> 00:10:08.880
until it most definitely is not.

00:10:08.880 --> 00:10:11.250
So let's do what every
good developer does

00:10:11.250 --> 00:10:12.750
with a long backlog.

00:10:12.750 --> 00:10:14.520
You're absolutely right.

00:10:14.520 --> 00:10:17.070
Immediately look for
something we can pawn off.

00:10:17.070 --> 00:10:17.460
All right.

00:10:17.460 --> 00:10:20.430
First up, we have
input validation.

00:10:20.430 --> 00:10:21.570
What do you think, Jay?

00:10:21.570 --> 00:10:21.870
Jay Parikh: No.

00:10:21.870 --> 00:10:22.290
Jessica Deen: No.

00:10:22.290 --> 00:10:23.730
Absolutely not.

00:10:23.730 --> 00:10:27.480
Yeah. I'm going to have to
escalate this to not me.

00:10:27.480 --> 00:10:29.280
Copilot, you're up.

00:10:29.280 --> 00:10:30.330
I believe in you.

00:10:30.330 --> 00:10:32.460
You love boring things.

00:10:32.460 --> 00:10:32.820
All right.

00:10:32.820 --> 00:10:35.670
Next. Type hints.

00:10:35.670 --> 00:10:36.270
Jay Parikh: Also no.

00:10:36.270 --> 00:10:36.780
Jessica Deen: Yeah.

00:10:36.780 --> 00:10:40.380
Nothing says I trust no one
like explaining every argument

00:10:40.380 --> 00:10:43.530
and return value
in painful detail.

00:10:43.530 --> 00:10:44.430
Hard pass.

00:10:44.430 --> 00:10:46.950
Again, I'm going to let
Copilot take this one.

00:10:46.950 --> 00:10:49.050
It lives for this kind of thing.

00:10:49.050 --> 00:10:49.440
All right.

00:10:49.440 --> 00:10:51.660
Next. To-do comments.

00:10:51.660 --> 00:10:52.770
Seriously?

00:10:52.770 --> 00:10:53.790
Jay Parikh: Oh, boy.

00:10:53.790 --> 00:10:55.350
Jessica Deen: I feel
personally attacked.

00:10:55.350 --> 00:10:57.030
Who opened this?

00:10:57.030 --> 00:10:59.220
Oh. Told you I break things.

00:10:59.220 --> 00:11:00.210
It was me.

00:11:00.210 --> 00:11:02.700
Yep. Copilot, my
trusty sidekick,

00:11:02.700 --> 00:11:05.610
go fulfill past me's
empty promises.

00:11:05.610 --> 00:11:06.720
So yeah.

00:11:06.720 --> 00:11:07.830
Instead of spending the rest

00:11:07.830 --> 00:11:10.260
of this keynote writing
boilerplate validation

00:11:10.260 --> 00:11:12.030
and chasing down old to-dos,

00:11:12.030 --> 00:11:15.420
I can let GitHub Copilot
coding agent handle the stuff

00:11:15.420 --> 00:11:18.390
that drains my will to
code and actually focus

00:11:18.390 --> 00:11:21.540
on real product
work like this one.

00:11:21.540 --> 00:11:24.270
Updating the mic icon with
a new design from Figma.

00:11:24.270 --> 00:11:26.760
I'll just click this arrow
here that'll self-assign me

00:11:26.760 --> 00:11:30.300
to the issue and it'll allow me
to start work on a local branch.

00:11:30.300 --> 00:11:33.630
Let's also go ahead and bring
up the simple browser here

00:11:33.630 --> 00:11:35.610
so that we can see what
we're working with.

00:11:35.610 --> 00:11:37.710
Great. I can see the
current mic icon.

00:11:37.710 --> 00:11:39.810
Now I'll just hop into
the mic icon file

00:11:39.810 --> 00:11:42.510
and we'll start doing
an on-click event.

00:11:42.510 --> 00:11:44.340
Perfect. Thanks, ghost text.

00:11:44.340 --> 00:11:47.610
Now, notice that when I do,
Copilot actually sees this

00:11:47.610 --> 00:11:50.160
and it starts to suggest
updates to other parts

00:11:50.160 --> 00:11:52.140
of the code proactively.

00:11:52.140 --> 00:11:55.980
All I have to do is hit Tab and
then Tab again and that's it.

00:11:55.980 --> 00:11:57.870
This is called Next
Edit Suggestions

00:11:57.870 --> 00:12:01.710
and it's Copilot taking
completions to the next level.

00:12:01.710 --> 00:12:04.560
Now, Jay, I could go
back over to the issue.

00:12:04.560 --> 00:12:06.480
I could grab the
design from Figma.

00:12:06.480 --> 00:12:09.510
I could start refactoring
and writing the route logic.

00:12:09.510 --> 00:12:12.780
But honestly, you didn't
come here to watch me code.

00:12:12.780 --> 00:12:14.610
They didn't come here
to watch me code.

00:12:14.610 --> 00:12:17.040
We've got a packed keynote
full of awesome things.

00:12:17.040 --> 00:12:17.430
Jay Parikh: We do.

00:12:17.430 --> 00:12:19.770
Jessica Deen: So let's
actually scale me up

00:12:19.770 --> 00:12:23.280
and let's bring an agent
in right here in VS Code.

00:12:23.280 --> 00:12:25.950
I'll simply pop over into
Copilot and all I have

00:12:25.950 --> 00:12:30.870
to do is tell Copilot to begin
to work on this issue and just

00:12:30.870 --> 00:12:33.960
like that, Copilot will
actually take care of the rest.

00:12:33.960 --> 00:12:36.750
It's going to go out and fetch
the issue details directly

00:12:36.750 --> 00:12:37.620
from GitHub.

00:12:37.620 --> 00:12:39.540
It'll even spot the Figma link

00:12:39.540 --> 00:12:41.640
and it'll grab the
designs automatically.

00:12:41.640 --> 00:12:42.960
And check this out, Jay.

00:12:42.960 --> 00:12:43.800
Look at this.

00:12:43.800 --> 00:12:48.000
Under References, it's even
sure to follow our organization

00:12:48.000 --> 00:12:50.640
and our code base's
best practices.

00:12:50.640 --> 00:12:53.040
It picked the Copilot
instructions file

00:12:53.040 --> 00:12:54.540
up automatically.

00:12:54.540 --> 00:12:56.700
Now, you're probably thinking
at this point, "Wow,

00:12:56.700 --> 00:12:59.430
Jessica, this is spectacular."

00:12:59.430 --> 00:13:01.500
And you are correct.

00:13:01.500 --> 00:13:04.680
But you also might be wondering,
"How is this all working?"

00:13:04.680 --> 00:13:06.450
I'm so glad you asked.

00:13:06.450 --> 00:13:10.380
This is all powered by Model
Context Protocol or MCP.

00:13:10.380 --> 00:13:14.340
And to keep it simple, MCP
enhances our chat experience

00:13:14.340 --> 00:13:18.420
by giving Copilot more context
and access to more tools.

00:13:18.420 --> 00:13:20.070
You can see those tools here.

00:13:20.070 --> 00:13:22.440
We can do a wide variety
of things with GitHub

00:13:22.440 --> 00:13:26.130
and we can even grab the
assets directly from Figma.

00:13:26.130 --> 00:13:28.530
Okay, now I can see that
agent mode is done.

00:13:28.530 --> 00:13:30.420
Let's take a look at it.

00:13:30.420 --> 00:13:32.220
Jay Parikh: Wow, that
looks spectacular.

00:13:32.220 --> 00:13:33.060
Jessica Deen: This
looks pretty great.

00:13:33.060 --> 00:13:35.070
It's a pixel perfect
match to Figma

00:13:35.070 --> 00:13:36.840
and it even has
the raised effect.

00:13:36.840 --> 00:13:38.640
Now, all I have to
do is hit "Keep".

00:13:38.640 --> 00:13:40.560
And then if I go over
to my source control,

00:13:40.560 --> 00:13:42.750
I want to show you something
else that I really love.

00:13:42.750 --> 00:13:45.570
Is Copilot can actually even
finish my commit messages

00:13:45.570 --> 00:13:46.560
for me too.

00:13:46.560 --> 00:13:50.040
It knows exactly what changed
and it knows my commit style.

00:13:50.040 --> 00:13:53.340
And quite honestly, it saves
me from writing fixed stuff

00:13:53.340 --> 00:13:55.830
or did the thing for
the third time today.

00:13:55.830 --> 00:13:57.630
Now, we could go ahead
and publish this

00:13:57.630 --> 00:13:59.760
and actually submit a PR,

00:13:59.760 --> 00:14:01.560
but we already know
how that part works.

00:14:01.560 --> 00:14:04.170
So I want to show you something
else that's really cool.

00:14:04.170 --> 00:14:06.630
The issue that you assigned
earlier, I know you have a lot

00:14:06.630 --> 00:14:08.070
of things to cover
in the keynote,

00:14:08.070 --> 00:14:10.920
I'm going to do you a solid and
I want to review this for you.

00:14:10.920 --> 00:14:13.080
While we were off
working in VS Code,

00:14:13.080 --> 00:14:15.510
Copilot actually already
handled the README.

00:14:15.510 --> 00:14:18.090
And we can take a look
and see if it's done.

00:14:18.090 --> 00:14:18.870
And I believe it is.

00:14:18.870 --> 00:14:19.350
There we go.

00:14:19.350 --> 00:14:20.850
We see the file's changed.

00:14:20.850 --> 00:14:23.760
And I'm just going to jump over
and look at the rich diff.

00:14:23.760 --> 00:14:24.300
And look at this.

00:14:24.300 --> 00:14:25.890
It added quite a
bit more things.

00:14:25.890 --> 00:14:26.640
Jay Parikh: That's right.

00:14:26.640 --> 00:14:27.690
Jessica Deen: This is awesome,

00:14:27.690 --> 00:14:29.940
but I don't think it's perfect.

00:14:29.940 --> 00:14:32.250
Now, we've talked a lot
about accessibility

00:14:32.250 --> 00:14:33.630
and having some visualization

00:14:33.630 --> 00:14:34.938
and some other things
to enhance it.

00:14:34.963 --> 00:14:35.460
Jay Parikh: Yeah.

00:14:35.460 --> 00:14:37.050
Jessica Deen: I think it
would be even more powerful

00:14:37.050 --> 00:14:39.240
if we added an architecture
diagram to this.

00:14:39.240 --> 00:14:39.930
Jay Parikh: Good idea.

00:14:39.930 --> 00:14:41.640
Jessica Deen: So I'm going to
jump over to the conversation.

00:14:41.640 --> 00:14:43.890
And honestly, this is
why we do code reviews.

00:14:43.890 --> 00:14:46.140
I'll just jump down here,
down at the bottom.

00:14:46.140 --> 00:14:48.600
And I'll go ahead and
tell Copilot that I want

00:14:48.600 --> 00:14:52.020
to add an architecture
diagram using Mermaid.js.

00:14:52.020 --> 00:14:53.010
Now, check this out.

00:14:53.010 --> 00:14:56.580
When I hit "Comment"
and I scroll up,

00:14:56.580 --> 00:14:59.040
we'll see Copilot should
pick this up pretty quickly.

00:14:59.040 --> 00:15:02.220
And it'll immediately get to
work on the requested changes.

00:15:02.220 --> 00:15:02.730
There we go.

00:15:02.730 --> 00:15:03.900
We could jump into the session.

00:15:03.900 --> 00:15:05.550
But we don't have
time to do that.

00:15:05.550 --> 00:15:08.520
Let me show you what a
completed one looks like.

00:15:08.520 --> 00:15:10.020
Let's take a look here.

00:15:10.020 --> 00:15:11.610
Look at that Mermaid diagram.

00:15:11.610 --> 00:15:12.480
That's pretty awesome.

00:15:12.480 --> 00:15:13.170
Jay Parikh: That's awesome.

00:15:13.170 --> 00:15:13.770
Jessica Deen: It's pretty great.

00:15:13.770 --> 00:15:18.180
[ Applause ]

00:15:18.180 --> 00:15:19.800
Now, this is one of
my favorite parts.

00:15:19.800 --> 00:15:23.370
Because in just a few issues,
Copilot helped me move

00:15:23.370 --> 00:15:26.370
from issue to
implementation quickly.

00:15:26.370 --> 00:15:29.580
And honestly, it handled the
stuff that, as developers,

00:15:29.580 --> 00:15:31.260
usually slows us down.

00:15:31.260 --> 00:15:35.040
And personally, as a
developer, it amplifies me.

00:15:35.040 --> 00:15:38.520
And as a result, I get to
focus on higher impact work

00:15:38.520 --> 00:15:41.220
and still move fast confidently.

00:15:41.220 --> 00:15:43.020
Jay Parikh: How do I
use that in my app?

00:15:43.020 --> 00:15:45.450
Jessica Deen: You know,
I am so glad you asked.

00:15:45.450 --> 00:15:48.090
This is all powered by
something called models.

00:15:48.090 --> 00:15:49.500
And the best part is, is

00:15:49.500 --> 00:15:52.470
that I can use these same
models in my own apps.

00:15:52.470 --> 00:15:54.900
In fact, that's what
makes this so powerful,

00:15:54.900 --> 00:15:56.730
is it's not just for GitHub.

00:15:56.730 --> 00:15:59.760
In fact, everyone in this room
can build their own agentic

00:15:59.760 --> 00:16:04.500
applications, too, using GitHub
models and Azure AI Foundry.

00:16:04.500 --> 00:16:06.210
We can even pop over
and take a look

00:16:06.210 --> 00:16:08.460
at the different models we
have in the playground.

00:16:08.460 --> 00:16:11.310
And when we click "Use This
Model", we can also take a look

00:16:11.310 --> 00:16:12.630
at the different languages.

00:16:12.630 --> 00:16:13.920
And when you scroll down,

00:16:13.920 --> 00:16:16.650
we'll even give you some
code to get started.

00:16:16.650 --> 00:16:19.050
And I believe we actually
have an issue open for that,

00:16:19.050 --> 00:16:21.690
that Amanda and Elijah on our
team are going to dive more

00:16:21.690 --> 00:16:26.220
into GitHub models and Azure AI
Foundry in just a few moments.

00:16:26.220 --> 00:16:29.250
Now, just to recap here, in
just about five minutes,

00:16:29.250 --> 00:16:31.110
we've tackled five issues.

00:16:31.110 --> 00:16:31.950
How are we doing so far?

00:16:31.950 --> 00:16:34.200
Jay Parikh: We're
doing really well.

00:16:34.200 --> 00:16:37.080
Now, I was looking
at, last night,

00:16:37.080 --> 00:16:38.580
though, we had an incident.

00:16:38.580 --> 00:16:39.150
Jessica Deen: We did.

00:16:39.150 --> 00:16:41.430
Jay Parikh: And I was wondering

00:16:41.430 --> 00:16:43.170
if we should take a
deeper look at that,

00:16:43.170 --> 00:16:47.370
because we may have an
issue with this old version

00:16:47.370 --> 00:16:49.110
of Java in the back end.

00:16:49.110 --> 00:16:49.830
Jessica Deen: I
think you're right.

00:16:49.830 --> 00:16:52.320
And honestly, that's one of the
things that's the hardest part

00:16:52.320 --> 00:16:56.010
about being a developer is
things like tech debt like that

00:16:56.010 --> 00:16:58.800
and figuring out how we can
address upgrading things.

00:16:58.800 --> 00:17:01.320
I believe our back
end is using Java 8.

00:17:01.320 --> 00:17:01.710
Jay Parikh: That's right.

00:17:01.710 --> 00:17:02.700
Jessica Deen: And
we've talked a lot

00:17:02.700 --> 00:17:04.710
about how we can upgrade that.

00:17:04.710 --> 00:17:06.720
Why don't I take a
look at the incident?

00:17:06.720 --> 00:17:08.460
And do you want to take a
look at the Java 8 update?

00:17:08.460 --> 00:17:09.750
Jay Parikh: Yeah, let
me get started on that.

00:17:09.750 --> 00:17:10.560
Jessica Deen: Perfect.

00:17:10.560 --> 00:17:11.040
All right.

00:17:11.040 --> 00:17:12.810
Let me go ahead and
switch over here.

00:17:12.810 --> 00:17:16.170
Now, let's talk about that
issue that Jay mentioned.

00:17:16.170 --> 00:17:18.600
I can see right here that
we do have an incident

00:17:18.600 --> 00:17:19.950
that happened last night.

00:17:19.950 --> 00:17:22.110
It looks like there was
an unhandled exception.

00:17:22.110 --> 00:17:24.570
And what's cool is I can also
see an incident's timeline

00:17:24.570 --> 00:17:25.560
and summary.

00:17:25.560 --> 00:17:27.540
Now, as I'm scrolling further,

00:17:27.540 --> 00:17:29.880
I can see that there's
a root cause analysis.

00:17:29.880 --> 00:17:31.800
I can see that there's
some attachments.

00:17:31.800 --> 00:17:36.960
And when I open that issue, when
I click the deep link to go

00:17:36.960 --> 00:17:40.110
over into Azure, I can see
the Azure monitor alert

00:17:40.110 --> 00:17:40.980
that was detected.

00:17:40.980 --> 00:17:46.110
I can see it was a Sev2 alert
that was fired at 1:57 a.m. Now,

00:17:46.110 --> 00:17:48.270
this is important, and
this is really cool,

00:17:48.270 --> 00:17:51.690
because the SRE agent from
Azure actually did all the work

00:17:51.690 --> 00:17:52.440
for me.

00:17:52.440 --> 00:17:54.360
We as developers know that one

00:17:54.360 --> 00:17:56.580
of the worst things is
being paged in the middle

00:17:56.580 --> 00:17:58.260
of the night and being on call.

00:17:58.260 --> 00:18:01.560
Mainly because at 1:57 in the
morning, I don't know about you,

00:18:01.560 --> 00:18:03.420
but my brain is not booted up.

00:18:03.420 --> 00:18:04.650
It is sleeping.

00:18:04.650 --> 00:18:06.450
It is in hibernation state.

00:18:06.450 --> 00:18:09.360
Luckily, SRE agent was
able to address that

00:18:09.360 --> 00:18:11.400
and handle that super quickly.

00:18:11.400 --> 00:18:15.240
I can see that it immediately
acknowledged the alert at 1:57,

00:18:15.240 --> 00:18:17.160
and it began the investigation.

00:18:17.160 --> 00:18:19.290
I can see the
activity logs for it.

00:18:19.290 --> 00:18:21.600
It's starting to
form a hypothesis.

00:18:21.600 --> 00:18:23.910
I can see the log
analytics queries.

00:18:23.910 --> 00:18:25.410
And scrolling down even further,

00:18:25.410 --> 00:18:27.780
I can see that it finished
the investigation.

00:18:27.780 --> 00:18:32.490
It was looking at the total
requests, memory utilization,

00:18:32.490 --> 00:18:37.350
CPU, and here's where it noticed
the spike in those 500 errors.

00:18:37.350 --> 00:18:38.970
Now, what's also
cool is it figured

00:18:38.970 --> 00:18:40.950
out the deployment
and the correlation.

00:18:40.950 --> 00:18:44.330
So it was able to detect that
these 500 errors were related

00:18:44.330 --> 00:18:46.040
to a faulty deployment.

00:18:46.040 --> 00:18:49.800
And what's even better is it
actually handled the rollback

00:18:49.800 --> 00:18:53.580
for me, and it continued
monitoring it after the fact.

00:18:53.580 --> 00:18:55.470
Now, this is really
important because if I look

00:18:55.470 --> 00:18:58.740
at the timestamp here,
we're now at 2:02.

00:18:58.740 --> 00:19:01.620
So in seven minutes
-- five minutes, actually,

00:19:01.620 --> 00:19:05.010
I believe -- it was able to
pick that up, roll it back,

00:19:05.010 --> 00:19:08.070
handle the monitoring, and I
didn't have to get out of bed.

00:19:08.070 --> 00:19:11.130
What's even more powerful
is because it commented

00:19:11.130 --> 00:19:12.780
in the issue, it only took me

00:19:12.780 --> 00:19:14.940
about 30 seconds to
get caught up on.

00:19:14.940 --> 00:19:15.930
So this is great.

00:19:15.930 --> 00:19:17.370
It saved me a lot of time.

00:19:17.370 --> 00:19:20.550
I didn't have to wake up, and
I could go back up to the top

00:19:20.550 --> 00:19:23.370
of this issue, assign
it to GitHub Copilot,

00:19:23.370 --> 00:19:26.190
and let GitHub Copilot maybe
address the code change

00:19:26.190 --> 00:19:27.300
that broke it.

00:19:27.300 --> 00:19:30.720
However, Jay, I think we
know what the issue is.

00:19:30.720 --> 00:19:34.260
We really can't put off that
Java migration any longer,

00:19:34.260 --> 00:19:36.180
and as painful as
it's going to be,

00:19:36.180 --> 00:19:37.470
I think we have to tackle it.

00:19:37.470 --> 00:19:38.250
What are your thoughts?

00:19:38.250 --> 00:19:39.390
Jay Parikh: I think
we can tackle it.

00:19:39.390 --> 00:19:41.730
Actually, Jessica, it
doesn't look that bad

00:19:41.730 --> 00:19:44.730
because I think we can call
in Copilot to help us.

00:19:44.730 --> 00:19:46.080
So check this out.

00:19:46.080 --> 00:19:46.500
Jessica Deen: All right.

00:19:46.500 --> 00:19:49.680
Jay Parikh: So, started this
project to see what we need

00:19:49.680 --> 00:19:53.220
to do to upgrade this, and
it runs this report for us,

00:19:53.220 --> 00:19:57.360
so we get a good landscape
as to what we've got to do here.

00:19:57.360 --> 00:20:01.020
So then I can pop over to
the "Migrate" tab here,

00:20:01.020 --> 00:20:02.970
and it says here we've got
a couple things to do here,

00:20:02.970 --> 00:20:04.920
but we've got to
upgrade our version

00:20:04.920 --> 00:20:07.650
of RabbitMQ here to
Azure Service Bus.

00:20:07.650 --> 00:20:07.890
Jessica Deen: Okay.

00:20:07.890 --> 00:20:08.820
Jay Parikh: So I'm just
going to click the

00:20:08.820 --> 00:20:12.120
"Migrate" button here, and
GitHub Copilot picks this up.

00:20:12.120 --> 00:20:14.940
It starts working on
this, and we'll see

00:20:14.940 --> 00:20:16.680
as it's analyzing
the project here,

00:20:16.680 --> 00:20:20.310
you can see that it's looking
at different files here.

00:20:20.310 --> 00:20:22.980
It's coming up with a
plan for what it needs

00:20:22.980 --> 00:20:24.780
to do to go change here.

00:20:24.780 --> 00:20:24.990
Jessica Deen: Okay.

00:20:24.990 --> 00:20:26.460
Jay Parikh: And now it's
going to start to go look

00:20:26.460 --> 00:20:28.890
at a bunch of files here,
and you can see, hey, look,

00:20:28.890 --> 00:20:30.300
there's a couple of
Java files here.

00:20:30.300 --> 00:20:31.260
We've got to go do this.

00:20:31.260 --> 00:20:34.410
So I'm going to hit "Continue"
here, and it's going to get

00:20:34.410 --> 00:20:36.660
to work here cranking through
these files and figuring

00:20:36.660 --> 00:20:39.570
out what we need to change here,
and you can see here it's going

00:20:39.570 --> 00:20:41.520
to jam through this,
and look at that.

00:20:41.520 --> 00:20:45.570
So here's a set of changes that
Copilot puts out there for us

00:20:45.570 --> 00:20:50.340
to upgrade here to Azure Service
Bus and off of RabbitMQ,

00:20:50.340 --> 00:20:54.500
and it looks like this is
done pretty, pretty fast.

00:20:54.500 --> 00:20:55.430
Jessica Deen: That's amazing.

00:20:55.430 --> 00:20:57.260
I mean, this just
saved us so much time,

00:20:57.260 --> 00:20:59.600
and here we were thinking, we
kept putting that issue off

00:20:59.600 --> 00:21:02.780
on the backlog, thinking it was
just going to take way too long,

00:21:02.780 --> 00:21:04.790
and, I think that's
basically now, what,

00:21:04.790 --> 00:21:07.327
seven issues in just
about seven minutes?

00:21:07.352 --> 00:21:07.880
Jay Parikh: That's not bad.

00:21:07.880 --> 00:21:09.020
Jessica Deen: That's a
pretty good success rate.

00:21:09.020 --> 00:21:10.440
Jay Parikh: Yeah, we
should keep it going.

00:21:10.440 --> 00:21:11.130
Jessica Deen: We should.

00:21:11.130 --> 00:21:12.360
You know, we were
actually talking

00:21:12.360 --> 00:21:14.940
about another issue
over lunch last week.

00:21:14.940 --> 00:21:16.025
I have an idea for it.

00:21:16.050 --> 00:21:16.470
Jay Parikh: Okay.

00:21:16.495 --> 00:21:17.190
Jessica Deen: Why don't I --

00:21:17.190 --> 00:21:18.051
Jay Parikh: You want to
get to work on that?

00:21:18.076 --> 00:21:18.805
Jessica Deen: Yeah, why
don't I work on that?

00:21:18.830 --> 00:21:19.480
Jay Parikh: And I'll
finish up this?

00:21:19.505 --> 00:21:19.800
Jessica Deen: Okay.

00:21:19.800 --> 00:21:20.340
Jay Parikh: Okay.

00:21:20.340 --> 00:21:20.610
Jessica Deen: Perfect.

00:21:20.610 --> 00:21:23.810
Jay Parikh: So just to
recap here, what you saw

00:21:23.810 --> 00:21:28.310
from our agent was to help you
migrate an old version of Java

00:21:28.310 --> 00:21:30.090
to a new version of Java.

00:21:30.090 --> 00:21:32.430
Now, it goes through
this phase of planning

00:21:32.430 --> 00:21:35.820
out what the migration needs to
look like, then it executes it,

00:21:35.820 --> 00:21:37.410
and then it'll summarize this.

00:21:37.410 --> 00:21:39.240
Now, this doesn't
just work for Java.

00:21:39.240 --> 00:21:43.200
It also works for.NET right
here in Visual Studio.

00:21:43.200 --> 00:21:45.960
So you can see here,
the agent is planning

00:21:45.960 --> 00:21:48.060
out what this upgrade
needs to look like.

00:21:48.060 --> 00:21:51.570
It then starts to
execute the upgrade.

00:21:51.570 --> 00:21:55.050
Now, if it gets stuck, it can
prompt the user, me, for hints,

00:21:55.050 --> 00:21:56.580
and I can take control back.

00:21:56.580 --> 00:21:58.230
It'll learn from my prompts

00:21:58.230 --> 00:22:01.110
so that it doesn't make these
same errors going forward.

00:22:01.110 --> 00:22:03.450
So finally, once Copilot
is actually done,

00:22:03.450 --> 00:22:06.300
it can produce a detailed
summary of what the changes are

00:22:06.300 --> 00:22:08.160
so that I can review
them, and when I'm ready,

00:22:08.160 --> 00:22:11.760
I can commit them, test them,
and push them to production.

00:22:11.760 --> 00:22:14.970
Now, we're taking the same
framework of plan, execute,

00:22:14.970 --> 00:22:18.810
and summarize to help also
modernize mainframe code.

00:22:18.810 --> 00:22:22.230
There are billions of lines of
COBOL running significant parts

00:22:22.230 --> 00:22:24.840
of major companies around
the world, and it's hard

00:22:24.840 --> 00:22:27.720
to know what all of this
code is doing today.

00:22:27.720 --> 00:22:31.500
Now, not only will the agent
help us document what all

00:22:31.500 --> 00:22:34.620
of this code is doing, it
will also help write a set

00:22:34.620 --> 00:22:38.430
of unit tests so that when you
do the upgrade, you will be able

00:22:38.430 --> 00:22:39.630
to test the application

00:22:39.630 --> 00:22:41.880
and making sure it's
working correctly.

00:22:41.880 --> 00:22:43.140
Now, we're still
working on this,

00:22:43.140 --> 00:22:46.110
and this should be
available later this year.

00:22:46.110 --> 00:22:48.660
Now, we have a lot of
customers who are taking

00:22:48.660 --> 00:22:52.020
and getting benefits from
the migration agent here.

00:22:52.020 --> 00:22:54.660
Not only for.NET,
but also for Java.

00:22:54.660 --> 00:22:57.690
They're saving time, and
they're able to move faster.

00:22:57.690 --> 00:23:01.950
Ford was able to also refactor
their RabbitMQ code base

00:23:01.950 --> 00:23:03.990
and upgrade to
Azure Service Bus.

00:23:03.990 --> 00:23:07.740
They did this three times
faster with GitHub Copilot.

00:23:07.740 --> 00:23:10.470
So Jessica, how's it
going over there?

00:23:10.470 --> 00:23:11.280
Jessica Deen: It's going great.

00:23:11.280 --> 00:23:12.600
You want to see
something really cool?

00:23:12.600 --> 00:23:13.680
Jay Parikh: Yeah,
let's check it out.

00:23:13.680 --> 00:23:14.460
Jessica Deen: All right.

00:23:14.460 --> 00:23:16.140
So last week, we were talking

00:23:16.140 --> 00:23:18.900
about adding a virtual
guestbook called Memories

00:23:18.900 --> 00:23:21.660
with an agentic Spotify
integration using Azure AI

00:23:21.660 --> 00:23:22.440
Foundry, right?

00:23:22.440 --> 00:23:22.920
Jay Parikh: Right.

00:23:22.920 --> 00:23:23.400
Jessica Deen: All right.

00:23:23.400 --> 00:23:25.560
I thought this was
going to be super hard.

00:23:25.560 --> 00:23:29.460
It turns out, in agent mode,
everything is possible.

00:23:29.460 --> 00:23:30.360
So look at this.

00:23:30.360 --> 00:23:33.810
I just told Copilot that I want
to get to work on issue 44

00:23:33.810 --> 00:23:35.190
for the memory service.

00:23:35.190 --> 00:23:37.170
Began to have a
normal conversation.

00:23:37.170 --> 00:23:40.230
It went out and got the
issue details from GitHub.

00:23:40.230 --> 00:23:43.260
It started creating all
of these components,

00:23:43.260 --> 00:23:45.840
and it even told me
exactly what it was doing.

00:23:45.840 --> 00:23:48.180
Scrolling down even further,
I told it I wanted to set

00:23:48.180 --> 00:23:51.780
up Azure Cosmos DB, some
Azure Foundry integration,

00:23:51.780 --> 00:23:54.000
and then it continued
with setting all this up.

00:23:54.000 --> 00:23:55.650
Do you want to see
the finished product?

00:23:55.650 --> 00:23:56.498
Jay Parikh: Yeah,
let's check it out.

00:23:56.523 --> 00:23:57.403
Jessica Deen: Do you guys want

00:23:57.428 --> 00:23:58.355
to see the finished product?

00:23:58.356 --> 00:23:59.260
[ Applause ]

00:23:59.285 --> 00:24:01.361
Absolutely. Let's do this.

00:24:01.386 --> 00:24:02.095
All right.

00:24:02.120 --> 00:24:02.670
Here it is.

00:24:02.670 --> 00:24:04.200
It's called The Memories.

00:24:04.200 --> 00:24:05.880
And check this out even more.

00:24:05.880 --> 00:24:07.140
Seth, who you guys met --

00:24:07.140 --> 00:24:07.680
Jay Parikh:
Seth is already here.

00:24:07.680 --> 00:24:09.060
Jessica Deen: He is
so on top of it.

00:24:09.060 --> 00:24:10.710
He was so excited to use it.

00:24:10.710 --> 00:24:13.470
He's already commented,
"This event is awesome."

00:24:13.470 --> 00:24:14.670
And here's what's really cool.

00:24:14.670 --> 00:24:17.970
Because we know we're at Build,
we also have a Windows sound.

00:24:17.970 --> 00:24:18.990
And guess what?

00:24:18.990 --> 00:24:20.280
I believe it really works.

00:24:20.280 --> 00:24:23.310
We can test Copilot's code, but
do you want to do the honors?

00:24:23.310 --> 00:24:24.000
Jay Parikh: No, why don't you?

00:24:24.000 --> 00:24:24.420
Jessica Deen: Okay.

00:24:24.420 --> 00:24:25.440
I'll go ahead and do the honors.

00:24:25.440 --> 00:24:26.310
Everyone ready?

00:24:26.334 --> 00:24:29.443
[ Music ]

00:24:29.468 --> 00:24:31.445
[ Applause ]

00:24:31.470 --> 00:24:32.190
It's pretty awesome.

00:24:32.190 --> 00:24:34.320
Now, what do you think?

00:24:34.320 --> 00:24:35.820
Jay Parikh: That is
excellent, Jessica.

00:24:35.820 --> 00:24:38.010
So thank you for
showing all this off.

00:24:38.010 --> 00:24:38.790
Jessica Deen: You're
very welcome.

00:24:38.790 --> 00:24:40.560
One more thought I did
have is, what do you think

00:24:40.560 --> 00:24:42.630
about dropping the "The"?

00:24:42.630 --> 00:24:43.830
Jay Parikh: You should probably
just call it Memories.

00:24:43.830 --> 00:24:44.811
Jessica Deen: I
think it's cleaner.

00:24:44.836 --> 00:24:45.424
All right.

00:24:45.449 --> 00:24:45.930
Jay Parikh: All right.

00:24:45.930 --> 00:24:47.100
Thank you, Jessica.

00:24:47.100 --> 00:24:47.670
Great job.

00:24:47.670 --> 00:24:48.459
Jessica Deen: Thank you.

00:24:48.484 --> 00:24:53.075
[ Applause ]

00:24:53.100 --> 00:24:53.640
Jay Parikh: Okay.

00:24:53.640 --> 00:24:56.640
So that's just a glimpse
of what we're doing

00:24:56.640 --> 00:25:00.630
to reimagine this end-to-end
development process.

00:25:00.630 --> 00:25:04.080
We're focused on every
phase of this plan,

00:25:04.080 --> 00:25:06.330
create, and operate cycle.

00:25:06.330 --> 00:25:10.620
Not only are you going to
have a set of AI-driven tools

00:25:10.620 --> 00:25:13.380
to help you move faster
in your own work,

00:25:13.380 --> 00:25:16.500
but you will have a team
of these always-on agents

00:25:16.500 --> 00:25:18.930
that you're going to be
able to orchestrate.

00:25:18.930 --> 00:25:22.230
Now, best of all, we want
to do this and optimize

00:25:22.230 --> 00:25:23.910
for openness and choice.

00:25:23.910 --> 00:25:26.340
You all saw the
announcement yesterday

00:25:26.340 --> 00:25:30.450
where we're open-sourcing
Copilot extension in VS Code.

00:25:30.450 --> 00:25:33.870
Now, I'm super excited about
this because I spent a lot

00:25:33.870 --> 00:25:35.520
of time in my career helping

00:25:35.520 --> 00:25:37.950
to drive different
open-source efforts,

00:25:37.950 --> 00:25:39.870
both software and hardware.

00:25:39.870 --> 00:25:42.060
And I know what a
great community can do

00:25:42.060 --> 00:25:44.970
to accelerate adoption
of new technology

00:25:44.970 --> 00:25:47.100
and to drive innovation forward.

00:25:47.100 --> 00:25:50.670
So yesterday, we also saw and we
announced that we are working

00:25:50.670 --> 00:25:54.360
with OpenAI to integrate
the Codex agent directly

00:25:54.360 --> 00:25:56.010
into the GitHub platform.

00:25:56.010 --> 00:26:00.360
And today, I'm actually excited
to announce that we are working

00:26:00.360 --> 00:26:03.750
with Anthropic to integrate
cloud code directly

00:26:03.750 --> 00:26:05.670
into the GitHub
platform as well.

00:26:05.670 --> 00:26:11.460
[ Applause ]

00:26:11.460 --> 00:26:14.880
So think of GitHub as the
organizing layer for your teams

00:26:14.880 --> 00:26:18.030
of always-on agents --
all of your SUI agents,

00:26:18.030 --> 00:26:20.760
all of your SRE agents
and any other agents

00:26:20.760 --> 00:26:22.230
that you might be using.

00:26:22.230 --> 00:26:25.920
It will be the platform where
you orchestrate intelligence

00:26:25.920 --> 00:26:28.950
across the entire
software life cycle.

00:26:28.950 --> 00:26:30.930
Now it's the perfect
place to do this

00:26:30.930 --> 00:26:33.480
because GitHub has
valuable context,

00:26:33.480 --> 00:26:35.580
and it has the right
security measures.

00:26:35.580 --> 00:26:37.500
Your agents can
operate effectively,

00:26:37.500 --> 00:26:40.620
efficiently, and securely.

00:26:40.620 --> 00:26:43.530
Openness and choice, that's
what all developers want,

00:26:43.530 --> 00:26:45.990
and that's what we're
going to deliver.

00:26:45.990 --> 00:26:49.380
Now, to wrap up this section,
I want to highlight a lot

00:26:49.380 --> 00:26:51.510
of customers here that
are getting benefits

00:26:51.510 --> 00:26:53.370
from using GitHub Copilot.

00:26:53.370 --> 00:26:58.380
Now, I especially like what
the team at Ramp is doing.

00:26:58.380 --> 00:27:00.240
Ramp is using
Copilot to integrate

00:27:00.240 --> 00:27:01.680
in their development lifecycle,

00:27:01.680 --> 00:27:05.910
and they are saving roughly
30,000 hours per month

00:27:05.910 --> 00:27:09.090
of manual work so that
they can ship faster

00:27:09.090 --> 00:27:11.940
and have fewer blockers as
they continue to innovate

00:27:11.940 --> 00:27:13.500
and build their product.

00:27:13.500 --> 00:27:15.240
Now, I also want
to have you hear

00:27:15.240 --> 00:27:18.150
from our partner
at Cathay Pacific.

00:27:18.150 --> 00:27:20.885
[ Music ]

00:27:20.910 --> 00:27:22.770
Lawrence Fong: Cathay Pacific
is the largest airline

00:27:22.770 --> 00:27:28.410
of Hong Kong and serves over 90
global destinations and a team

00:27:28.410 --> 00:27:33.090
of 30,000 people, including
over 1,000 software developers.

00:27:33.090 --> 00:27:36.840
Building and maintaining
software is mission critical.

00:27:36.840 --> 00:27:39.480
With GitHub Copilot
and agent mode,

00:27:39.480 --> 00:27:44.100
we are able to save developer
time and increase productivity.

00:27:44.100 --> 00:27:46.410
Rajeev Nair: To me, it is
more than just a tool.

00:27:46.410 --> 00:27:49.140
It feels like a
collaborative partner.

00:27:49.140 --> 00:27:51.900
Naveen Jaisankar: GitHub Copilot
helps us to shift faster.

00:27:51.900 --> 00:27:54.000
I mean, agent mode is
really useful, right?

00:27:54.000 --> 00:27:56.520
With the multi-modal
features that we have,

00:27:56.520 --> 00:27:59.070
it gives you a flexibility
on how you are going to use

00:27:59.070 --> 00:28:01.320
that agent mode in a better way.

00:28:01.320 --> 00:28:01.860
Lawrence Fong: Innovation

00:28:01.860 --> 00:28:05.045
at Cathay is taking off
with GitHub Copilot.

00:28:05.070 --> 00:28:08.611
[ Music ]

00:28:08.635 --> 00:28:11.015
[ Applause ]

00:28:11.040 --> 00:28:13.560
Jay Parikh: It's great to see
how they're saving so much time

00:28:13.560 --> 00:28:16.020
and bringing joy back to
their development teams.

00:28:16.020 --> 00:28:20.100
Okay, so let's shift from
AI-powered tools to the platform

00:28:20.100 --> 00:28:23.430
that powers your AI
applications and agents.

00:28:23.430 --> 00:28:27.900
Building an AI-driven product
today requires an entirely new

00:28:27.900 --> 00:28:31.680
set of infrastructure,
systems, services, and tools.

00:28:31.680 --> 00:28:33.870
And that's where
Foundry comes in.

00:28:33.870 --> 00:28:38.310
Foundry is the AI app
in Agent Factory.

00:28:38.310 --> 00:28:40.290
Now, a bit of a side note here.

00:28:40.290 --> 00:28:43.380
Earlier this year, I was sharing
our vision for Agent Factory

00:28:43.380 --> 00:28:46.290
with Bill, and he lit
up with excitement.

00:28:46.290 --> 00:28:48.060
He shared with me that when he

00:28:48.060 --> 00:28:51.930
and Paul started Microsoft
50 years ago, the vision was

00:28:51.930 --> 00:28:54.240
to create a software factory.

00:28:54.240 --> 00:28:57.750
It was a company built around
smart programmers capable

00:28:57.750 --> 00:29:00.210
of developing a broad
range of software,

00:29:00.210 --> 00:29:03.480
from tools to applications
to operating systems.

00:29:03.480 --> 00:29:06.240
This was unlike many other
companies at the time

00:29:06.240 --> 00:29:09.150
that were focused on
single-purpose applications.

00:29:09.150 --> 00:29:12.390
We're taking the same approach
as we build out Foundry.

00:29:12.390 --> 00:29:15.030
We're building a full-stack
platform for all

00:29:15.030 --> 00:29:18.060
of your AI applications
and agents.

00:29:18.060 --> 00:29:19.050
So it's pretty awesome

00:29:19.050 --> 00:29:22.260
to see the parallel
here 50 years later.

00:29:22.260 --> 00:29:25.470
Now, we announced Foundry
last fall at Ignite,

00:29:25.470 --> 00:29:26.910
and we've been working really,

00:29:26.910 --> 00:29:29.400
really hard to ship
features quickly.

00:29:29.400 --> 00:29:31.350
Now, as Satya
mentioned yesterday,

00:29:31.350 --> 00:29:34.920
more than 70,000 organizations
today use Foundry.

00:29:34.920 --> 00:29:38.190
We ship so many things it's
impossible to cover them.

00:29:38.190 --> 00:29:41.610
And I really hope you take
some time to go play with all

00:29:41.610 --> 00:29:44.910
of the new features and try them
out and see what you can build.

00:29:44.910 --> 00:29:48.090
Now, we're using Foundry
ourselves internally as well,

00:29:48.090 --> 00:29:50.040
and you're going to hear
from Charles in a little bit

00:29:50.040 --> 00:29:53.160
about M365 and Copilot
Studio as well,

00:29:53.160 --> 00:29:56.130
and both of those actually
leverage Foundry.

00:29:56.130 --> 00:29:58.410
I'm not going to have
time to cover everything,

00:29:58.410 --> 00:30:02.790
but I want to jump into three
main areas of Foundry here.

00:30:02.790 --> 00:30:05.760
Today, we're going to
cover models and agents,

00:30:05.760 --> 00:30:08.460
and there's a lot
actually to go explore

00:30:08.460 --> 00:30:10.770
in knowledge or data as well.

00:30:10.770 --> 00:30:13.890
So here's a couple of things
that are really, really exciting

00:30:13.890 --> 00:30:16.260
to help you understand
how to use these models

00:30:16.260 --> 00:30:18.210
in very sophisticated ways.

00:30:18.210 --> 00:30:20.250
First of all, we have
this new leaderboard,

00:30:20.250 --> 00:30:22.440
which will help you pick models.

00:30:22.440 --> 00:30:26.010
Second, we've actually done an
integration with Hugging Face

00:30:26.010 --> 00:30:30.270
so that you get access to
11,000 more models in addition

00:30:30.270 --> 00:30:33.720
to the 1,900 models that
are in the catalog today.

00:30:33.720 --> 00:30:36.330
And then we also commit
to same-time access.

00:30:36.330 --> 00:30:39.840
So as OpenAI releases the
newest, latest, greatest models,

00:30:39.840 --> 00:30:42.990
you will have them accessible
in Foundry as well.

00:30:42.990 --> 00:30:44.430
We've added a model router,

00:30:44.430 --> 00:30:46.440
which will help you
select the best model

00:30:46.440 --> 00:30:48.840
for your prompt in real time.

00:30:48.840 --> 00:30:51.480
And then there's an
integration using MCP

00:30:51.480 --> 00:30:53.640
into Azure API
Management Service.

00:30:53.640 --> 00:30:56.400
So whatever APIs you've
built in your enterprise,

00:30:56.400 --> 00:31:02.010
you can access them via an agent
or an AI application via MCP.

00:31:02.010 --> 00:31:05.520
As you saw earlier, the GitHub
VS Code integration is there,

00:31:05.520 --> 00:31:09.060
and it's used by 100
million-plus developers.

00:31:09.060 --> 00:31:12.510
We also have a GitHub
Models tab to test

00:31:12.510 --> 00:31:14.400
out your prompts right there.

00:31:14.400 --> 00:31:18.240
And then also a very rich
set of functionality

00:31:18.240 --> 00:31:21.270
to help you customize your
models and bring your own data

00:31:21.270 --> 00:31:24.690
to do whatever you need to do
for your specific use case.

00:31:24.690 --> 00:31:27.390
And finally, we have a
distillation capability

00:31:27.390 --> 00:31:29.850
that will allow you
to take a big model,

00:31:29.850 --> 00:31:32.790
break it down to a smaller
model, so that you can optimize

00:31:32.790 --> 00:31:35.310
for cost and for performance.

00:31:35.310 --> 00:31:38.220
Now, a wide variety of
organizations are already using

00:31:38.220 --> 00:31:40.710
and taking advantage
of these capabilities.

00:31:40.710 --> 00:31:42.990
One example here is
the Indiana Pacers.

00:31:42.990 --> 00:31:46.650
They've built an in-arena,
real-time captioning system.

00:31:46.650 --> 00:31:49.110
And using Foundry, they are
able to get the error rate

00:31:49.110 --> 00:31:51.900
down to just about 1%.

00:31:51.900 --> 00:31:55.140
So let's hear from our
next customer here, Manus,

00:31:55.140 --> 00:31:57.764
on what they're doing
to build with Foundry.

00:31:57.789 --> 00:31:58.710
[ Music ]

00:31:58.710 --> 00:32:01.200
Tao Cheung: Think of Manus
not as a chat interface,

00:32:01.200 --> 00:32:04.410
but as the world's first,
self-driving digital operator.

00:32:04.410 --> 00:32:07.350
An agent defined by
action, not advice.

00:32:07.350 --> 00:32:10.800
It doesn't wait, it
senses, then executes.

00:32:10.800 --> 00:32:15.090
Powered by Azure AI Foundry,
Manus is fast, secure,

00:32:15.090 --> 00:32:18.840
and scales for even the
most demanding use cases.

00:32:18.840 --> 00:32:22.680
From campaign artwork to deep
research and custom code,

00:32:22.680 --> 00:32:24.690
it delivers with precision.

00:32:24.690 --> 00:32:26.880
With Azure AI Foundry
under the hood,

00:32:26.880 --> 00:32:28.680
we are not just
imagining the future

00:32:28.680 --> 00:32:30.930
of agentic AI, we
are building it.

00:32:30.930 --> 00:32:31.170
[ Music ]

00:32:33.177 --> 00:32:37.355
[ Applause ]

00:32:37.380 --> 00:32:39.420
Jay Parikh: I love what the
team at Manus is building.

00:32:39.420 --> 00:32:40.680
It's really interesting stuff.

00:32:40.680 --> 00:32:41.910
You should check it out.

00:32:41.910 --> 00:32:46.170
So now onto the other core
area of Foundry: agents.

00:32:46.170 --> 00:32:48.900
We're seeing a lot of customers
build agents of all types

00:32:48.900 --> 00:32:53.130
to power their business and move
forward in this new AI era.

00:32:53.130 --> 00:32:57.210
Foundry gives you a complete
stack of agent capabilities.

00:32:57.210 --> 00:33:00.600
Let me highlight a few key
services that we've been talking

00:33:00.600 --> 00:33:03.870
about this week that can extend
Foundry so that you can provide

00:33:03.870 --> 00:33:06.270
and build a richer
set of agents.

00:33:06.270 --> 00:33:07.950
First up, Agent Service.

00:33:07.950 --> 00:33:10.410
Agent Service allows
you to create, deploy,

00:33:10.410 --> 00:33:13.530
and monitor agents
at enterprise scale.

00:33:13.530 --> 00:33:15.600
Second is agent catalog.

00:33:15.600 --> 00:33:18.120
It provides a starter
set of templates.

00:33:18.120 --> 00:33:21.030
So if you want to get started
at building an agent,

00:33:21.030 --> 00:33:23.430
you can jump right into the
catalog, use a template,

00:33:23.430 --> 00:33:27.840
use a recipe, and start to build
an agent and iterate from there.

00:33:27.840 --> 00:33:30.780
Agent knowledge allows you
to bring data from Fabric

00:33:30.780 --> 00:33:34.350
or from Databricks or from
SharePoint and put that together

00:33:34.350 --> 00:33:36.720
with your agent so
your agent can produce

00:33:36.720 --> 00:33:40.380
or perform more
sophisticated tasks.

00:33:40.380 --> 00:33:42.180
Next up, we have agent tools.

00:33:42.180 --> 00:33:47.370
So we support frameworks such as
MCP and A2A, and you have access

00:33:47.370 --> 00:33:50.940
to 14,000-plus services
using those frameworks.

00:33:50.940 --> 00:33:54.150
Now, we have also frameworks
that will allow you

00:33:54.150 --> 00:33:56.640
to build multi-agent workflows.

00:33:56.640 --> 00:33:59.400
So you can build very,
very complex workflows,

00:33:59.400 --> 00:34:02.070
automate decision-making
in a cohesive

00:34:02.070 --> 00:34:04.500
and intelligent workforce.

00:34:04.500 --> 00:34:07.890
Let's take a look at how easy
it is to build an example

00:34:07.890 --> 00:34:10.410
of a multi-agent
system with Foundry.

00:34:10.410 --> 00:34:14.510
Please welcome Amanda and
Elijah to walk us through this.

00:34:14.510 --> 00:34:20.345
[ Applause ]

00:34:20.370 --> 00:34:21.270
Amanda Foster: What better way

00:34:21.270 --> 00:34:23.730
to showcase our
Foundry Agent Factory

00:34:23.730 --> 00:34:25.440
than by demonstrating it live,

00:34:25.440 --> 00:34:27.150
then taking you behind
the scenes with us

00:34:27.150 --> 00:34:29.010
to show you how we
built the agent

00:34:29.010 --> 00:34:30.950
and ensure they're
safe and secure?

00:34:30.950 --> 00:34:33.860
Before we jump into our
multi-agent application,

00:34:33.860 --> 00:34:37.310
let's first build a single
agent together using Azure AI

00:34:37.310 --> 00:34:38.640
Foundry Portal.

00:34:38.640 --> 00:34:40.320
Meet our RSVP agent.

00:34:40.320 --> 00:34:41.790
Here's how we'll build it.

00:34:41.790 --> 00:34:43.650
First, we're going
to give it a model.

00:34:43.650 --> 00:34:46.020
Here we're using GPT-4o.

00:34:46.020 --> 00:34:48.090
Next, we're going to give
it a set of instructions.

00:34:48.090 --> 00:34:50.790
And finally, we're going
to configure some tools.

00:34:50.790 --> 00:34:52.920
Here, we're going to use
the file search tool

00:34:52.920 --> 00:34:55.170
to manage my invite list as well

00:34:55.170 --> 00:34:58.410
as the create calendar
event open API tool,

00:34:58.410 --> 00:35:00.390
which will call
an Azure Logic app

00:35:00.390 --> 00:35:02.790
to create a calendar
event on my behalf.

00:35:02.790 --> 00:35:06.690
But now let's see
this agent in action.

00:35:06.690 --> 00:35:10.740
Right now, I'm going to ask
it to create a calendar event

00:35:10.740 --> 00:35:13.740
for today actually called
"Post-Build After Party",

00:35:13.740 --> 00:35:15.810
and I'm inviting Elijah.

00:35:15.810 --> 00:35:16.470
Elijah Straight: Oh, sweet.

00:35:16.470 --> 00:35:19.980
I'm excited for
this after party.

00:35:19.980 --> 00:35:20.910
And what's it doing
right now, Amanda?

00:35:20.910 --> 00:35:22.920
Amanda Foster: As you
can see, in a moment,

00:35:22.920 --> 00:35:25.350
it will start using
its configuration,

00:35:25.350 --> 00:35:28.680
which we just did together, to
make the correct tool calls

00:35:28.680 --> 00:35:33.030
and then eventually create the
calendar event on my behalf.

00:35:33.030 --> 00:35:33.660
Elijah Straight: Awesome.

00:35:33.660 --> 00:35:35.610
So now, moment of truth.

00:35:35.610 --> 00:35:37.350
Let's pull up my calendar.

00:35:37.350 --> 00:35:42.390
And you guys can see I got a
really busy day here today.

00:35:42.390 --> 00:35:43.800
And there it is.

00:35:43.800 --> 00:35:44.880
It showed up in my calendar.

00:35:44.880 --> 00:35:48.090
Thanks so much, Amanda,
for the sweet invite.

00:35:48.090 --> 00:35:48.990
So that was great.

00:35:48.990 --> 00:35:50.910
But now let's jump
into the code.

00:35:50.910 --> 00:35:53.310
So I'm jumping into VS
Code, and you can see here

00:35:53.310 --> 00:35:56.250
that I have the Azure AI
Foundry extension installed.

00:35:56.250 --> 00:35:59.160
This extension is great because
we can see the models, agents,

00:35:59.160 --> 00:36:02.060
and threads that are
associated with our project.

00:36:02.060 --> 00:36:04.220
I want to take a moment
to zoom in on Threads

00:36:04.220 --> 00:36:08.090
because transparency is a key
part of agentic workflows.

00:36:08.090 --> 00:36:11.030
And through Threads, we can see
each step the agent is taking

00:36:11.030 --> 00:36:11.870
along the way.

00:36:11.870 --> 00:36:14.450
So here we can actually
see what Amanda just said,

00:36:14.450 --> 00:36:16.350
as well as the agent's response,

00:36:16.350 --> 00:36:18.570
as well as more in-depth
details, like the number

00:36:18.570 --> 00:36:19.920
of tokens that were used,

00:36:19.920 --> 00:36:22.310
as well as the tools
that were invoked.

00:36:22.310 --> 00:36:23.600
Pretty cool, huh, Amanda?

00:36:23.600 --> 00:36:23.990
Amanda Foster: Yeah.

00:36:23.990 --> 00:36:26.510
Elijah, but where is
this Thread data stored?

00:36:26.510 --> 00:36:27.980
Elijah Straight: That's
a great question.

00:36:27.980 --> 00:36:29.510
Developers actually
have the ability

00:36:29.510 --> 00:36:30.890
to use managed resources,

00:36:30.890 --> 00:36:34.080
but I actually today have
them in my own Cosmos DB.

00:36:34.080 --> 00:36:36.570
What's great also is that
we could use the data

00:36:36.570 --> 00:36:40.530
in Microsoft Fabric and Azure
Databricks to power our agents.

00:36:40.530 --> 00:36:42.420
And so, yeah, we can see here.

00:36:42.420 --> 00:36:44.160
It's also, we're very excited

00:36:44.160 --> 00:36:47.160
that Cosmos DB is now
available in Microsoft Fabric.

00:36:47.160 --> 00:36:48.360
So that's great.

00:36:48.360 --> 00:36:49.680
Now, let's jump
back into the code

00:36:49.680 --> 00:36:52.260
to see how we can actually
build our Foundry agent.

00:36:52.260 --> 00:36:53.790
So I'm going to go
here into this file,

00:36:53.790 --> 00:36:57.030
and you can see we're using
the Foundry agent service SDK

00:36:57.030 --> 00:36:59.340
to be able to initiate
our agent client.

00:36:59.340 --> 00:37:02.430
Then from there, we're going to
attach the file search tool.

00:37:02.430 --> 00:37:04.110
What's important to
note here, though,

00:37:04.110 --> 00:37:06.270
is that even though I'm using
the file search tool today,

00:37:06.270 --> 00:37:09.870
we could use a variety of
tools, including external APIs,

00:37:09.870 --> 00:37:12.300
MCP or model context
protocol servers,

00:37:12.300 --> 00:37:16.440
or even other agents using the
Foundry connected agent tool.

00:37:16.440 --> 00:37:17.220
Pretty cool stuff.

00:37:17.220 --> 00:37:19.710
And then you can see here I'm
giving it a model as well

00:37:19.710 --> 00:37:21.540
as a name and the system prompt.

00:37:21.540 --> 00:37:22.320
That's great.

00:37:22.320 --> 00:37:24.600
Now let's see how we
execute our agent.

00:37:24.600 --> 00:37:25.740
So I'm going to go in here.

00:37:25.740 --> 00:37:28.920
You can see I'm executing
it using the Foundry agent

00:37:28.920 --> 00:37:30.900
service SDK.

00:37:30.900 --> 00:37:32.010
But what's also
important to know is

00:37:32.010 --> 00:37:35.370
that we're using Foundry agents
today, but we could use any kind

00:37:35.370 --> 00:37:37.980
of agent, including
CrewAI, LangChain,

00:37:37.980 --> 00:37:42.420
or even multiple agents using
agent-to-agent or A2A protocol.

00:37:42.420 --> 00:37:43.860
Pretty cool stuff.

00:37:43.860 --> 00:37:46.980
So this is awesome, but now
let's see our agents in action.

00:37:46.980 --> 00:37:49.080
Amanda, do you want to
show them what we built?

00:37:49.080 --> 00:37:49.890
Amanda Foster: Yeah.

00:37:49.890 --> 00:37:52.080
Now let's dive into
the application.

00:37:52.080 --> 00:37:55.680
Build Events is a multi-agent
event planner application

00:37:55.680 --> 00:37:58.710
powered by a voice-controlled
agentic orchestrator,

00:37:58.710 --> 00:38:02.280
which will delegate tasks, or
"tool calls" as we call them,

00:38:02.280 --> 00:38:05.730
to our sub-agents we built using
the Foundry agent service.

00:38:05.730 --> 00:38:08.190
Together, we just
built our RSVP agent,

00:38:08.190 --> 00:38:10.260
but now let me
show you the power

00:38:10.260 --> 00:38:14.320
of multiple agents working
together in one experience.

00:38:21.410 --> 00:38:23.270
Computer Voice: Hello,
how can I assist you

00:38:23.270 --> 00:38:25.650
with your event
planning needs today?

00:38:25.650 --> 00:38:28.080
Amanda Foster: Hi, I'd like
help planning a hackathon

00:38:28.080 --> 00:38:31.650
in San Francisco
on May 22, 2025.

00:38:31.650 --> 00:38:36.210
My budget is $15,000, and I'm
expecting around 200 attendees.

00:38:36.210 --> 00:38:39.360
The event will be from 5
to 10 p.m. Pacific time.

00:38:39.360 --> 00:38:42.400
Could you please help
me find an event venue?

00:38:44.190 --> 00:38:46.830
Computer Voice: I'm searching
for a venue in San Francisco

00:38:46.830 --> 00:38:51.390
to host your -- sure, I
can assist with that.

00:38:51.390 --> 00:38:54.570
Would you like help with
creating invitations or setting

00:38:54.570 --> 00:38:57.030
up an RSVP system
for the hackathon?

00:38:57.030 --> 00:38:58.860
Amanda Foster: As you can see,
our first agent is now hard

00:38:58.860 --> 00:39:01.770
at work, which will help
me find an event venue.

00:39:01.770 --> 00:39:03.270
Computer Voice: Here
are some venue options

00:39:03.270 --> 00:39:05.790
in San Francisco
for your hackathon.

00:39:05.790 --> 00:39:07.650
One, the Fillmore.

00:39:07.650 --> 00:39:09.450
Capacity up to 1,000 guests.

00:39:09.450 --> 00:39:10.920
Amanda Foster: Hey,
this looks great.

00:39:10.920 --> 00:39:12.450
Could we go with the Fillmore?

00:39:12.450 --> 00:39:15.510
Could you now create the
calendar event and send

00:39:15.510 --> 00:39:18.700
out my invites to
my invite list?

00:39:20.180 --> 00:39:21.200
Computer Voice:
I'm in the process

00:39:21.200 --> 00:39:24.470
of creating the calendar
event for the hackathon

00:39:24.470 --> 00:39:27.260
at the Fillmore and
sending out the invites

00:39:27.260 --> 00:39:29.750
to your existing invite list.

00:39:29.750 --> 00:39:32.130
I'll update you once it's done.

00:39:32.130 --> 00:39:35.130
Is there anything you'd like
to arrange for the hackathon?

00:39:35.130 --> 00:39:36.750
The hackathon event --

00:39:36.750 --> 00:39:37.200
Amanda Foster: Yes.

00:39:37.200 --> 00:39:39.420
Now I'd like your help
generating an image

00:39:39.420 --> 00:39:42.120
to promote my event on LinkedIn,

00:39:42.120 --> 00:39:43.800
as well as drafting
some content.

00:39:43.800 --> 00:39:46.260
I'd like you to make the
image convey excitement,

00:39:46.260 --> 00:39:50.650
but other than that, take full
creative liberty on both tasks.

00:39:53.340 --> 00:39:56.550
Computer Voice: I'm working on
generating an exciting image

00:39:56.550 --> 00:40:00.960
and drafting content to promote
your hackathon on LinkedIn.

00:40:00.960 --> 00:40:02.910
I'll have them ready shortly.

00:40:02.910 --> 00:40:07.260
Is there anything specific you'd
like to include in the post?

00:40:07.260 --> 00:40:08.070
Amanda Foster: As you can see,

00:40:08.070 --> 00:40:11.610
now two Foundry agents have been
kicked off at the same time,

00:40:11.610 --> 00:40:15.090
working simultaneously to help
me get my LinkedIn post ready.

00:40:15.090 --> 00:40:16.080
The first one finished.

00:40:16.080 --> 00:40:22.220
And here is the draft we
have for the LinkedIn post.

00:40:22.220 --> 00:40:25.580
And here is the image.

00:40:25.580 --> 00:40:27.590
Hi, this looks great.

00:40:27.590 --> 00:40:32.070
Could you now post both the
image and the draft to LinkedIn?

00:40:36.030 --> 00:40:37.500
Computer Voice: I'm
posting the image

00:40:37.500 --> 00:40:39.930
and draft to LinkedIn now.

00:40:39.930 --> 00:40:42.750
I'll let you know
once it's live.

00:40:42.750 --> 00:40:45.270
Amanda Foster: So now our final
agent has been kicked off,

00:40:45.270 --> 00:40:48.120
and it will give
the response back

00:40:48.120 --> 00:40:49.890
and tell us the
status of our post.

00:40:49.890 --> 00:40:52.630
So moment of truth.

00:40:54.270 --> 00:40:55.720
Elijah Straight: Dum-da-da-dum.

00:40:56.850 --> 00:40:59.650
Getting it there.

00:41:03.960 --> 00:41:06.180
And this is a live demo,
so it may take a second.

00:41:06.180 --> 00:41:06.240
Amanda Foster: Yeah,

00:41:06.240 --> 00:41:09.870
everything is happening
live, so that is why --

00:41:09.870 --> 00:41:11.400
Computer Voice: The
LinkedIn post has been

00:41:11.400 --> 00:41:13.170
successfully published.

00:41:13.170 --> 00:41:15.180
Amanda Foster: Okay, now
let's go to LinkedIn.

00:41:15.180 --> 00:41:17.400
And, again, this is live,

00:41:17.400 --> 00:41:20.652
so we're making sure
everything went through.

00:41:20.677 --> 00:41:21.600
Elijah Straight: There it is.

00:41:21.600 --> 00:41:24.330
Amanda Foster: And as you can
see, the post is now live.

00:41:24.330 --> 00:41:27.240
Check out our Build Events
by Contoso page after this

00:41:27.240 --> 00:41:29.190
if you want to see my practice.

00:41:29.190 --> 00:41:32.850
Now, Elijah is going to show us
how we ensure our agents are

00:41:32.850 --> 00:41:35.610
always doing as we
program them to do.

00:41:35.610 --> 00:41:37.080
Elijah Straight:
Amanda, that was great.

00:41:37.080 --> 00:41:39.870
And you guys are all invited
to our hackathon coming up.

00:41:39.870 --> 00:41:41.820
So now that we know our
agents are up and running,

00:41:41.820 --> 00:41:43.410
it's also crucial to make sure

00:41:43.410 --> 00:41:45.900
that they're delivering
high-quality results.

00:41:45.900 --> 00:41:46.830
And in order to do that,

00:41:46.830 --> 00:41:50.310
we've integrated the Azure
AI Evaluation SDK directly

00:41:50.310 --> 00:41:53.090
into our CICD pipeline
with GitHub Actions.

00:41:53.090 --> 00:41:56.270
And what's actually even more
exciting is, using GitHub Models,

00:41:56.270 --> 00:41:59.480
which Jessica presented
earlier, we generated a summary

00:41:59.480 --> 00:42:01.220
of all the evals that
we're running here.

00:42:01.220 --> 00:42:02.660
So we can see that right here,

00:42:02.660 --> 00:42:06.500
which enhances our overall
DevOps experience.

00:42:06.500 --> 00:42:08.270
And then you can see,
here are our agents

00:42:08.270 --> 00:42:11.210
that we're evaluating, as
well as operational metrics,

00:42:11.210 --> 00:42:13.970
doing pretty well, and then
some AI quality metrics.

00:42:13.970 --> 00:42:15.560
And it looks like, Amanda,
we've got to do some work

00:42:15.560 --> 00:42:18.060
to improve the AI quality.

00:42:18.060 --> 00:42:22.350
So today, you've seen how to
create, use, and evaluate agents

00:42:22.350 --> 00:42:24.750
with the Azure AI
Agent Foundry service.

00:42:24.750 --> 00:42:27.630
Amanda and I actually have a
breakout session today at 4:30,

00:42:27.630 --> 00:42:29.520
where we'll be taking
an even deeper dive

00:42:29.520 --> 00:42:31.230
on the app you saw here today.

00:42:31.230 --> 00:42:33.480
We're super excited to
see what you build.

00:42:33.480 --> 00:42:35.820
And with that, Jay, we'll
kick it back to you.

00:42:35.820 --> 00:42:36.450
Thank you, guys.

00:42:36.450 --> 00:42:37.660
[ Applause ]

00:42:40.950 --> 00:42:41.790
Jay Parikh: Thank you, Amanda.

00:42:41.790 --> 00:42:42.930
Thank you, Elijah.

00:42:42.930 --> 00:42:46.110
Love the capabilities you
are building for developers.

00:42:46.110 --> 00:42:49.890
So let's fast forward just a
couple of days and pretend

00:42:49.890 --> 00:42:52.620
that this hackathon happened
and it went really well.

00:42:52.620 --> 00:42:55.230
But now I want to dig into
the data about the event.

00:42:55.230 --> 00:42:57.750
So I want to bring on
Patrick to show us how.

00:42:57.750 --> 00:43:01.560
[ Applause ]

00:43:01.560 --> 00:43:02.550
PATRICK LeBLANC: What's up, Jay?

00:43:02.550 --> 00:43:03.450
Jay Parikh: How are you?

00:43:03.450 --> 00:43:04.650
PATRICK LeBLANC: How's it going?

00:43:04.650 --> 00:43:05.130
All right.

00:43:05.130 --> 00:43:08.430
So the event team,
they want to search.

00:43:08.430 --> 00:43:10.800
They want to do a better
search on their app, okay?

00:43:10.800 --> 00:43:12.770
And so they came to me and
they were like, "Patrick,

00:43:12.770 --> 00:43:15.260
we want to look for
presenters that are good

00:43:15.260 --> 00:43:17.670
at live demos," like us, right?

00:43:17.670 --> 00:43:21.150
"and that are good
with Gen AI and data."

00:43:21.150 --> 00:43:22.530
And I'm like, "All
right, I could do that.

00:43:22.530 --> 00:43:23.310
Let me see what you got."

00:43:23.310 --> 00:43:26.220
So they show me this app and
they say, "Oh, by the way,

00:43:26.220 --> 00:43:28.830
we're only using a vector
search and a keyword search."

00:43:28.830 --> 00:43:33.150
And I thought, "Wow, like
1900s again.", right?

00:43:33.150 --> 00:43:34.860
But let's switch this up.

00:43:34.860 --> 00:43:35.730
Jay Parikh: Maybe
we can do better.

00:43:35.730 --> 00:43:36.360
PATRICK LeBLANC:
We can do better.

00:43:36.360 --> 00:43:37.710
There's a new hope.

00:43:37.710 --> 00:43:41.070
We can use semantic
operators in PostgreSQL.

00:43:41.070 --> 00:43:41.370
Jay Parikh: Wow.

00:43:41.370 --> 00:43:42.240
PATRICK LeBLANC:
Not only, right?

00:43:42.240 --> 00:43:44.100
I'm going to amp this
search up a little bit.

00:43:44.100 --> 00:43:45.030
And I click "Search".

00:43:45.030 --> 00:43:46.830
And what you're going to
see is that it narrows it

00:43:46.830 --> 00:43:50.850
down just some very specific
speakers, including myself, Jay.

00:43:50.850 --> 00:43:52.380
Including myself, right?

00:43:52.380 --> 00:43:54.690
But you may be
thinking, "Hey, how?

00:43:54.690 --> 00:43:55.500
How did you do this?"

00:43:55.500 --> 00:43:56.820
So enough of all this talking.

00:43:56.820 --> 00:43:58.680
Let's head over to VS Code.

00:43:58.680 --> 00:44:00.780
So we're going to
head over to VS Code.

00:44:00.780 --> 00:44:03.900
And I'm going to introduce you
to these semantic operators.

00:44:03.900 --> 00:44:06.420
And the first one I'm going to
show you is the AI generate.

00:44:06.420 --> 00:44:08.880
And so basically I'm going
to pass the events in

00:44:08.880 --> 00:44:11.340
and it creates a description
for all my events.

00:44:11.340 --> 00:44:12.540
I don't have to do anything.

00:44:12.540 --> 00:44:13.215
It just works for me.

00:44:13.240 --> 00:44:13.830
Jay Parikh: That's easy.

00:44:13.830 --> 00:44:14.370
PATRICK LeBLANC: Okay?

00:44:14.395 --> 00:44:15.064
It's easy.

00:44:15.089 --> 00:44:17.430
But let's take a look at
a query that resembles

00:44:17.430 --> 00:44:19.980
or reflects what we
did behind the scenes.

00:44:19.980 --> 00:44:22.710
And so the first part
of our query, we used --

00:44:22.710 --> 00:44:24.390
we did go back to the 1900s.

00:44:24.390 --> 00:44:27.060
We used a vector search
and a keyword search

00:44:27.060 --> 00:44:29.580
to handle the GenAI
and the data part.

00:44:29.580 --> 00:44:33.960
But then we used a semantic
join down here in our view

00:44:33.960 --> 00:44:37.080
to handle the live
and the good part.

00:44:37.080 --> 00:44:38.250
And then you can see right here,

00:44:38.250 --> 00:44:40.860
it returned the exact same
speakers you saw on that page.

00:44:40.860 --> 00:44:41.400
Jay Parikh: That's excellent.

00:44:41.400 --> 00:44:42.300
PATRICK LeBLANC: That's
excellent, right?

00:44:42.300 --> 00:44:45.720
And so you heard Amanda
and Elijah say that, "Hey,

00:44:45.720 --> 00:44:50.070
we're storing all of our thread
data in Cosmos DB running

00:44:50.070 --> 00:44:53.550
in Fabric, which means they keep
all their data in the OneLake.

00:44:53.550 --> 00:44:54.660
The OneLake is amazing.

00:44:54.660 --> 00:44:56.790
So we decided that we're
going to replicate,

00:44:56.790 --> 00:44:59.940
we're going to mirror our
Postgres SQL database

00:44:59.940 --> 00:45:02.850
over into Fabric, which puts
our data in the OneLake.

00:45:02.850 --> 00:45:05.370
And now we can combine
these two different sources

00:45:05.370 --> 00:45:07.980
into a single query to
create a semantic model.

00:45:07.980 --> 00:45:09.060
And watch this.

00:45:09.060 --> 00:45:10.500
Let me show you something else.

00:45:10.500 --> 00:45:14.730
And we're going to create
this really beautiful report

00:45:14.730 --> 00:45:15.690
right here.

00:45:15.690 --> 00:45:16.410
There we go.

00:45:16.410 --> 00:45:18.390
Create this really beautiful
report that they can use.

00:45:18.390 --> 00:45:20.400
So for example, they can
look at their hackathon

00:45:20.400 --> 00:45:22.458
in San Francisco to
see all the data.

00:45:22.483 --> 00:45:22.920
Jay Parikh: Oh, wow.

00:45:22.920 --> 00:45:24.390
PATRICK LeBLANC: And they
can gain some insight

00:45:24.390 --> 00:45:26.010
at how great that event was.

00:45:26.010 --> 00:45:27.990
But they can also
take a look at this

00:45:27.990 --> 00:45:30.270
and possibly make this
event even better.

00:45:30.270 --> 00:45:31.560
Jay Parikh: That is awesome.

00:45:31.560 --> 00:45:32.825
Thank you for sharing
those insights.

00:45:32.850 --> 00:45:33.240
PATRICK LeBLANC: Yeah.

00:45:33.240 --> 00:45:34.110
Do you think we can get this --

00:45:34.110 --> 00:45:35.025
should we get this in the app?

00:45:35.050 --> 00:45:35.713
Jay Parikh: Yeah.

00:45:35.738 --> 00:45:37.350
You want to say it to Copilot?

00:45:37.350 --> 00:45:38.760
PATRICK LeBLANC: Hey,
Copilot, do what you do.

00:45:38.760 --> 00:45:40.260
Let's create that issue, Jay.

00:45:40.260 --> 00:45:40.620
All right.

00:45:40.620 --> 00:45:41.190
Thank you, everyone.

00:45:41.190 --> 00:45:41.910
Have a great Build.

00:45:41.910 --> 00:45:47.250
[ Applause ]

00:45:47.250 --> 00:45:49.833
Jay Parikh: So lots of
customers are already firing up

00:45:49.858 --> 00:45:52.110
their agent factories,
as you can see.

00:45:52.110 --> 00:45:56.130
Carvana actually used Foundry to
build an agent to analyze all

00:45:56.130 --> 00:45:57.840
of their customer interactions.

00:45:57.840 --> 00:46:01.050
And from there, the insights
that they gained, they were able

00:46:01.050 --> 00:46:05.700
to make a 40% reduction in
inbound calls for sale.

00:46:05.700 --> 00:46:08.660
Now, let's hear from Nasdaq
on what they're building.

00:46:08.685 --> 00:46:12.810
[ Music ]

00:46:12.810 --> 00:46:16.230
Robert Ianuzzi: It takes
countless hours of manual work

00:46:16.230 --> 00:46:19.320
to make sure corporate
governance teams are fully

00:46:19.320 --> 00:46:21.180
equipped and ready
for their meetings.

00:46:21.180 --> 00:46:24.180
Mohsin Shafqat: We are building
AI agents using Azure AI Foundry

00:46:24.180 --> 00:46:25.590
for Nasdaq Boardvantage.

00:46:25.590 --> 00:46:29.280
These agents help Nasdaq's
customers answer questions

00:46:29.280 --> 00:46:31.860
about risk, governance,
board meetings,

00:46:31.860 --> 00:46:33.330
and industrial insights.

00:46:33.330 --> 00:46:37.680
Robert Ianuzzi: Our customers
reported a 25% reduction

00:46:37.680 --> 00:46:39.060
in the amount of time

00:46:39.060 --> 00:46:41.880
that corporate secretaries
spent preparing summaries

00:46:41.880 --> 00:46:42.690
for each meeting.

00:46:42.690 --> 00:46:44.340
It was science
fiction 10 years ago.

00:46:44.340 --> 00:46:50.910
[ Applause ]

00:46:50.910 --> 00:46:53.130
Jay Parikh: Now, these new
capabilities are great,

00:46:53.130 --> 00:46:55.560
but adopting these in
the enterprise is going

00:46:55.560 --> 00:46:59.340
to be limited if we can't trust
it and we can't secure it.

00:46:59.340 --> 00:47:02.550
Foundry offers these
capabilities around trust

00:47:02.550 --> 00:47:04.710
and security baked
in from the start.

00:47:04.710 --> 00:47:07.890
It's a core principle for
how we're building Foundry.

00:47:07.890 --> 00:47:11.370
Now, we're also integrating
Microsoft security products

00:47:11.370 --> 00:47:14.880
like Entra, Purview, and
Defender right into Foundry.

00:47:14.880 --> 00:47:16.800
So as you're building
agents, you're going

00:47:16.800 --> 00:47:18.090
to be able to secure it.

00:47:18.090 --> 00:47:22.110
So to show us how all of this
works, please welcome Mehrnoosh.

00:47:22.110 --> 00:47:26.520
[ Applause ]

00:47:26.520 --> 00:47:28.290
Mehrnoosh Sameki:
Hello, everyone.

00:47:28.290 --> 00:47:33.030
I am tasked with ensuring that
my AI agent is safe and secure.

00:47:33.030 --> 00:47:36.360
There's a lot that I need to do
from identifying and measuring

00:47:36.360 --> 00:47:39.390
for the right risks, putting
the right control in place,

00:47:39.390 --> 00:47:43.620
and perform ongoing monitoring
for any new threats and issues.

00:47:43.620 --> 00:47:46.980
Luckily, Foundry enables
me to do all of that.

00:47:46.980 --> 00:47:51.030
Today, I'm just going to show
you a small part of three steps,

00:47:51.030 --> 00:47:53.580
measure, protect, and monitor.

00:47:53.580 --> 00:47:57.150
Now, I know that once my AI
application goes out there,

00:47:57.150 --> 00:47:59.490
bad actors will
try to misuse it.

00:47:59.490 --> 00:48:01.560
So here on my computer,

00:48:01.560 --> 00:48:04.710
I'm going to use the
AI red-teaming agents

00:48:04.710 --> 00:48:07.890
to adversarially test
my AI application

00:48:07.890 --> 00:48:11.100
against such attacks
before I ship it.

00:48:11.100 --> 00:48:14.550
As you can see, I have
the right risk categories

00:48:14.550 --> 00:48:17.550
and attack strategies set up.

00:48:17.550 --> 00:48:21.060
And now, my AI red-teaming
agent is attempting

00:48:21.060 --> 00:48:22.980
to attack my system.

00:48:22.980 --> 00:48:26.400
Let's take a look at some
results from an earlier run.

00:48:26.400 --> 00:48:31.290
Here, I can see that 42% of
attacks have gone through.

00:48:31.290 --> 00:48:32.700
Double-clicking on that,

00:48:32.700 --> 00:48:35.550
I can see that my model
is getting confused

00:48:35.550 --> 00:48:38.220
by some jailbreak attempts.

00:48:38.220 --> 00:48:41.430
I need to activate additional
guardrails in order

00:48:41.430 --> 00:48:43.350
to protect against these.

00:48:43.350 --> 00:48:47.190
Luckily, Foundry
enables me with agents,

00:48:47.190 --> 00:48:50.670
data, and model guardrails.

00:48:50.670 --> 00:48:56.010
I can create a content filter,
attach my Prompt Shield

00:48:56.010 --> 00:48:58.830
and activate it to
protect me against direct

00:48:58.830 --> 00:49:02.340
and indirect jailbreak attempts
coming through grounding data,

00:49:02.340 --> 00:49:05.880
agent tool calls,
even user interface.

00:49:05.880 --> 00:49:09.840
I set my output filters here,
attach it to the endpoint

00:49:09.840 --> 00:49:13.920
that I'm using in this
agent, and just like that,

00:49:13.920 --> 00:49:16.020
I have my guardrail set up.

00:49:16.020 --> 00:49:18.330
Now, it's time to monitor

00:49:18.330 --> 00:49:21.720
against new threats
to my AI systems.

00:49:21.720 --> 00:49:23.490
I can see the new threats

00:49:23.490 --> 00:49:25.230
against my AI system
in this view.

00:49:25.230 --> 00:49:28.290
As you can see, several
jailbreak attempts have happened

00:49:28.290 --> 00:49:29.790
against my AI system.

00:49:29.790 --> 00:49:30.840
But the great news is

00:49:30.840 --> 00:49:34.740
that Prompt Shield has
already blocked them for me.

00:49:34.740 --> 00:49:36.540
I would like to
double-click on that

00:49:36.540 --> 00:49:38.760
and understand the
source of the issue.

00:49:38.760 --> 00:49:42.720
For that, I head to Defender.

00:49:42.720 --> 00:49:45.420
Defender is a product
for security operations

00:49:45.420 --> 00:49:48.630
to fully investigate
security incidents.

00:49:48.630 --> 00:49:50.310
I can see the whole
incident here,

00:49:50.310 --> 00:49:53.910
including where it
is coming from.

00:49:53.910 --> 00:49:58.230
The attacker appears to be
part of a known attack group.

00:49:58.230 --> 00:50:02.880
I think it's safe to remove this
agent's access to resources just

00:50:02.880 --> 00:50:04.920
in case it's compromised.

00:50:04.920 --> 00:50:07.380
I go to Entra for that.

00:50:07.380 --> 00:50:14.490
Using Entra's Agent ID, I can
track and manage all my agents.

00:50:14.490 --> 00:50:17.380
Here is the compromised one.

00:50:18.690 --> 00:50:22.530
Let's remove its
access from resources

00:50:22.530 --> 00:50:24.330
until I address the issue.

00:50:24.330 --> 00:50:27.690
Now my system is secure again.

00:50:27.690 --> 00:50:31.920
As you can see, Foundry plus
Microsoft Security enables you

00:50:31.920 --> 00:50:36.150
to identify and measure for new
risks, put the right controls

00:50:36.150 --> 00:50:40.620
in place, and perform ongoing
monitoring post-production.

00:50:40.620 --> 00:50:41.670
Thank you.

00:50:41.670 --> 00:50:45.960
[ Applause ]

00:50:45.960 --> 00:50:46.980
Jay Parikh: All right.

00:50:46.980 --> 00:50:48.780
Thank you, Mehrnoosh.

00:50:48.780 --> 00:50:52.380
So here are some customers that
are seeing significant benefits

00:50:52.380 --> 00:50:56.460
of building with Foundry because
security and trust is baked in.

00:50:56.460 --> 00:51:00.330
Using Foundry, Heineken has
implemented regular evaluations

00:51:00.330 --> 00:51:05.610
and personality checks to
safeguard its chat bot

00:51:05.610 --> 00:51:08.910
from violating its
business values.

00:51:08.910 --> 00:51:12.660
So let's hear from Accenture
on how they're using Foundry.

00:51:12.660 --> 00:51:16.530
Anoop Gopinatha: At
Accenture, we focus on AI

00:51:16.530 --> 00:51:18.750
and agent-led
end-to-end business

00:51:18.750 --> 00:51:20.130
process transformations.

00:51:20.130 --> 00:51:22.470
Chaitanya Geddem: We knew
responsible AI could help us

00:51:22.470 --> 00:51:24.510
improve the efficiency
and security

00:51:24.510 --> 00:51:26.220
of our development processes.

00:51:26.220 --> 00:51:27.000
Nayan Paul: With this leadership

00:51:27.000 --> 00:51:28.770
and responsible, generative AI,

00:51:28.770 --> 00:51:31.380
Azure AI Foundry is a
game-changer for us.

00:51:31.380 --> 00:51:33.300
Chaitanya Geddem: We
have seen a 30% increase

00:51:33.300 --> 00:51:36.090
in overall efficiency,
20% reduction in cost,

00:51:36.090 --> 00:51:39.840
and it reduced the time to
build AI applications by 50%.

00:51:39.840 --> 00:51:42.514
Anoop Gopinatha: There is no
GenAI without responsible AI.

00:51:43.133 --> 00:51:47.585
[ Applause ]

00:51:47.610 --> 00:51:48.270
Jay Parikh: Okay.

00:51:48.270 --> 00:51:50.700
So we've seen our tools.

00:51:50.700 --> 00:51:52.230
We've seen our Agent Factory.

00:51:52.230 --> 00:51:53.820
And it's also protected

00:51:53.820 --> 00:51:57.090
with industry-leading
trust and security.

00:51:57.090 --> 00:52:00.720
But we shouldn't be restricted
to just deploying in the cloud.

00:52:00.720 --> 00:52:03.300
We don't want two different
platforms, one for the cloud

00:52:03.300 --> 00:52:05.190
and a different
one from the edge.

00:52:05.190 --> 00:52:06.630
That would be a real pain.

00:52:06.630 --> 00:52:09.330
So we're building Foundry
so that we can extend it

00:52:09.330 --> 00:52:11.550
from the cloud all
the way to the edge.

00:52:11.550 --> 00:52:13.050
Now, this is really cool,

00:52:13.050 --> 00:52:15.180
so we should just jump
right into the demo.

00:52:15.180 --> 00:52:16.722
Please welcome Seth.

00:52:16.747 --> 00:52:19.429
[ Applause ]

00:52:19.454 --> 00:52:21.570
Seth Juarez: How's it going?

00:52:21.570 --> 00:52:22.560
I'm so excited to be here.

00:52:22.560 --> 00:52:24.570
Everyone should know that
all those demos are live.

00:52:24.570 --> 00:52:25.800
We're not faking
any of this stuff.

00:52:25.800 --> 00:52:26.610
Jay Parikh: They're all live.

00:52:26.610 --> 00:52:27.390
Seth Juarez: Except
for this one.

00:52:27.390 --> 00:52:28.050
Just kidding.

00:52:28.050 --> 00:52:31.140
So let's go ahead and let
me show you Foundry models,

00:52:31.140 --> 00:52:32.370
but locally.

00:52:32.370 --> 00:52:34.140
Here's a number of models
that are available

00:52:34.140 --> 00:52:36.570
to me directly inside.

00:52:36.570 --> 00:52:38.160
I'm just running the
command because,

00:52:38.160 --> 00:52:39.360
you know, it's kind of cool.

00:52:39.360 --> 00:52:40.860
But the thing is that
there's a bunch of models

00:52:40.860 --> 00:52:43.710
that you can download
and use locally.

00:52:43.710 --> 00:52:45.930
And that's the thing because
when you're moving from cloud

00:52:45.930 --> 00:52:47.880
to edge and you want to
have some of this benefit,

00:52:47.880 --> 00:52:51.900
you can have it directly
on your actual machine.

00:52:51.900 --> 00:52:52.668
Can you not hear me?

00:52:52.693 --> 00:52:53.143
Producer: Yep.

00:52:53.168 --> 00:52:53.768
Seth Juarez: Oh, okay.

00:52:53.793 --> 00:52:54.363
Producer: Now I can hear you.

00:52:54.388 --> 00:52:55.081
Seth Juarez: Now
you can hear me.

00:52:55.106 --> 00:52:55.576
Thank you.

00:52:55.601 --> 00:52:56.640
I could have just
spoken to this.

00:52:56.640 --> 00:52:57.390
Would that have been awkward?

00:52:57.390 --> 00:52:57.930
Jay Parikh: Maybe.

00:52:57.930 --> 00:52:58.363
Seth Juarez: Okay.

00:52:58.388 --> 00:52:59.556
[ Laughter ]

00:52:59.581 --> 00:53:02.370
So let me go ahead and just
say, "Write me an outline

00:53:02.370 --> 00:53:04.470
for how LM" -- I think
you asked me to do that.

00:53:04.470 --> 00:53:04.800
Jay Parikh: I did.

00:53:04.800 --> 00:53:05.490
It was homework.

00:53:05.490 --> 00:53:05.910
Seth Juarez: Yeah.

00:53:05.934 --> 00:53:06.813
Jay Parikh: We'll grade later.

00:53:06.837 --> 00:53:08.700
Seth Juarez: And so I'm going
to get it done as soon as I can.

00:53:08.700 --> 00:53:10.200
And I'll give it to
you in an email.

00:53:10.200 --> 00:53:11.340
Jay Parikh: I can see
you're working hard.

00:53:11.340 --> 00:53:13.470
Seth Juarez: Well, yes, I'm
typing it up right now.

00:53:13.470 --> 00:53:17.160
Notice that this is working
locally, directly on my machine.

00:53:17.160 --> 00:53:20.520
And you can see that
it's hitting my GPU.

00:53:20.520 --> 00:53:21.000
Jay Parikh: Excellent.

00:53:21.000 --> 00:53:22.590
Seth Juarez: Yeah,
which is really good.

00:53:22.590 --> 00:53:23.880
Wait, I did the wrong GPU.

00:53:23.880 --> 00:53:24.570
It's this one.

00:53:24.570 --> 00:53:26.700
Sorry. You're like, "That's
not the right one, Seth."

00:53:26.700 --> 00:53:27.480
That's the one.

00:53:27.480 --> 00:53:29.910
But the thing about this is
that this is going to tie

00:53:29.910 --> 00:53:32.070
into something that you
heard about yesterday,

00:53:32.070 --> 00:53:33.930
the Windows MCP Registry.

00:53:33.930 --> 00:53:36.750
And now imagine what your
operating system might be able

00:53:36.750 --> 00:53:38.761
to do for you later on. But
I'm just going to tease it.

00:53:38.786 --> 00:53:40.117
Jay Parikh: Lots of
interesting ideas.

00:53:40.142 --> 00:53:41.040
Seth Juarez: So that's my demo.

00:53:41.040 --> 00:53:42.180
So thank you so much, my friend.

00:53:42.180 --> 00:53:42.660
Jay Parikh: Thank you.

00:53:42.660 --> 00:53:44.940
Can you hang out for a second?

00:53:44.940 --> 00:53:45.900
Just one more second.

00:53:45.900 --> 00:53:46.320
Seth Juarez: Okay.

00:53:46.320 --> 00:53:47.520
Okay. We'll do that.

00:53:47.520 --> 00:53:49.590
Jay Parikh: All right.

00:53:49.590 --> 00:53:50.220
Thank you, Seth.

00:53:50.220 --> 00:53:51.960
That's really cool stuff.

00:53:51.960 --> 00:53:57.180
So now we have seen
the AI-powered tools

00:53:57.180 --> 00:53:58.170
that we have.

00:53:58.170 --> 00:54:00.900
We've also talked about
our Agent Factory.

00:54:00.900 --> 00:54:03.120
We're securing this whole thing

00:54:03.120 --> 00:54:07.560
with the industry-leading
security and safety.

00:54:07.560 --> 00:54:10.140
Now, we've also seen
how we can take it

00:54:10.140 --> 00:54:12.690
from the edge to
the cloud as well.

00:54:12.690 --> 00:54:15.930
But we want to keep moving here,

00:54:15.930 --> 00:54:19.650
and we want to keep exploring
the frontier of what we can do

00:54:19.650 --> 00:54:22.080
with our tools and our platform.

00:54:22.080 --> 00:54:26.580
So before we go, we want
to share one more thing.

00:54:26.580 --> 00:54:28.950
We're teaming up
with the MSR team

00:54:28.950 --> 00:54:32.910
to really explore what
could be possible to build

00:54:32.910 --> 00:54:36.090
and to incorporate into our
tools and our platform.

00:54:36.090 --> 00:54:38.130
Now, these are not new products.

00:54:38.130 --> 00:54:39.750
We don't have dates in terms

00:54:39.750 --> 00:54:41.430
of when we're shipping
these things,

00:54:41.430 --> 00:54:43.710
so we have a lot to
figure out still,

00:54:43.710 --> 00:54:45.270
but we want to give you a sense

00:54:45.270 --> 00:54:47.220
of what capabilities
we're working on.

00:54:47.220 --> 00:54:49.560
So Seth, let's show
them what we got.

00:54:49.560 --> 00:54:50.820
Seth Juarez: Let's do
it, but we're going

00:54:50.820 --> 00:54:52.530
to make it awkward here.

00:54:52.530 --> 00:54:54.450
Okay, this is Project Amelie.

00:54:54.450 --> 00:54:57.060
And for those that don't know
-- yeah, we'll hang out here.

00:54:57.060 --> 00:54:59.580
For those that don't know, I
used to be a data scientist.

00:54:59.580 --> 00:55:01.770
I'm not just this
beautifully quaffed beard.

00:55:01.770 --> 00:55:03.240
I used to be a data scientist.

00:55:03.240 --> 00:55:06.630
And what happened is there was a
lot of work that we needed to do

00:55:06.630 --> 00:55:10.260
as data scientists when we did
an AI thing or machine learning.

00:55:10.260 --> 00:55:12.240
That's what we called it, you
know, before it was cool.

00:55:12.240 --> 00:55:14.190
So imagine you're
asked to build a model

00:55:14.190 --> 00:55:16.890
like, "Predict accommodation
rental prices in Seattle."

00:55:16.890 --> 00:55:20.460
What you would have to do is you
would have to get some data,

00:55:20.460 --> 00:55:22.050
you'd have to analyze
it a little bit.

00:55:22.050 --> 00:55:24.180
And so, again, here's
some homework here

00:55:24.180 --> 00:55:26.190
that I was maybe
supposed to do for you.

00:55:26.190 --> 00:55:27.690
We can upload the data set.

00:55:27.690 --> 00:55:29.940
And what you would do as a data
scientist is you would look

00:55:29.940 --> 00:55:32.280
at every row of these data sets,

00:55:32.280 --> 00:55:35.010
you would try to figure out
if the column was right,

00:55:35.010 --> 00:55:37.620
and sometimes someone --

00:55:37.620 --> 00:55:38.070
Jay Parikh: Maybe.

00:55:38.070 --> 00:55:39.690
Seth Juarez: -- it was
probably one of you,

00:55:39.690 --> 00:55:44.130
would put a string dollar where
there should have been a number.

00:55:44.130 --> 00:55:45.000
Do you know what I'm saying?

00:55:45.000 --> 00:55:46.800
Some of you would
actually do this.

00:55:46.800 --> 00:55:48.030
Very frustrating.

00:55:48.030 --> 00:55:50.760
So notice here that it's
already done some analysis,

00:55:50.760 --> 00:55:55.500
and what I can do is I can start
to ask it things as if it were

00:55:55.500 --> 00:55:58.080
like a mini data
scientist in a box.

00:55:58.080 --> 00:56:00.900
And notice that it's trying
to look at this information

00:56:00.900 --> 00:56:02.790
and it's doing some
of this stuff.

00:56:02.790 --> 00:56:04.560
So it's still accessing this.

00:56:04.560 --> 00:56:06.900
This doesn't take -- this
is not a five-minute demo.

00:56:06.900 --> 00:56:07.816
It takes about an hour.

00:56:07.841 --> 00:56:08.218
Jay Parikh: Right, right.

00:56:08.243 --> 00:56:09.570
Seth Juarez: But for
a data scientist,

00:56:09.570 --> 00:56:11.220
that's like a whole
day and a half.

00:56:11.220 --> 00:56:13.200
Let me show you something
that's already done.

00:56:13.200 --> 00:56:14.460
This thing is already done.

00:56:14.460 --> 00:56:15.408
You can see it
goes through. Oh --

00:56:15.433 --> 00:56:17.070
Jay Parikh: Oh,
there's the error.

00:56:17.070 --> 00:56:18.270
Seth Juarez: You want to
know what error it was?

00:56:18.270 --> 00:56:19.373
Jay Parikh: I do.

00:56:19.398 --> 00:56:20.700
Hmm.

00:56:20.700 --> 00:56:23.070
Hmm. Oh, the dollar sign.

00:56:23.070 --> 00:56:24.180
Who did that?

00:56:24.180 --> 00:56:26.130
Okay, but notice that
it was able to iterate

00:56:26.130 --> 00:56:28.680
and finally get to
the actual models.

00:56:28.680 --> 00:56:32.490
It self-corrected, the
actual code, and some metrics

00:56:32.490 --> 00:56:35.490
because it's using two different
models, one for reasoning

00:56:35.490 --> 00:56:37.050
and one for generating code,

00:56:37.050 --> 00:56:40.590
so that you can actually
use this actual code

00:56:40.590 --> 00:56:42.180
to get started as
a data scientist.

00:56:42.180 --> 00:56:42.780
How cool is that?

00:56:42.780 --> 00:56:43.530
[ Applause ]

00:56:43.530 --> 00:56:44.100
Pretty awesome.

00:56:44.100 --> 00:56:45.241
Seth Juarez: Yeah,
but there's more.

00:56:45.266 --> 00:56:46.080
There's more.

00:56:46.080 --> 00:56:48.720
There's an OpenAI benchmark
that they put up.

00:56:48.720 --> 00:56:50.850
This RD agent,
together with MSR,

00:56:50.850 --> 00:56:54.030
is actually at the top
of the leaderboard.

00:56:54.030 --> 00:56:54.031
Jay Parikh: Top of
the leaderboard.

00:56:54.031 --> 00:56:54.750
Seth Juarez: That's right.

00:56:54.750 --> 00:56:55.620
So thank you so much.

00:56:55.620 --> 00:56:56.287
This is awesome.

00:56:56.312 --> 00:56:57.142
Jay Parikh: That's awesome.

00:56:57.167 --> 00:57:00.990
Hey, so do you think we have
time for one more thing?

00:57:00.990 --> 00:57:03.810
Seth Juarez: Well, I'm not
dressed like the fun director

00:57:03.810 --> 00:57:05.670
at a cruise for nothing, right?

00:57:05.670 --> 00:57:06.990
So let's do one more thing.

00:57:06.990 --> 00:57:07.440
Jay Parikh: Okay.

00:57:07.440 --> 00:57:08.220
Seth Juarez: Let's
do one more thing.

00:57:08.220 --> 00:57:11.100
So it turns out that I went
and read a paper this weekend

00:57:11.100 --> 00:57:12.330
on something called GraphRAG,

00:57:12.330 --> 00:57:14.910
and Microsoft Research has done
some amazing things with this.

00:57:14.910 --> 00:57:15.540
Jay Parikh: It is.

00:57:15.540 --> 00:57:17.940
Seth Juarez: GraphRAG is
a situation where instead

00:57:17.940 --> 00:57:20.640
of just taking chunks of text
and putting it into a vector

00:57:20.640 --> 00:57:24.360
and searching, it actually takes
the chunks of text and uses LLMs

00:57:24.360 --> 00:57:27.840
to extract entities
and relationships,

00:57:27.840 --> 00:57:32.070
and it makes a graph so that
other LLMs can query it.

00:57:32.070 --> 00:57:36.210
And the SQL Server team actually
did this with their code.

00:57:36.210 --> 00:57:37.950
So let's take a
look at this thing.

00:57:37.950 --> 00:57:38.790
They weren't going
to let me look

00:57:38.790 --> 00:57:40.350
at their code here in person.

00:57:40.350 --> 00:57:44.550
So here is an error log of
something that actually happened

00:57:44.550 --> 00:57:45.840
to one of their engineers.

00:57:45.840 --> 00:57:48.750
Now, C++ is super scary
to me, even to this day,

00:57:48.750 --> 00:57:49.738
because of pointers and such.

00:57:49.763 --> 00:57:50.370
Jay Parikh: Yeah, me too.

00:57:50.370 --> 00:57:51.120
Seth Juarez: Yeah, I know.

00:57:51.120 --> 00:57:54.480
And so looking at this
thing is kind of stressful.

00:57:54.480 --> 00:57:59.910
But now imagine being able to
talk to this new data structure,

00:57:59.910 --> 00:58:03.390
figure out where the
errors actually live,

00:58:03.390 --> 00:58:07.890
understand the actual code,
and maybe even get to a fix.

00:58:07.890 --> 00:58:09.150
Jay Parikh: That's
pretty amazing.

00:58:09.150 --> 00:58:11.160
Seth Juarez: Yeah, and
for example, whenever we get

00:58:11.160 --> 00:58:13.560
into a new organization like
you are, you can literally talk

00:58:13.560 --> 00:58:16.140
to the knowledge of
a senior engineer.

00:58:16.140 --> 00:58:17.670
Jay Parikh: And how
big is this graph?

00:58:17.670 --> 00:58:18.540
Seth Juarez: This graph has

00:58:18.540 --> 00:58:22.590
about 14 million nodes
and 24 million edges.

00:58:22.590 --> 00:58:24.240
So it really is --

00:58:24.240 --> 00:58:25.410
Jay Parikh: So it's
a big code base.

00:58:25.410 --> 00:58:27.000
Seth Juarez: It is
a big code base.

00:58:27.000 --> 00:58:30.660
And there you see it's literally
fixing the actual code

00:58:30.660 --> 00:58:32.160
of our actual production thing.

00:58:32.160 --> 00:58:33.180
That's why I brought the video.

00:58:33.180 --> 00:58:35.070
We're not going to give
Seth access to code.

00:58:35.070 --> 00:58:35.880
So that's it.

00:58:35.880 --> 00:58:36.540
Isn't that great?

00:58:36.540 --> 00:58:37.367
Jay Parikh: That is awesome.

00:58:37.392 --> 00:58:37.885
Seth Juarez: Yeah.

00:58:37.910 --> 00:58:41.430
Jay Parikh: So should
we do one more thing?

00:58:41.430 --> 00:58:42.450
What do you think, audience?

00:58:42.450 --> 00:58:46.175
[ Applause ]

00:58:46.200 --> 00:58:47.100
I mean --

00:58:47.100 --> 00:58:50.010
Seth Juarez: I love being on
stage, so let's just do this.

00:58:50.010 --> 00:58:51.480
Do you all remember that --

00:58:51.480 --> 00:58:55.104
Jay Parikh: Do you want to -- we
should do something more fun.

00:58:55.129 --> 00:58:55.772
Seth Juarez: More fun?

00:58:55.797 --> 00:58:56.352
Jay Parikh: More fun.

00:58:56.377 --> 00:58:56.974
Yeah.

00:58:56.999 --> 00:58:57.780
Seth Juarez: Okay.

00:58:57.780 --> 00:58:59.310
So do you remember this game?

00:58:59.310 --> 00:59:00.030
Let's play the video.

00:59:00.030 --> 00:59:01.110
Do you remember this game here?

00:59:01.110 --> 00:59:01.620
Let's play it.

00:59:01.620 --> 00:59:02.730
Oh, get it up here.

00:59:02.730 --> 00:59:04.960
Anyone remember this game?

00:59:04.984 --> 00:59:06.486
[ Cheers ]

00:59:06.510 --> 00:59:07.380
Jay Parikh: Yeah.

00:59:07.380 --> 00:59:09.210
Seth Juarez: Yeah, I used
to play it all the time myself.

00:59:09.210 --> 00:59:09.390
Jay Parikh: Me too.

00:59:09.390 --> 00:59:10.950
Seth Juarez: One of
the things, though,

00:59:10.950 --> 00:59:12.000
you couldn't do something.

00:59:12.000 --> 00:59:13.230
Jay Parikh: You couldn't
do a few things.

00:59:13.230 --> 00:59:15.180
Seth Juarez: If we
go to the code,

00:59:15.180 --> 00:59:16.530
they actually released the code,

00:59:16.530 --> 00:59:19.230
and there's a love letter
here to all of the programmers.

00:59:19.255 --> 00:59:21.804
Jay Parikh: Do you
guys remember this?

00:59:21.829 --> 00:59:22.620
Seth Juarez: He said, you know,

00:59:22.620 --> 00:59:27.120
you could add some game features
like weapons or jumping.

00:59:27.120 --> 00:59:34.260
So someone used the exact same
GraphRAG, indexed this code,

00:59:34.260 --> 00:59:37.890
and then made the coding agent.

00:59:37.890 --> 00:59:42.300
They said, "Hey, can
you make it jump?"

00:59:42.300 --> 00:59:46.350
And you can see -- people
tell me that all the time,

00:59:46.350 --> 00:59:47.730
and they can't even
make me do it, right?

00:59:47.730 --> 00:59:47.970
Jay Parikh: Right.

00:59:47.970 --> 00:59:48.900
Seth Juarez: And so you can see

00:59:48.900 --> 00:59:54.090
that it actually created this
capability for realsies.

00:59:54.090 --> 00:59:56.520
I don't say for
realsies on purpose

00:59:56.520 --> 00:59:58.320
on stage, but for realsies.

00:59:58.320 --> 00:59:59.700
You can see it actually did it.

00:59:59.700 --> 01:00:02.160
And now, if we can
roll the second one,

01:00:02.160 --> 01:00:04.260
we're actually going
to see the dude.

01:00:04.260 --> 01:00:05.214
Jay Parikh: Look at that.

01:00:05.239 --> 01:00:05.903
Seth Juarez: Look at that.

01:00:05.928 --> 01:00:07.036
Jay Parikh: The
player's jumping.

01:00:07.061 --> 01:00:07.876
Seth Juarez: Come
on. How cool is that?

01:00:07.901 --> 01:00:09.300
[ Applause ]

01:00:09.300 --> 01:00:10.380
So there you have it, my friend.

01:00:10.380 --> 01:00:11.010
Jay Parikh: All right.

01:00:11.010 --> 01:00:13.530
Thank you, Seth.

01:00:13.530 --> 01:00:15.030
That's pretty cool, Seth.

01:00:15.030 --> 01:00:17.010
So thank you for that.

01:00:17.010 --> 01:00:21.120
Now, we want to wrap up here.

01:00:21.120 --> 01:00:24.120
And, you know, as builders,

01:00:24.120 --> 01:00:26.550
we know how important
these things are,

01:00:26.550 --> 01:00:28.560
our tools and our platform.

01:00:28.560 --> 01:00:31.110
They matter for
perfecting our craft.

01:00:31.110 --> 01:00:34.050
They matter for shaping
the culture of our teams.

01:00:34.050 --> 01:00:39.240
And they also matter for shaping
and realizing our ambitions.

01:00:39.240 --> 01:00:41.340
When I think about
the opportunity here,

01:00:41.340 --> 01:00:43.980
the thing that gets me
most excited is the idea

01:00:43.980 --> 01:00:47.070
of breaking free from the
constraints of the old ways

01:00:47.070 --> 01:00:49.530
of building and operating.

01:00:49.530 --> 01:00:54.240
To break out of this single-pane,
linear, deterministic view,

01:00:54.240 --> 01:00:57.930
and into a kind of multiverse
where you can build and operate

01:00:57.930 --> 01:01:01.260
in multiple dimensions
simultaneously.

01:01:01.260 --> 01:01:05.250
And to do so in parallel with
effectively a limitless number

01:01:05.250 --> 01:01:08.070
of agents acting on your behalf.

01:01:08.070 --> 01:01:10.350
There's a lot of work
to do here still.

01:01:10.350 --> 01:01:13.590
And to realize this kind of
vision, and it's something

01:01:13.590 --> 01:01:16.800
that we'll need to do
together and in the open

01:01:16.800 --> 01:01:20.040
to make AI superpowers
ubiquitous.

01:01:20.040 --> 01:01:22.650
But if we can do it,
we can create a world

01:01:22.650 --> 01:01:25.380
where we are no longer
constrained by the number

01:01:25.380 --> 01:01:29.640
of developers you can hire and
the number of hours in the day.

01:01:29.640 --> 01:01:32.760
It's a world where the only
constraints are imagination

01:01:32.760 --> 01:01:36.930
and our drive and maybe
looking for a few GPUs.

01:01:36.930 --> 01:01:39.750
But that's still a
world worth building.

01:01:39.750 --> 01:01:41.070
So let's go build it.

01:01:41.070 --> 01:01:41.700
Thank you.

01:01:41.700 --> 01:01:42.960
And please welcome Jatinder.

01:01:42.960 --> 01:01:49.620
[ Applause ]

01:01:49.620 --> 01:01:51.120
Jatinder Mann: Thank you, Jay.

01:01:51.120 --> 01:01:54.360
Windows AI Foundry is
our next step forward,

01:01:54.360 --> 01:01:57.390
building on the foundation
of Azure AI Foundry

01:01:57.390 --> 01:01:59.490
and Windows Copilot Runtime

01:01:59.490 --> 01:02:02.670
to bring the full power
of AI to the client.

01:02:02.670 --> 01:02:06.090
It gives you a consistent system
for running, customizing,

01:02:06.090 --> 01:02:10.620
and building AI models
directly on Windows at-scale.

01:02:10.620 --> 01:02:13.470
You get access to a
growing catalog of models,

01:02:13.470 --> 01:02:16.140
tools to customize them
with your own data,

01:02:16.140 --> 01:02:19.620
APIs for natural language and
vision, and the support you need

01:02:19.620 --> 01:02:22.140
to run custom models
consistently,

01:02:22.140 --> 01:02:25.320
regardless of the
underlying silicon.

01:02:25.320 --> 01:02:26.970
The growth in available models

01:02:26.970 --> 01:02:29.760
over the past year
has been exceptional.

01:02:29.760 --> 01:02:33.600
Today, you can explore a
wide range of local models,

01:02:33.600 --> 01:02:36.930
tuned for Windows, and sourced
from the AI Toolkit extension,

01:02:36.930 --> 01:02:39.180
as you can see here,
or pulling directly

01:02:39.180 --> 01:02:41.220
from leading repositories.

01:02:41.220 --> 01:02:44.430
These span CPU, GPU,
and, of course, NPU,

01:02:44.430 --> 01:02:46.320
unlocking powerful SLMs

01:02:46.320 --> 01:02:49.710
across the incredibly broad
Windows install base.

01:02:49.710 --> 01:02:52.140
But it's not just about
the number of models.

01:02:52.140 --> 01:02:54.720
It's about the quality.

01:02:54.720 --> 01:02:57.420
Just a year ago, small
language models were good

01:02:57.420 --> 01:02:59.940
at summarization and basic chat.

01:02:59.940 --> 01:03:03.420
Today, those same models,
running entirely on your device,

01:03:03.420 --> 01:03:07.230
can solve math problems, reason
through multi-step tasks,

01:03:07.230 --> 01:03:09.120
and power intelligent agents

01:03:09.120 --> 01:03:11.910
with real contextual
understanding.

01:03:11.910 --> 01:03:15.960
That kind of capability used to
require cloud-scale compute.

01:03:15.960 --> 01:03:19.470
Now, it runs locally
on a Windows PC.

01:03:19.470 --> 01:03:22.110
Take our own Phi
models as an example.

01:03:22.110 --> 01:03:26.370
We went from Phi-3 to Phi-4 in
months, and just last week,

01:03:26.370 --> 01:03:29.550
we introduced the Phi-4
reasoning family.

01:03:29.550 --> 01:03:32.670
These models are compact enough
for the edge, but smart enough

01:03:32.670 --> 01:03:33.660
to rival the kinds

01:03:33.660 --> 01:03:37.500
of experiences you'd
expect from GPT-4o.

01:03:37.500 --> 01:03:40.410
But this kind of advancement
also creates more complexity

01:03:40.410 --> 01:03:41.490
for developers.

01:03:41.490 --> 01:03:44.880
You're now managing more models
across more device types

01:03:44.880 --> 01:03:47.400
under tighter
performance constraints.

01:03:47.400 --> 01:03:50.130
That's exactly why we
built Foundry Local

01:03:50.130 --> 01:03:52.140
into Windows AI Foundry.

01:03:52.140 --> 01:03:54.660
It gives you a
model-as-a-service experience

01:03:54.660 --> 01:03:59.250
to access, run, and integrate
high-quality models optimized

01:03:59.250 --> 01:04:01.320
for real Windows hardware.

01:04:01.320 --> 01:04:04.170
Let me show you what
this looks like.

01:04:04.170 --> 01:04:07.020
So first, let's see what
models are available

01:04:07.020 --> 01:04:09.180
in the Windows AI
Foundry catalog.

01:04:09.180 --> 01:04:11.880
I have my command line
open, and I'm going

01:04:11.880 --> 01:04:17.250
to type "Foundry model list",
like Seth had shown before.

01:04:17.250 --> 01:04:19.410
And this gives me a list
of models optimized

01:04:19.410 --> 01:04:23.790
for this Windows PC across CPU,
GPU, and MPU, like Mistral,

01:04:23.790 --> 01:04:25.800
Phi, and even DeepSeek.

01:04:25.800 --> 01:04:28.530
I can also see which models
are already downloaded,

01:04:28.530 --> 01:04:34.500
or I can run one by typing
"Foundry model run", the name

01:04:34.500 --> 01:04:38.820
of the model, "Phi-4
mini reasoning".

01:04:38.820 --> 01:04:45.570
And everything here is running
locally on an NVIDIA RTX GPU.

01:04:45.570 --> 01:04:47.820
So let me start by
interacting with the model.

01:04:47.820 --> 01:04:52.020
I'm going to ask it a riddle to
test its reasoning abilities.

01:04:52.020 --> 01:04:54.600
And you can see this is
running really fast.

01:04:54.600 --> 01:04:57.330
So now that I'm happy
with the Phi-4 model,

01:04:57.330 --> 01:05:00.870
I want to integrate it into
my Electron Agent app.

01:05:00.870 --> 01:05:04.620
And all I have to do is
change this REST endpoint

01:05:04.620 --> 01:05:08.970
from the Azure cloud
to a local host,

01:05:08.970 --> 01:05:12.750
and I have a fully-local,
AI-powered chat experience.

01:05:12.750 --> 01:05:17.310
So now I have a new agent app
powered by Phi-4 running locally,

01:05:17.310 --> 01:05:20.220
and let's ask it
the same question.

01:05:20.220 --> 01:05:23.340
So now that you've seen
how simple it is to access

01:05:23.340 --> 01:05:25.260
and run models with
Foundry Local,

01:05:25.260 --> 01:05:27.000
let's talk about the next step.

01:05:27.000 --> 01:05:29.850
Customizing those models
to suit your data,

01:05:29.850 --> 01:05:32.010
your domain, and your users.

01:05:32.010 --> 01:05:33.930
Just like with Azure AI Foundry,

01:05:33.930 --> 01:05:36.600
Windows AI Foundry gives
you a flexible path

01:05:36.600 --> 01:05:40.500
to tailor model behavior
using two proven approaches.

01:05:40.500 --> 01:05:43.020
Parameter-efficient
fine-tuning with LoRA

01:05:43.020 --> 01:05:46.200
and retrieval-augmented
generation using semantic search

01:05:46.200 --> 01:05:47.580
and vector indexing.

01:05:47.580 --> 01:05:49.200
So let's start with LoRA.

01:05:49.200 --> 01:05:51.930
You fine-tune a base
model like Phi Silica

01:05:51.930 --> 01:05:55.860
by training a compact adapter
layer on your private data.

01:05:55.860 --> 01:05:58.350
This fine-tuning runs in
your Azure environment

01:05:58.350 --> 01:06:00.780
and outputs a
lightweight adapter file

01:06:00.780 --> 01:06:04.170
that can be deployed with a
base model on the client.

01:06:04.170 --> 01:06:07.230
At inference time, the
adapter runs in parallel,

01:06:07.230 --> 01:06:10.350
improving output quality
without modifying base weights

01:06:10.350 --> 01:06:12.300
or introducing latency overhead.

01:06:12.300 --> 01:06:14.550
And the whole process,
from data prep

01:06:14.550 --> 01:06:17.790
to job submission is
integrated into the AI toolkit

01:06:17.790 --> 01:06:22.140
for VS Code using familiar
tools like BICEP and Azure ML.

01:06:22.140 --> 01:06:25.200
So let's use the Phi
Silica model with LoRA

01:06:25.200 --> 01:06:29.070
to build an education agent app
using my own training data.

01:06:29.070 --> 01:06:32.250
So I'm going to start here in
the AI Toolkit for VS Code.

01:06:32.250 --> 01:06:35.250
And because I want to
fine-tune the Phi Silica model

01:06:35.250 --> 01:06:37.500
with my own custom data,
I'm going to start

01:06:37.500 --> 01:06:40.200
with a fine-tuning
tool right here.

01:06:40.200 --> 01:06:41.670
So let's start the project.

01:06:41.670 --> 01:06:44.100
Step one, let's give it a name.

01:06:44.100 --> 01:06:46.650
Let's call it Phi Silica LoRA.

01:06:46.650 --> 01:06:49.920
Then we have to select a
model from the model catalog.

01:06:49.920 --> 01:06:52.470
I'm going to configure
the project.

01:06:52.470 --> 01:07:00.690
And next, let's select the
training data, the test data,

01:07:00.690 --> 01:07:02.580
and the rest of the
hyperparameters look good.

01:07:02.580 --> 01:07:04.560
So I'm going to
generate the project.

01:07:04.560 --> 01:07:07.380
And so, this is going to
contain two key resources,

01:07:07.380 --> 01:07:09.810
my training data and
a BICEP file used

01:07:09.810 --> 01:07:12.300
to deploy my training
job in Azure.

01:07:12.300 --> 01:07:15.270
So the training data consists
of many samples of how I'd

01:07:15.270 --> 01:07:17.280
like the model to respond.

01:07:17.280 --> 01:07:20.010
It contains sample input
prompts and output.

01:07:20.010 --> 01:07:22.620
And LoRA is then going
to learn from this data.

01:07:22.620 --> 01:07:26.070
The BICEP file contains my
Azure subscription information,

01:07:26.070 --> 01:07:30.690
so my job can run
privately with my data.

01:07:30.690 --> 01:07:33.630
So let's start a new
fine-tuning job.

01:07:33.630 --> 01:07:35.730
Let's call it Job1.

01:07:35.730 --> 01:07:38.880
Let's select the
Azure subscription.

01:07:38.880 --> 01:07:39.750
There we go.

01:07:39.750 --> 01:07:41.970
And finally, a resource group.

01:07:41.970 --> 01:07:44.310
And now you can see that
the job is provisioning.

01:07:44.310 --> 01:07:46.020
And if you look closely
at the console,

01:07:46.020 --> 01:07:49.230
you can see that the job has
already started to run in Azure.

01:07:49.230 --> 01:07:52.410
And because training takes
time, I already trained LoRA

01:07:52.410 --> 01:07:53.970
for the purposes of this demo.

01:07:53.970 --> 01:07:56.790
So let me open up
the AI Dev Gallery.

01:07:56.790 --> 01:07:58.590
This is an interactive
sample app

01:07:58.590 --> 01:08:01.860
to help developers integrate
AI into their Windows apps.

01:08:01.860 --> 01:08:04.950
And I've already selected
my downloaded LoRA adapter,

01:08:04.950 --> 01:08:06.360
and I've generated the response.

01:08:06.360 --> 01:08:07.860
So now you can see
the difference

01:08:07.860 --> 01:08:11.340
in response output both
with the LoRA adapter

01:08:11.340 --> 01:08:13.140
and without the LoRA adapter.

01:08:13.140 --> 01:08:16.260
And in order to integrate LoRA
into your app, all you have

01:08:16.260 --> 01:08:18.750
to do is copy these
few lines of code.

01:08:18.750 --> 01:08:25.410
[ Applause ]

01:08:25.410 --> 01:08:27.690
In other cases, you
don't need to fine-tune.

01:08:27.690 --> 01:08:28.830
You just need the model

01:08:28.830 --> 01:08:31.830
to reference the right
knowledge at the right time.

01:08:31.830 --> 01:08:35.700
That's where retrieval augmented
generation, or RAG, comes in.

01:08:35.700 --> 01:08:38.550
Windows AI Foundry includes
a full semantic indexing

01:08:38.550 --> 01:08:41.520
and search pipeline, similar
to what you use in Azure.

01:08:41.520 --> 01:08:44.280
You can convert structured
or unstructured content,

01:08:44.280 --> 01:08:47.640
like documentation, FAQs,
or support tickets,

01:08:47.640 --> 01:08:49.980
into an embedding-based
vector store

01:08:49.980 --> 01:08:52.680
that the model can
query during inference.

01:08:52.680 --> 01:08:55.890
This gives you up-to-date
answers tailored

01:08:55.890 --> 01:08:58.140
to your domain
without retraining.

01:08:58.140 --> 01:09:01.620
So now I'm going to use Filmora,
a video editing app native

01:09:01.620 --> 01:09:04.470
to Windows, that uses the
Windows Semantic Search

01:09:04.470 --> 01:09:09.270
and Knowledge Retrieval APIs
locally on a Copilot+ PC.

01:09:09.270 --> 01:09:11.580
So let me show you
how this works.

01:09:11.580 --> 01:09:14.550
Here I have the Filmora app
preloaded with a video clip

01:09:14.550 --> 01:09:17.340
that I want to edit that
I'm playing right now.

01:09:17.340 --> 01:09:21.690
I'm going to go to the Filmora
AI Mate, and I'm going to ask it

01:09:21.690 --> 01:09:25.020
to make this video look
vintage from the 1950s.

01:09:25.020 --> 01:09:27.420
And thanks to the
Knowledge Retrieval API,

01:09:27.420 --> 01:09:29.640
Filmora's AI Mate
creates a knowledge base

01:09:29.640 --> 01:09:33.360
of all available assets, like
effects, filter, and music.

01:09:33.360 --> 01:09:36.570
The Semantic Search API helps
AI Mate provide contextual

01:09:36.570 --> 01:09:39.930
suggestions, making it easy to
achieve my desired outcome.

01:09:39.930 --> 01:09:42.720
So not only can I see the
type of treatment I can apply

01:09:42.720 --> 01:09:45.360
to this video, I can
also see the top assets

01:09:45.360 --> 01:09:46.740
that are most relevant

01:09:46.740 --> 01:09:48.990
to the vintage outcome
I just described.

01:09:48.990 --> 01:09:51.780
So I really like these
last two filters.

01:09:51.780 --> 01:09:53.610
I'm going to select
the film damaged one,

01:09:53.610 --> 01:09:55.690
and let's see what
this looks like.

01:09:56.880 --> 01:09:59.220
I was able to create
an amazing video

01:09:59.220 --> 01:10:02.250
without specialized knowledge
thanks to the Filmora app,

01:10:02.250 --> 01:10:05.220
their AI Mate agent, and
all while running locally

01:10:05.220 --> 01:10:07.920
on a Copilot+ PC.

01:10:07.920 --> 01:10:10.710
So everything we've shown so
far assumes you're working

01:10:10.710 --> 01:10:12.780
with pre-optimized models.

01:10:12.780 --> 01:10:14.970
But when you bring
your own custom model,

01:10:14.970 --> 01:10:17.010
things get more complex.

01:10:17.010 --> 01:10:19.200
Windows ML changes that.

01:10:19.200 --> 01:10:20.850
It's a unified execution layer

01:10:20.850 --> 01:10:24.300
that simplifies custom model
deployment across Windows.

01:10:24.300 --> 01:10:27.420
It handles hardware mapping,
power-aware execution,

01:10:27.420 --> 01:10:31.560
and fallback, so your model just
runs with no need to tailor it

01:10:31.560 --> 01:10:33.360
for individual devices.

01:10:33.360 --> 01:10:35.850
This is only possible
because of the breakthroughs

01:10:35.850 --> 01:10:39.960
from our silicon partners, AMD,
Intel, NVIDIA, and Qualcomm,

01:10:39.960 --> 01:10:42.930
who have each pushed AI
performance on their platforms

01:10:42.930 --> 01:10:44.460
and are now coming together

01:10:44.460 --> 01:10:46.440
to make those
capabilities accessible

01:10:46.440 --> 01:10:48.600
at scale through Windows ML.

01:10:48.600 --> 01:10:51.090
Next, let's hear directly
from them and some

01:10:51.090 --> 01:10:53.730
of our developer partners
who have a private preview

01:10:53.730 --> 01:10:56.850
and share what their experience
has been with Windows ML.

01:10:56.850 --> 01:11:00.450
And after that, we will welcome
Charles Lamanna to the stage.

01:11:00.450 --> 01:11:00.840
Thank you.

01:11:00.840 --> 01:11:03.210
[ Applause ]

01:11:03.210 --> 01:11:03.960
Lisa Pearce: We're excited

01:11:03.960 --> 01:11:07.830
to see Windows ML unify the
AI stack, making it easier

01:11:07.830 --> 01:11:10.920
for developers to build
high-performance applications

01:11:10.920 --> 01:11:13.910
that run across
CPU, GPU, and MPU.

01:11:13.910 --> 01:11:16.670
Ian Buck: It gives developers
the trusted Windows platform API

01:11:16.670 --> 01:11:19.340
compatibility while
enabling hardware makers

01:11:19.340 --> 01:11:21.380
to deliver great AI performance

01:11:21.380 --> 01:11:23.630
with their own optimized
implementations.

01:11:23.630 --> 01:11:25.070
Vinesh Sukumar: Windows
ML is a breakthrough

01:11:25.070 --> 01:11:28.100
for our software partners and
countless application developers

01:11:28.100 --> 01:11:31.670
that we work with, creating a
consistent, high-performance path

01:11:31.670 --> 01:11:33.570
for AI to scale on the edge.

01:11:33.570 --> 01:11:35.250
Vamsi Boppana: We see
this as a critical step

01:11:35.250 --> 01:11:37.500
in making our
platforms a foundation

01:11:37.500 --> 01:11:40.320
for AI innovation on Windows.

01:11:40.320 --> 01:11:42.210
Barthélémy Kiss: Founder
turns gameplay videos

01:11:42.210 --> 01:11:44.850
into instant highlight reels.

01:11:44.850 --> 01:11:46.500
Windows ML has enabled us

01:11:46.500 --> 01:11:49.020
to integrate models
three times faster

01:11:49.020 --> 01:11:52.830
and slashes our model
integration costs by up to 70%.

01:11:52.830 --> 01:11:53.730
Eric Yang: We've
been building photo

01:11:53.730 --> 01:11:56.010
and video software for
over 20 years now.

01:11:56.010 --> 01:11:58.560
We're really excited to
partner with Microsoft

01:11:58.560 --> 01:12:00.930
to test an early
version of Windows ML.

01:12:00.930 --> 01:12:03.810
Because we were already using
Onyx, it was a simple process

01:12:03.810 --> 01:12:05.190
to build an early prototype

01:12:05.190 --> 01:12:08.910
that saved our developers
substantial time.

01:12:08.910 --> 01:12:13.584
[ Music ]

01:12:13.609 --> 01:12:15.330
[ Applause ]

01:12:15.330 --> 01:12:17.100
Charles Lamanna: Good
morning, everybody.

01:12:17.100 --> 01:12:18.750
It's great to be back at Build.

01:12:18.750 --> 01:12:21.420
Always exciting to get time
together with all of you.

01:12:21.420 --> 01:12:24.600
As you saw from Jay's session,
there are going to be a lot

01:12:24.600 --> 01:12:27.290
of agents created over
the next couple of years.

01:12:27.290 --> 01:12:29.150
Developers are going
to be building agents.

01:12:29.150 --> 01:12:31.670
Companies are going to be
deploying and adopting agents.

01:12:31.670 --> 01:12:35.060
And they're going to be the
new building block of IT

01:12:35.060 --> 01:12:37.170
and apps and services.

01:12:37.170 --> 01:12:39.480
And the scale is staggering.

01:12:39.480 --> 01:12:45.270
IDC estimates 1.3 billion agents
are going to be built by 2028.

01:12:45.270 --> 01:12:47.010
That's just a couple years away.

01:12:47.010 --> 01:12:50.430
And the reality is all these
agents are going to have lots

01:12:50.430 --> 01:12:54.740
of expertise, lots of skills,
and lots of capabilities.

01:12:54.740 --> 01:12:56.630
And the big question
is going to be,

01:12:56.630 --> 01:12:59.720
how do we navigate all
these different agents?

01:12:59.720 --> 01:13:01.790
And that's where
Copilot comes in.

01:13:01.790 --> 01:13:05.910
It's one place to find and
use all of your agents.

01:13:05.910 --> 01:13:07.980
It extends across
all of your work.

01:13:07.980 --> 01:13:10.080
It follows you from app to app.

01:13:10.080 --> 01:13:11.430
It makes you more efficient

01:13:11.430 --> 01:13:14.670
and puts all these agents
right at your fingertips.

01:13:14.670 --> 01:13:17.910
But it's not just
going to be Copilot.

01:13:17.910 --> 01:13:20.610
We also are going to have to
collaborate and communicate

01:13:20.610 --> 01:13:22.800
with these agents, which
we'll do right inside

01:13:22.800 --> 01:13:25.890
of Microsoft Teams, the same
way that we communicate

01:13:25.890 --> 01:13:28.350
with other people on our team.

01:13:28.350 --> 01:13:32.100
And we're also going to have to
reimagine applications in a way

01:13:32.100 --> 01:13:34.950
where it's people using
the GUI, but also agents

01:13:34.950 --> 01:13:38.760
in the background and using
that same user interface.

01:13:38.760 --> 01:13:42.420
As we build all of this, we're
going to have to secure it.

01:13:42.420 --> 01:13:45.810
And the good news is your
existing security capabilities

01:13:45.810 --> 01:13:47.190
will keep working.

01:13:47.190 --> 01:13:50.700
Entra for identity, Defender
for protecting your back end

01:13:50.700 --> 01:13:51.810
and all your systems,

01:13:51.810 --> 01:13:54.990
and Purview for data labeling
and data protection.

01:13:54.990 --> 01:13:57.150
And to see kind of how
all this fits together,

01:13:57.150 --> 01:13:59.730
we have a whole bunch of
more demos to show you.

01:13:59.730 --> 01:14:03.270
And I'm going to start by
showing Copilot in action

01:14:03.270 --> 01:14:05.580
and really highlight some of
the things that you heard

01:14:05.580 --> 01:14:07.350
yesterday from Satya,

01:14:07.350 --> 01:14:11.220
this idea of a five-in-one
experience in Copilot.

01:14:11.220 --> 01:14:14.610
So if you look on this left-hand
side here, you have Search,

01:14:14.610 --> 01:14:17.700
you have Chat, you have agents
like Researcher, Analyst,

01:14:17.700 --> 01:14:21.270
and more, and even things
like Notebooks and Pages.

01:14:21.270 --> 01:14:23.610
So that way you can go to one
place and always get access

01:14:23.610 --> 01:14:25.830
to all the AI capabilities
you care about,

01:14:25.830 --> 01:14:28.770
whether the agents are
built by Microsoft or built

01:14:28.770 --> 01:14:31.710
on the back end by developers
or other companies.

01:14:31.710 --> 01:14:34.110
And one of the things
that I always use Copilot

01:14:34.110 --> 01:14:35.910
for is around research.

01:14:35.910 --> 01:14:39.120
Okay. Got a message from Jay.

01:14:39.120 --> 01:14:40.830
Let's see.

01:14:40.830 --> 01:14:41.880
AI never sleeps.

01:14:41.880 --> 01:14:42.690
You know, there's always a --

01:14:42.690 --> 01:14:44.490
it's a new hour,
it's a new paper.

01:14:44.490 --> 01:14:47.910
So Jay's asking me to go
check out one of these papers

01:14:47.910 --> 01:14:51.240
about some new RAG approaches
for agents and back ends

01:14:51.240 --> 01:14:53.460
and to compare it against what
Hydar on our team is doing.

01:14:53.460 --> 01:14:56.160
So normally, this
would be a time

01:14:56.160 --> 01:14:58.590
where I feverishly start
reading through the paper,

01:14:58.590 --> 01:15:02.250
but I can use Copilot and the
researcher agent to get caught

01:15:02.250 --> 01:15:03.360
up and not miss any

01:15:03.360 --> 01:15:06.050
of the important
details really quickly.

01:15:06.050 --> 01:15:09.350
So I'll come in here and
just paste my prompt,

01:15:09.350 --> 01:15:12.840
and I'll reference the
document that I care about.

01:15:12.840 --> 01:15:14.430
I zoom in here.

01:15:14.430 --> 01:15:17.430
You can see something really
powerful about Researcher.

01:15:17.430 --> 01:15:21.150
It knows my documents, my
meetings, my files, the specs,

01:15:21.150 --> 01:15:25.410
the arc diagrams, even connects
back to GitHub or Azure DevOps

01:15:25.410 --> 01:15:28.080
to compare this paper
against our internal,

01:15:28.080 --> 01:15:29.640
generative strategies.

01:15:29.640 --> 01:15:31.050
And this is what's great

01:15:31.050 --> 01:15:33.660
about researcher is
it knows how we work.

01:15:33.660 --> 01:15:35.460
It's not just going
out to the web

01:15:35.460 --> 01:15:37.080
when it generates the response.

01:15:37.080 --> 01:15:40.320
And a researcher, like any good
researcher, doesn't run off

01:15:40.320 --> 01:15:41.850
and start doing its tasks.

01:15:41.850 --> 01:15:43.800
It has some follow-up
questions, you know,

01:15:43.800 --> 01:15:45.180
"How long do you want
the paper to be?",

01:15:45.180 --> 01:15:47.460
"Anything to pay attention
to in particular?"

01:15:47.460 --> 01:15:48.810
And the big thing I care

01:15:48.810 --> 01:15:51.990
about, as a developer,
is how it diverges

01:15:51.990 --> 01:15:54.470
from the current approaches
that we're using.

01:15:54.470 --> 01:15:56.090
So I'll send this message,

01:15:56.090 --> 01:15:59.150
and what's happening here
is it's going out and doing

01:15:59.150 --> 01:16:00.920
that diff, that
comparison for me.

01:16:00.920 --> 01:16:03.080
And to figure out what we're
doing today, that's not easy.

01:16:03.080 --> 01:16:04.790
I didn't write it in the prompt.

01:16:04.790 --> 01:16:07.650
It has to go to all those data
sources I talked about earlier.

01:16:07.650 --> 01:16:09.930
And what the researcher
agent does is it kind

01:16:09.930 --> 01:16:11.550
of executes a series of steps.

01:16:11.550 --> 01:16:13.830
And this can take 10
minutes, 15 minutes,

01:16:13.830 --> 01:16:16.170
even longer to come
back with a response.

01:16:16.170 --> 01:16:18.000
I won't make us wait
for that to come back.

01:16:18.000 --> 01:16:19.890
So I'll switch over here

01:16:19.890 --> 01:16:22.290
to one that's already
completed earlier.

01:16:22.290 --> 01:16:24.930
And what's great is you
can kind of see it started

01:16:24.930 --> 01:16:28.230
to do this breakdown for me,
comparing multi-agent RAG

01:16:28.230 --> 01:16:31.380
to our own, internal,
generative answers approach.

01:16:31.380 --> 01:16:32.790
And the bit that I really

01:16:32.790 --> 01:16:38.160
like about this response is it's
pretty thorough, very verbose,

01:16:38.160 --> 01:16:41.610
but there's kind of a hero
table that I really care about.

01:16:41.610 --> 01:16:47.250
And what that does is it clearly
separates what the paper does

01:16:47.250 --> 01:16:49.110
against what we're doing today.

01:16:49.110 --> 01:16:50.640
So I can look at query handling,

01:16:50.640 --> 01:16:52.830
retrieval sources,
or doc selection.

01:16:52.830 --> 01:16:54.660
And with so much
research happening,

01:16:54.660 --> 01:16:57.960
so much change happening,
I can use this to figure

01:16:57.960 --> 01:17:00.420
out the right algorithm and
the right approach easily.

01:17:00.420 --> 01:17:02.490
And this isn't going to
replace what you do inside

01:17:02.490 --> 01:17:05.850
of GitHub Copilot or VS Code,
but this is more about education

01:17:05.850 --> 01:17:07.350
and research and preparation.

01:17:07.350 --> 01:17:08.430
If I come down here, you can

01:17:08.430 --> 01:17:11.040
see all the amazing sources
that were pulled together.

01:17:11.040 --> 01:17:14.700
So to make my life easy, I'm
going to go create that page,

01:17:14.700 --> 01:17:17.280
which pulls together that
Researcher response.

01:17:17.280 --> 01:17:18.330
And I'm going to take this

01:17:18.330 --> 01:17:21.730
and just share it
right back with Jay.

01:17:23.220 --> 01:17:25.650
And this makes it so
I don't have to go type

01:17:25.650 --> 01:17:27.840
up anything myself either.

01:17:27.840 --> 01:17:29.910
And this is going to be
that new way of working.

01:17:29.910 --> 01:17:32.250
We have agents to make us more
efficient and more productive.

01:17:32.250 --> 01:17:34.230
And if I want to, I
can go deeper right

01:17:34.230 --> 01:17:35.190
into that experience.

01:17:35.190 --> 01:17:38.150
Now, if I come back
over here to Copilot,

01:17:38.150 --> 01:17:40.520
it's not just about Researcher.

01:17:40.520 --> 01:17:42.980
We also have a huge collection

01:17:42.980 --> 01:17:46.410
of agents available
inside the agent store.

01:17:46.410 --> 01:17:48.960
We have hundreds of different
agents you can pick from,

01:17:48.960 --> 01:17:51.570
whether they're developer or
sales or finance or more.

01:17:51.570 --> 01:17:55.320
And the agents you build
can also show up here.

01:17:55.320 --> 01:17:57.690
And that's something that
we're seeing change pretty

01:17:57.690 --> 01:17:58.950
dramatically with agents.

01:17:58.950 --> 01:18:01.290
It's this open ecosystem.

01:18:01.290 --> 01:18:03.840
We're all going to have
our agents that we like

01:18:03.840 --> 01:18:06.360
and that we use based on
our developer environment,

01:18:06.360 --> 01:18:09.240
and we're not going to change
that support here at Microsoft.

01:18:09.240 --> 01:18:13.740
And a key part of that is MCP,
or the model context protocol.

01:18:13.740 --> 01:18:18.210
As Kevin said yesterday,
that's just like HTTP.

01:18:18.210 --> 01:18:21.270
This is the new way these
agents are going to communicate

01:18:21.270 --> 01:18:23.100
to back-end systems and work

01:18:23.100 --> 01:18:25.170
with all the different
things that we care about.

01:18:25.170 --> 01:18:28.530
And it's not just about MCP
clients, us building things

01:18:28.530 --> 01:18:33.780
like Copilot or GitHub
Copilot, but also MCP servers.

01:18:33.780 --> 01:18:36.780
And we're excited that we
published Dynamics 365 MCP

01:18:36.780 --> 01:18:39.900
servers available
to anybody to use.

01:18:39.900 --> 01:18:43.050
And we also announced
support for agent-to-agent

01:18:43.050 --> 01:18:45.480
or A2A protocol from Google.

01:18:45.480 --> 01:18:48.480
And we're going to support all
open protocols that matter

01:18:48.480 --> 01:18:50.730
to our customers and
to our developers.

01:18:50.730 --> 01:18:53.490
Because this is going to
be an open agentic web

01:18:53.490 --> 01:18:54.930
as we move forward.

01:18:54.930 --> 01:18:58.710
And this ecosystem is
already flourishing.

01:18:58.710 --> 01:19:02.100
There are hundreds of partners
already adopting and integrating

01:19:02.100 --> 01:19:04.800
through graph connectors,
agents, and more.

01:19:04.800 --> 01:19:06.990
Companies like UiPath
and Gong showing

01:19:06.990 --> 01:19:10.830
up with first-class experiences
inside Copilot and agents.

01:19:10.830 --> 01:19:13.200
So no matter what IT
environment somebody has,

01:19:13.200 --> 01:19:15.720
these agents will work great.

01:19:15.720 --> 01:19:18.600
And three of the great,
most powerful examples

01:19:18.600 --> 01:19:23.370
that we have are around
Adobe, SAP, and ServiceNow.

01:19:23.370 --> 01:19:25.560
These are some of the most
important applications

01:19:25.560 --> 01:19:27.360
in any enterprise environment.

01:19:27.360 --> 01:19:29.340
And they're going to be
available right inside

01:19:29.340 --> 01:19:32.100
of Copilot with
AI-rich experiences.

01:19:32.100 --> 01:19:34.840
Let's hear it from
them in a short video.

01:19:34.865 --> 01:19:37.020
[ Music ]

01:19:37.020 --> 01:19:38.400
Dorit Zilbershot: AI
agents are really going

01:19:38.400 --> 01:19:40.230
to change the way we work.

01:19:40.230 --> 01:19:41.220
Walter Sun: Take a look
at the intersection

01:19:41.220 --> 01:19:42.660
of Microsoft productivity users

01:19:42.660 --> 01:19:44.730
and SAP business
application users.

01:19:44.730 --> 01:19:46.800
It makes a lot of sense
to give them the ability

01:19:46.800 --> 01:19:48.090
to get more done.

01:19:48.090 --> 01:19:49.200
Amit Ahuja: Adobe
Marketing Agent

01:19:49.200 --> 01:19:52.830
and Microsoft 365 Copilot
together unlock so much.

01:19:52.830 --> 01:19:55.230
Marketers don't have to
switch applications now

01:19:55.230 --> 01:19:56.850
to make informed decisions.

01:19:56.850 --> 01:19:58.500
Dorit Zilbershot:
ServiceNow AI agents

01:19:58.500 --> 01:20:01.800
and Microsoft 365
Copilot unified

01:20:01.800 --> 01:20:05.910
in one experience means your
AI agents can pull context

01:20:05.910 --> 01:20:09.960
from Teams Chat, Outlook,
calendar, and files.

01:20:09.960 --> 01:20:11.820
Amit Ahuja: Marketers
instantly access audience

01:20:11.820 --> 01:20:14.690
analysis right in the
applications they use.

01:20:14.690 --> 01:20:18.200
This is next-level,
data-driven decision-making.

01:20:18.200 --> 01:20:19.490
Walter Sun: Choosing
Microsoft Copilot

01:20:19.490 --> 01:20:22.670
to augment the capabilities of
SAP tool was natural for us.

01:20:22.670 --> 01:20:23.780
It's the first step

01:20:23.780 --> 01:20:25.970
in bidirectional,
agent-to-agent collaborations.

01:20:25.970 --> 01:20:29.070
Dorit Zilbershot: We're
shifting AI from a tool you use

01:20:29.070 --> 01:20:31.470
to a system that you
collaborate with.

01:20:31.470 --> 01:20:33.360
Amit Ajuha: This is
a perfect example

01:20:33.360 --> 01:20:35.950
of where the future
work is going.

01:20:37.170 --> 01:20:38.400
Charles Lamanna:
So lots of agents.

01:20:38.400 --> 01:20:40.170
That's the ongoing theme.

01:20:40.170 --> 01:20:42.960
And one of the challenges, you
don't just want only Copilot

01:20:42.960 --> 01:20:44.400
to be the place or
the way you think

01:20:44.400 --> 01:20:45.660
about bringing order to it.

01:20:45.660 --> 01:20:47.400
We're going to have to
create some structure

01:20:47.400 --> 01:20:49.320
around these agents, too.

01:20:49.320 --> 01:20:52.590
And to do that, we go and
draw from past experience.

01:20:52.590 --> 01:20:55.890
How do we organize teams of
people working together?

01:20:55.890 --> 01:20:57.030
You know, you have groups.

01:20:57.030 --> 01:20:57.990
You have permissions.

01:20:57.990 --> 01:20:59.430
You have working spaces.

01:20:59.430 --> 01:21:01.260
We're going to do the
same type of thing

01:21:01.260 --> 01:21:04.770
with agents appearing
right alongside all

01:21:04.770 --> 01:21:06.180
of our organizations.

01:21:06.180 --> 01:21:10.050
This combo of agents and people
working together, this is going

01:21:10.050 --> 01:21:13.380
to be what the modern
team looks like.

01:21:13.380 --> 01:21:15.300
And what that means is
we're going to have to work

01:21:15.300 --> 01:21:19.040
through a new way of
getting our jobs done.

01:21:19.040 --> 01:21:21.740
Agents are emerging
at massive scale.

01:21:21.740 --> 01:21:25.400
The applications that we
use every day, the GUIs,

01:21:25.400 --> 01:21:27.530
the current terminals,
everything,

01:21:27.530 --> 01:21:29.240
are going to have to change.

01:21:29.240 --> 01:21:33.180
And the way we collaborate
is going to evolve.

01:21:33.180 --> 01:21:37.380
All these things require
new tools, new thinking,

01:21:37.380 --> 01:21:39.720
new ways of getting
our job done.

01:21:39.720 --> 01:21:41.520
And the first big
component of that is going

01:21:41.520 --> 01:21:42.990
to be Copilot Studio,

01:21:42.990 --> 01:21:46.110
an incredibly easy way
to go create agents.

01:21:46.110 --> 01:21:49.920
Or Power Apps, a way to rapidly
build out these new types

01:21:49.920 --> 01:21:52.380
of intelligent
application experiences.

01:21:52.380 --> 01:21:56.040
And Teams is growing and
evolving to support these teams

01:21:56.040 --> 01:21:58.170
of people and agents
working together.

01:21:58.170 --> 01:22:01.110
So wherever people are
working, you will have access

01:22:01.110 --> 01:22:03.660
to all this great
agent capability

01:22:03.660 --> 01:22:05.990
that we build and
that you build.

01:22:05.990 --> 01:22:08.720
And if I look at Copilot
Studio, we really view it

01:22:08.720 --> 01:22:11.660
as the easiest way to
go create those agents.

01:22:11.660 --> 01:22:15.960
It's used by over
230,000 organizations.

01:22:15.960 --> 01:22:19.440
And it wraps up the models, the
connectors, the orchestrators,

01:22:19.440 --> 01:22:22.110
the observability,
diagnostics, and more.

01:22:22.110 --> 01:22:25.950
So you can have a one-stop shop
and spend more time building

01:22:25.950 --> 01:22:28.590
as opposed to managing the
agents that you create.

01:22:28.590 --> 01:22:30.300
This is best seen in a demo.

01:22:30.300 --> 01:22:33.570
So I am super excited to
welcome Ryan to the stage

01:22:33.570 --> 01:22:35.693
to show it all in action.

01:22:35.718 --> 01:22:36.521
Ryan Cunningham:
Thank you, Charles!

01:22:36.545 --> 01:22:40.081
[ Applause ]

01:22:40.106 --> 01:22:44.930
CSX is one of the largest
transportation providers

01:22:44.930 --> 01:22:46.130
in the country.

01:22:46.130 --> 01:22:48.470
Their train division
alone operates

01:22:48.470 --> 01:22:52.350
about 20,000 miles of track.

01:22:52.350 --> 01:22:53.880
And what you're seeing behind me

01:22:53.880 --> 01:22:57.570
on the square screens is a
dramatization of the type

01:22:57.570 --> 01:23:01.050
of monitoring a team like
that needs to make sure

01:23:01.050 --> 01:23:04.530
such a complex system stays
running smooth like butter.

01:23:04.530 --> 01:23:06.540
Because things happen, you know.

01:23:06.540 --> 01:23:08.640
And you want to be
able to monitor just

01:23:08.640 --> 01:23:13.270
in case any incident
might occur.

01:23:15.030 --> 01:23:17.250
There's one now, in fact.

01:23:17.250 --> 01:23:20.190
About 24 miles outside
of Bardstown, Kentucky,

01:23:20.190 --> 01:23:23.280
a freight train has had to
come to a preemptive stop

01:23:23.280 --> 01:23:24.450
because of signal failure.

01:23:24.450 --> 01:23:27.780
Now, everybody's okay, but this
thing is carrying Class III

01:23:27.780 --> 01:23:28.800
hazardous materials.

01:23:28.800 --> 01:23:30.540
It's now blocking a main line.

01:23:30.540 --> 01:23:33.330
And by the way, it's 3 a.m. in
February, and it's snowing.

01:23:33.330 --> 01:23:35.130
We've got work to do, right?

01:23:35.130 --> 01:23:36.690
We've got trains to reroute,

01:23:36.690 --> 01:23:39.450
crews to dispatch,
regulators to notify.

01:23:39.450 --> 01:23:41.160
That is a lot on the shoulders

01:23:41.160 --> 01:23:44.250
of the ops team working
the night shift at CSX.

01:23:44.250 --> 01:23:47.210
And it's a perfect
opportunity for agents

01:23:47.210 --> 01:23:48.620
to jump in and help out.

01:23:48.620 --> 01:23:51.620
And we're going to build
them in Copilot Studio.

01:23:51.620 --> 01:23:53.160
Let's take a look.

01:23:53.160 --> 01:23:55.920
Now, for those of you who
have not come face-to-face

01:23:55.920 --> 01:23:58.260
with an agent in
Copilot Studio before,

01:23:58.260 --> 01:23:59.490
this is what it looks like.

01:23:59.490 --> 01:24:02.370
You know, it starts
at plain-spoken,

01:24:02.370 --> 01:24:06.210
natural language instructions
about what we need this agent

01:24:06.210 --> 01:24:07.980
to do and how to react.

01:24:07.980 --> 01:24:11.940
And a grounding in the knowledge
from our organization.

01:24:11.940 --> 01:24:13.560
You know, here are our policies.

01:24:13.560 --> 01:24:16.440
Here's what happens when
an incident occurs.

01:24:16.440 --> 01:24:17.700
But, folks, these agents

01:24:17.700 --> 01:24:20.820
in Copilot Studio now are not
just waiting for somebody

01:24:20.820 --> 01:24:23.250
to ask them a question and
answer it on a document.

01:24:23.250 --> 01:24:24.840
This isn't just a chatbot.

01:24:24.840 --> 01:24:27.240
Agents also have tools,

01:24:27.240 --> 01:24:30.180
skills to do work inside
of the organization.

01:24:30.180 --> 01:24:32.430
And, you know, because
Copilot Studio is part

01:24:32.430 --> 01:24:33.840
of Power Platform, we have more

01:24:33.840 --> 01:24:36.600
than 1,500 connectors
out of the box.

01:24:36.600 --> 01:24:39.150
Everything from
Acumatica to Zendesk.

01:24:39.150 --> 01:24:42.060
If it's got an API, you can
work with it with an agent.

01:24:42.060 --> 01:24:43.470
But, as Charles mentioned,

01:24:43.470 --> 01:24:46.380
we're also now supporting
new open standards

01:24:46.380 --> 01:24:48.780
like model context protocol,

01:24:48.780 --> 01:24:51.420
you know, to be able to go
hook up to MCP servers.

01:24:51.420 --> 01:24:54.900
And here's one that I've, you
know, created inside of CSX

01:24:54.900 --> 01:24:56.960
to work with some of our
compliance documents.

01:24:56.960 --> 01:25:00.170
I can authenticate it to it and
pull through all of those skills

01:25:00.170 --> 01:25:03.540
and capabilities, keep them
automatically up to date.

01:25:03.540 --> 01:25:06.150
But I also want to
give this agent skills

01:25:06.150 --> 01:25:07.800
and tools of its own, right?

01:25:07.800 --> 01:25:11.070
And one of those important ways
to do it is with a prompt.

01:25:11.070 --> 01:25:13.170
So I can create very
custom prompts.

01:25:13.170 --> 01:25:16.470
I'm going to paste in a pretty
specific set of instructions

01:25:16.470 --> 01:25:18.000
for how I want this
agent to react

01:25:18.000 --> 01:25:19.680
when a new incident occurs.

01:25:19.680 --> 01:25:24.030
And I'm going to select now
from any model at my disposal.

01:25:24.030 --> 01:25:27.870
In fact, I've got a version of
the DeepSeek reasoning model

01:25:27.870 --> 01:25:29.310
that I've fine-tuned

01:25:29.310 --> 01:25:32.340
and post-trained in
Azure AI Foundry.

01:25:32.340 --> 01:25:36.600
And now, like any AI model in
Foundry, I can bring it here

01:25:36.600 --> 01:25:38.850
into Copilot Studio
and see how it's going

01:25:38.850 --> 01:25:40.950
to perform in my agent.

01:25:40.950 --> 01:25:44.610
And that means I can have my
most advanced AI developers

01:25:44.610 --> 01:25:47.400
and data scientists do
that foundational work

01:25:47.400 --> 01:25:50.280
and then consume it up here in
Copilot Studio for hundreds

01:25:50.280 --> 01:25:51.180
or thousands of agents.

01:25:51.180 --> 01:25:53.520
And so you see, DeepSeek
took a minute to reason

01:25:53.520 --> 01:25:56.220
over that and brought back
a pretty verbose response

01:25:56.220 --> 01:25:58.890
and did exactly what I asked
it to do in the prompt.

01:25:58.890 --> 01:26:01.800
And I can use this really
high-productivity test harness

01:26:01.800 --> 01:26:04.740
to iterate and get it to
do exactly what I need.

01:26:04.740 --> 01:26:07.110
Now, the thing is,
not everything

01:26:07.110 --> 01:26:08.340
in our modern organizations

01:26:08.340 --> 01:26:11.730
yet has an MCP server
or even a REST API.

01:26:11.730 --> 01:26:13.650
And that's where another
really important tool

01:26:13.650 --> 01:26:18.170
for agents is the ability to
just use computers directly.

01:26:18.170 --> 01:26:21.320
And we're really excited to
have computer use now be part

01:26:21.320 --> 01:26:22.520
of Copilot Studio.

01:26:22.520 --> 01:26:25.670
And I've set up a computer
use capability here.

01:26:25.670 --> 01:26:27.170
I've authenticated it already

01:26:27.170 --> 01:26:29.850
to a virtual machine that's
running some software inside

01:26:29.850 --> 01:26:30.420
of CSX.

01:26:30.420 --> 01:26:33.720
And I've provided it some very
plain-spoken instructions

01:26:33.720 --> 01:26:35.670
about how to use that computer.

01:26:35.670 --> 01:26:40.050
Go to this website, open a
certain screen and do some work.

01:26:40.050 --> 01:26:43.020
And what's cool is that I
can just watch, right inside

01:26:43.020 --> 01:26:45.900
of this test harness,
my agent fire up

01:26:45.900 --> 01:26:47.400
and get those things
ready for me.

01:26:47.400 --> 01:26:49.290
It's going to connect
with the virtual machine.

01:26:49.290 --> 01:26:51.210
It's going to
initialize a session.

01:26:51.210 --> 01:26:53.340
And then pretty soon, it's going
to just start using software.

01:26:53.340 --> 01:26:57.240
I mean, this is night and day
different from things like RPA

01:26:57.240 --> 01:26:59.310
of the past, where
I would have had to

01:26:59.310 --> 01:27:02.400
script and granularly
record every single click

01:27:02.400 --> 01:27:04.140
and hope that nothing changed.

01:27:04.140 --> 01:27:06.810
Now the agent can
use a computer just

01:27:06.810 --> 01:27:08.880
like a person can.

01:27:08.880 --> 01:27:12.210
But look, those are all
very cool tools for agents.

01:27:12.210 --> 01:27:14.280
But do you want to know
what the most powerful tool

01:27:14.280 --> 01:27:16.260
for an agent is?

01:27:16.260 --> 01:27:18.350
It's another agent, right?

01:27:18.350 --> 01:27:22.940
And now Copilot Studio supports
multi-agent orchestration.

01:27:22.940 --> 01:27:25.220
And so I can come in
here and add agents,

01:27:25.220 --> 01:27:27.920
not even just other
Copilot Studio agents,

01:27:27.920 --> 01:27:30.200
but agents from Fabric,
agents from Foundry,

01:27:30.200 --> 01:27:33.090
agents using the
Microsoft 365 SDK.

01:27:33.090 --> 01:27:36.720
And I can build a team of
agents to work together.

01:27:36.720 --> 01:27:37.260
So what do you think?

01:27:37.260 --> 01:27:38.760
Should we send
this team to work?

01:27:38.760 --> 01:27:42.330
Should we see how they react to
that incident we just received?

01:27:42.330 --> 01:27:43.680
I'm going to put in
just a little bit

01:27:43.680 --> 01:27:46.290
of information here
about the incident.

01:27:46.290 --> 01:27:47.040
Let's try that again.

01:27:47.040 --> 01:27:48.030
I clicked the wrong button.

01:27:48.030 --> 01:27:49.740
Put in a little bit of
information about the incident,

01:27:49.740 --> 01:27:53.700
and we're going to see these
agents get to work in real time.

01:27:53.700 --> 01:27:54.900
Let's see how they do.

01:27:54.900 --> 01:27:56.970
Sure enough, we're
already filing a report.

01:27:56.970 --> 01:27:59.730
And then the inspection agent is
going to pick it up and go look

01:27:59.730 --> 01:28:01.560
for information about
that locomotive.

01:28:01.560 --> 01:28:03.780
The crew management agent
is going to wake somebody

01:28:03.780 --> 01:28:05.790
up in the middle of the night
and get a crew dispatch.

01:28:05.790 --> 01:28:08.640
And the route availability agent
is already trying to figure

01:28:08.640 --> 01:28:09.690
out how to reroute trains.

01:28:09.690 --> 01:28:12.180
Now, that is a pretty
fast response.

01:28:12.180 --> 01:28:13.020
What do you think, Charles?

01:28:13.020 --> 01:28:16.330
I think we're going to get this
thing back on track in no time.

01:28:16.355 --> 01:28:21.300
[ Applause ]

01:28:21.300 --> 01:28:22.650
Charles Lamanna:
The first demo ever

01:28:22.650 --> 01:28:24.090
that involved a train crossing.

01:28:24.090 --> 01:28:25.710
So thank you, Ryan.

01:28:25.710 --> 01:28:27.150
So you think about these agents.

01:28:27.150 --> 01:28:28.860
They're working in
the background.

01:28:28.860 --> 01:28:30.420
You know, they're helping
with the scheduling,

01:28:30.420 --> 01:28:33.540
the dispatching the workers
out to look at the rail cars.

01:28:33.540 --> 01:28:36.600
But you also are going to
want apps in the foreground

01:28:36.600 --> 01:28:40.080
that people and agents can use
together to get the job done.

01:28:40.080 --> 01:28:42.390
Which means you're going
to need a new type

01:28:42.390 --> 01:28:44.460
of application experience.

01:28:44.460 --> 01:28:47.100
So Power Apps makes
it easy to do this.

01:28:47.100 --> 01:28:50.580
It already provides that
full-stack experience.

01:28:50.580 --> 01:28:55.230
UI development, middleware,
connectors, a data platform,

01:28:55.230 --> 01:28:57.570
all in one integrated
SaaS offering.

01:28:57.570 --> 01:29:02.100
But now you can layer on agents
to that same secure platform.

01:29:02.100 --> 01:29:05.280
And these agents can work with
the apps and in the background.

01:29:05.280 --> 01:29:06.000
So I'm going to hand it back

01:29:06.000 --> 01:29:08.490
over to Ryan to
show us in action.

01:29:08.490 --> 01:29:09.270
Ryan Cunningham: All right.

01:29:09.270 --> 01:29:11.250
So agents are off doing work.

01:29:11.250 --> 01:29:14.040
But what does that mean for
the experience of the humans?

01:29:14.040 --> 01:29:16.170
Right? To take a look at that,

01:29:16.170 --> 01:29:18.060
I'm going to put on
my operator hat.

01:29:18.060 --> 01:29:21.030
Right? So we're going
to go into the control room

01:29:21.030 --> 01:29:24.660
at CSX and look at a whole
new type of application

01:29:24.660 --> 01:29:25.710
for working with agents.

01:29:25.710 --> 01:29:27.930
Now, this is not your
uncle's Power App.

01:29:27.930 --> 01:29:30.270
It is not just about
manual data entry.

01:29:30.270 --> 01:29:33.060
In fact, a lot of the agents
are doing that work for us.

01:29:33.060 --> 01:29:36.240
And now I'm looking
at a feed of activity

01:29:36.240 --> 01:29:37.740
of what those agents are doing.

01:29:37.740 --> 01:29:39.420
And I'm playing
the role, in fact,

01:29:39.420 --> 01:29:42.600
of a regional agent
manager at CSX.

01:29:42.600 --> 01:29:46.410
And I have a number of agents
that are under my supervision.

01:29:46.410 --> 01:29:49.320
And I can zoom in and see
all the work they're doing

01:29:49.320 --> 01:29:51.480
autonomously on my behalf.

01:29:51.480 --> 01:29:53.430
And I can spot check it
and make sure that they're

01:29:53.430 --> 01:29:54.690
on the straight and narrow.

01:29:54.690 --> 01:29:57.180
But look, agents
will not do 100%

01:29:57.180 --> 01:29:59.670
of the things 100% of the time.

01:29:59.670 --> 01:30:01.740
They will also need my help.

01:30:01.740 --> 01:30:01.950
Right?

01:30:01.950 --> 01:30:03.510
And here's where
I can zoom in to

01:30:03.510 --> 01:30:05.130
where the agents
need assistance.

01:30:05.130 --> 01:30:08.580
And, in fact, I can see here
exactly the chain of thought

01:30:08.580 --> 01:30:10.320
and process that an agent took

01:30:10.320 --> 01:30:12.450
and where it got stuck
creating an incident.

01:30:12.450 --> 01:30:15.660
And I can drill right in
to that particular record

01:30:15.660 --> 01:30:17.610
and get this agent
unblocked quickly.

01:30:17.610 --> 01:30:19.590
And that's why it's
so important for this

01:30:19.590 --> 01:30:21.900
to be inside of an application.

01:30:21.900 --> 01:30:23.160
But unblocking agents

01:30:23.160 --> 01:30:25.590
or correcting them is
only one type of work.

01:30:25.590 --> 01:30:29.430
Agents can also notice
trends and point out things

01:30:29.430 --> 01:30:32.610
that I might not even
notice myself as a human.

01:30:32.610 --> 01:30:34.410
And I can partner
with them inside

01:30:34.410 --> 01:30:36.210
of this application
to go investigate.

01:30:36.210 --> 01:30:39.570
Let's go say, let's only look
at the most severe incidents

01:30:39.570 --> 01:30:41.040
and let's show them in
the southern states

01:30:41.040 --> 01:30:42.390
and show it to me by month.

01:30:42.390 --> 01:30:46.080
I can be very plain spoken in
my interactions with the agent.

01:30:46.080 --> 01:30:48.390
And not only will it think
about that and think

01:30:48.390 --> 01:30:50.970
about the best way to
filter that table,

01:30:50.970 --> 01:30:54.990
it will also generate,
dynamically, user experiences

01:30:54.990 --> 01:30:56.550
for me to go explore
that question.

01:30:56.550 --> 01:30:58.590
That chart never existed before.

01:30:58.590 --> 01:30:59.670
You know, no developer had

01:30:59.670 --> 01:31:01.410
to write the front
end code with D3.

01:31:01.410 --> 01:31:04.200
No data scientist had
to go build a cube.

01:31:04.200 --> 01:31:07.020
It's just automatically
generated dynamically right

01:31:07.020 --> 01:31:08.130
at runtime.

01:31:08.130 --> 01:31:10.350
Now, that begs an
interesting question.

01:31:10.350 --> 01:31:14.400
Now, what is the role for us
as developers in this world

01:31:14.400 --> 01:31:18.150
where agents can generate
user experience on the fly?

01:31:18.150 --> 01:31:22.950
And for that, I'm going to
switch back to my developer app.

01:31:22.950 --> 01:31:24.720
And we're going to
go use Power Apps.

01:31:24.720 --> 01:31:28.950
But this is a very different
type of Power Apps experience

01:31:28.950 --> 01:31:31.230
than what you may be
used to in the past.

01:31:31.230 --> 01:31:34.050
We have completely reimagined
Power Apps from the ground

01:31:34.050 --> 01:31:36.120
up in a world of agents first.

01:31:36.120 --> 01:31:38.160
And so I'm going to
start with a prompt here

01:31:38.160 --> 01:31:40.110
that really doesn't have
anything to do with tech.

01:31:40.110 --> 01:31:42.720
It starts with our business
problem and our challenge,

01:31:42.720 --> 01:31:45.750
just like I would send an
email to a technical team.

01:31:45.750 --> 01:31:48.000
And in fact, that's
exactly what we've created

01:31:48.000 --> 01:31:50.880
in this new capability
for building a plan.

01:31:50.880 --> 01:31:55.200
You'll see we have a digital
team of agents built right

01:31:55.200 --> 01:31:59.040
into Power Apps that function
as an innovation team.

01:31:59.040 --> 01:32:02.460
The requirements agent picked up
that prompt and started thinking

01:32:02.460 --> 01:32:05.760
about, "Who are the users? What
jobs to be done do they have?

01:32:05.760 --> 01:32:07.530
What are their user stories?"

01:32:07.530 --> 01:32:09.720
And that's one of
multiple agents

01:32:09.720 --> 01:32:13.650
that I'm live co-authoring
with right here in line.

01:32:13.650 --> 01:32:16.500
The process agent picked
up and started mapping

01:32:16.500 --> 01:32:20.370
from those user stories how
an actual process would flow

01:32:20.370 --> 01:32:22.170
and where would the
AI agents do work

01:32:22.170 --> 01:32:23.640
and where would the
humans do work.

01:32:23.640 --> 01:32:25.860
Now, of course, all of this
is something I can edit.

01:32:25.860 --> 01:32:27.000
I can add new steps.

01:32:27.000 --> 01:32:28.200
I can drag and drop.

01:32:28.200 --> 01:32:31.710
I can partner with the agents
at every step of the way.

01:32:31.710 --> 01:32:34.200
But it becomes an
important foundation

01:32:34.200 --> 01:32:35.670
for building software.

01:32:35.670 --> 01:32:38.370
So when I'm happy with the
requirements and the processes,

01:32:38.370 --> 01:32:41.760
now agents will generate
a data model for me.

01:32:41.760 --> 01:32:44.490
And in fact, in seconds here,
the data agent has picked this

01:32:44.490 --> 01:32:48.060
up and built a complex,
relational data model

01:32:48.060 --> 01:32:52.470
over Microsoft Dataverse, the
same platform we run complex,

01:32:52.470 --> 01:32:55.800
multibillion-dollar CRM
and ERP estates on top of.

01:32:55.800 --> 01:32:58.350
This is the kind of
scale and sophistication

01:32:58.350 --> 01:33:00.120
that a Vibe coder
could only dream

01:33:00.120 --> 01:33:04.350
of, at my fingertips, working
with agents in real time.

01:33:04.350 --> 01:33:06.750
And, of course, when I'm happy
with my data model and I'm happy

01:33:06.750 --> 01:33:09.450
with my stories, a solution
architect agent will go

01:33:09.450 --> 01:33:11.820
recommend all of the
individual pieces

01:33:11.820 --> 01:33:13.950
of technology for me to build.

01:33:13.950 --> 01:33:15.570
Now, the cool part about all

01:33:15.570 --> 01:33:19.410
of this is it's not just
an abstract plan, right?

01:33:19.410 --> 01:33:21.240
This is power platform.

01:33:21.240 --> 01:33:24.180
And so I can take these assets
that we're recommending

01:33:24.180 --> 01:33:26.820
and actually generate
them in seconds.

01:33:26.820 --> 01:33:29.910
And as a developer, go say,
"Great, let's build that app

01:33:29.910 --> 01:33:32.700
for safety incident tracking",
fire it up over the data

01:33:32.700 --> 01:33:35.880
that the data agent generated,
and in a few seconds here,

01:33:35.880 --> 01:33:38.160
see that app working
in real time,

01:33:38.160 --> 01:33:41.460
pulling through all those
great AI features and all

01:33:41.460 --> 01:33:43.710
of the context from the plan.

01:33:43.710 --> 01:33:49.110
And, in fact, even all of those
agents are here with me as well,

01:33:49.110 --> 01:33:53.250
right, ready to go help me move
this business process forward.

01:33:53.250 --> 01:33:54.690
And this is how we're
going to do it, folks.

01:33:54.690 --> 01:33:58.080
1.3 billion agents, right?

01:33:58.080 --> 01:33:59.520
I mean, we saw
some amazing tools

01:33:59.520 --> 01:34:01.110
from Jay's team this morning
about how we're going

01:34:01.110 --> 01:34:02.700
to lay the foundation for
that and how we're going

01:34:02.700 --> 01:34:04.500
to do the hardest
parts of the problem.

01:34:04.500 --> 01:34:07.350
But for that size and
scale, for the developers

01:34:07.350 --> 01:34:10.020
who wear all kinds of other
hats in the organization,

01:34:10.020 --> 01:34:11.910
this is where we need platforms.

01:34:11.910 --> 01:34:14.670
It's where Copilot Studio will
help us build the agents,

01:34:14.670 --> 01:34:17.700
where Power Apps will help
us build the experiences,

01:34:17.700 --> 01:34:21.300
and together, we're going to
change the way the world works.

01:34:21.300 --> 01:34:21.780
Thank you all.

01:34:21.780 --> 01:34:22.590
Back to you, Charles.

01:34:22.590 --> 01:34:28.410
[ Applause ]

01:34:28.410 --> 01:34:28.740
Charles Lamanna: Awesome.

01:34:28.740 --> 01:34:30.090
Thank you, Ryan.

01:34:30.090 --> 01:34:32.040
And what we see is collaboration
is going to happen

01:34:32.040 --> 01:34:35.460
in more places than just
inside of applications.

01:34:35.460 --> 01:34:37.530
We're also going to have
Teams being the place

01:34:37.530 --> 01:34:40.650
where we work together, and it's
the best collaboration space

01:34:40.650 --> 01:34:42.630
that we already know and love.

01:34:42.630 --> 01:34:48.900
And today, 320 million people
are already using Teams every

01:34:48.900 --> 01:34:50.340
single day.

01:34:50.340 --> 01:34:53.280
And there's going to be a new
set of hundreds of millions

01:34:53.280 --> 01:34:56.880
of agents that will also be
showing up inside of Teams.

01:34:56.880 --> 01:35:00.480
It's the number one place for
collaboration between people

01:35:00.480 --> 01:35:02.340
and agents as we move forward.

01:35:02.340 --> 01:35:05.340
Whether it's in a chat or in
a channel or in a meeting

01:35:05.340 --> 01:35:07.170
or in a call, you will
have this ability

01:35:07.170 --> 01:35:10.650
to very easily interact
with these AI agents.

01:35:10.650 --> 01:35:13.740
And as we go make that
easier for developers,

01:35:13.740 --> 01:35:17.160
Teams AI Library is
the missing piece.

01:35:17.160 --> 01:35:19.830
It makes it easy to bring
your agents that you build

01:35:19.830 --> 01:35:22.200
and host wherever you
want, with whatever model

01:35:22.200 --> 01:35:24.480
and whatever back-end
infrastructure that you want,

01:35:24.480 --> 01:35:27.750
to have it show up right
inside of Microsoft Teams.

01:35:27.750 --> 01:35:31.410
And that makes it easy so all
the AI agents have one place

01:35:31.410 --> 01:35:32.970
to go and collaborate.

01:35:32.970 --> 01:35:35.730
And to show that in action,
I'm excited to welcome Farrah

01:35:35.730 --> 01:35:38.400
to the stage to
demo it end-to-end.

01:35:38.400 --> 01:35:39.090
Take it away, Farah.

01:35:39.090 --> 01:35:42.455
[ Applause ]

01:35:42.480 --> 01:35:44.340
Farah Shariff:
Thank you, Charles.

01:35:44.340 --> 01:35:46.560
Well, I didn't bring any
cool hats for my demo,

01:35:46.560 --> 01:35:49.170
but I'll show you
some cool stuff.

01:35:49.170 --> 01:35:53.280
All right. So you just heard
Charles describe Teams

01:35:53.280 --> 01:35:55.980
as the collaboration
space for you to interact

01:35:55.980 --> 01:36:00.090
with both your coworkers
and your agents together.

01:36:00.090 --> 01:36:02.820
So let's jump in and
see it in action.

01:36:02.820 --> 01:36:03.930
You can see that the agent

01:36:03.930 --> 01:36:07.320
that Ryan built earlier has
shared the new crew roster

01:36:07.320 --> 01:36:09.780
schedule in this
Teams group chat.

01:36:09.780 --> 01:36:13.260
And in the chat, you can see
that along with my coworkers,

01:36:13.260 --> 01:36:16.020
I also have the agent in it.

01:36:16.020 --> 01:36:20.430
This allows us to access
critical information right here

01:36:20.430 --> 01:36:23.340
in the flow of work, whether
that information is coming

01:36:23.340 --> 01:36:26.370
from people or agents.

01:36:26.370 --> 01:36:30.840
Now, let me join my Teams
meeting, my daily stand-up,

01:36:30.840 --> 01:36:33.090
where I talk about the
most pressing issues

01:36:33.090 --> 01:36:36.300
with my fellow engineers and
see how agents can help.

01:36:36.300 --> 01:36:37.530
Hey, team.

01:36:37.530 --> 01:36:39.990
Thanks for joining me at Build.

01:36:39.990 --> 01:36:43.260
So I'm clearly late to this
meeting, but you can see

01:36:43.260 --> 01:36:45.930
that the notes and actions
from the discussion

01:36:45.930 --> 01:36:49.590
so far are already getting
populated here thanks

01:36:49.590 --> 01:36:54.540
to the facilitator agent, a
pre-built Microsoft agent.

01:36:54.540 --> 01:36:57.300
And again, along
with my coworkers,

01:36:57.300 --> 01:37:02.190
you can see that I also
have a stand-up agent here.

01:37:02.190 --> 01:37:04.830
I'll show you in a second
how I built this agent,

01:37:04.830 --> 01:37:07.590
but this is essentially here to
help bubble up topics for us

01:37:07.590 --> 01:37:14.790
to discuss, including topics
sent over by other agents,

01:37:14.790 --> 01:37:18.150
such as the incident from
earlier today was sent

01:37:18.150 --> 01:37:22.620
over by the incident
response manager agent.

01:37:22.620 --> 01:37:27.750
And it uses the A2A protocol to
communicate with other agents,

01:37:27.750 --> 01:37:32.040
whether they're built in
Copilot Studio, Azure Foundry,

01:37:32.040 --> 01:37:34.050
Teams AI Library, and more.

01:37:34.050 --> 01:37:35.340
And you saw that I
didn't even have

01:37:35.340 --> 01:37:36.840
to add the incident agent here.

01:37:36.840 --> 01:37:40.140
It was just able to talk
to my stand-up agent.

01:37:40.140 --> 01:37:44.700
So let's switch gears and let
me show you how I built the

01:37:44.700 --> 01:37:48.540
stand-up agent using
the Teams AI Library.

01:37:48.540 --> 01:37:51.540
So just like you saw earlier
with Copilot Studio,

01:37:51.540 --> 01:37:54.180
you can also build
agents capable

01:37:54.180 --> 01:37:56.370
of using the A2A protocol

01:37:56.370 --> 01:38:02.040
and MCP using the newly
updated Teams AI Library.

01:38:02.040 --> 01:38:05.760
So the AI library is an SDK that
essentially takes care of a lot

01:38:05.760 --> 01:38:09.360
of the heavy lifting on
things like authentication,

01:38:09.360 --> 01:38:11.970
conversation
complexities of bots,

01:38:11.970 --> 01:38:14.850
integration with AI
models, et cetera.

01:38:14.850 --> 01:38:18.030
The result is not just
faster development,

01:38:18.030 --> 01:38:22.080
but also more capable
agents that are optimized

01:38:22.080 --> 01:38:26.520
for the human-to-agent
collaboration inside Teams

01:38:26.520 --> 01:38:30.510
and works across your
channels, chats, and meetings.

01:38:30.510 --> 01:38:33.030
So here's the stand-up
agent that I was using

01:38:33.030 --> 01:38:34.500
in the meeting just now.

01:38:34.500 --> 01:38:38.190
And as you can see, it took
about 50 lines of code

01:38:38.190 --> 01:38:43.260
to get it all up and running,
and just one line of code

01:38:43.260 --> 01:38:46.410
to enable the A2A protocol.

01:38:46.410 --> 01:38:52.470
Now let's say that I want to
use MCP to also enable my agent

01:38:52.470 --> 01:38:54.750
to access the train schedules.

01:38:54.750 --> 01:38:59.970
Well, again, it is just one
line of code to do that.

01:38:59.970 --> 01:39:04.050
And that's because the Teams
AI Library handles the

01:39:04.050 --> 01:39:06.570
orchestration with
the MCP server,

01:39:06.570 --> 01:39:09.570
regardless of your AI model.

01:39:09.570 --> 01:39:12.000
It is that easy.

01:39:12.000 --> 01:39:16.080
And with the right SDK, you
will always stay on track

01:39:16.080 --> 01:39:18.270
and never get derailed.

01:39:18.270 --> 01:39:19.320
Back to you, Charles.

01:39:19.320 --> 01:39:23.670
[ Applause ]

01:39:23.670 --> 01:39:25.800
Charles Lamanna:
Thank you, Farah.

01:39:25.800 --> 01:39:28.290
And as we think about all
of these agents showing

01:39:28.290 --> 01:39:31.830
up across our applications,
our teams, and in more places,

01:39:31.830 --> 01:39:33.750
we're going to need
to secure them.

01:39:33.750 --> 01:39:37.230
And that's where we have an
incredible set of capabilities.

01:39:37.230 --> 01:39:40.980
Entra manages identities so your
agents behave just like users

01:39:40.980 --> 01:39:44.400
or apps do today in
your entire directory.

01:39:44.400 --> 01:39:47.010
We have Purview to
discover, manage, label,

01:39:47.010 --> 01:39:51.060
and protect all your data as it
flows throughout Copilot Teams,

01:39:51.060 --> 01:39:53.430
Copilot Studio, and more.

01:39:53.430 --> 01:39:57.900
And we have all this wired up
into a single managed platform.

01:39:57.900 --> 01:40:00.450
To show this, I'm excited
to welcome Shilpa on stage,

01:40:00.450 --> 01:40:03.420
who will highlight all this
great security features.

01:40:03.420 --> 01:40:05.610
Shilpa Ranganathan:
Thank you, Charles.

01:40:05.610 --> 01:40:07.800
Hello, everyone.

01:40:07.800 --> 01:40:10.500
As developers, we're
all creating agents

01:40:10.500 --> 01:40:12.120
that act autonomously.

01:40:12.120 --> 01:40:14.850
But with that power
comes responsibility,

01:40:14.850 --> 01:40:17.370
especially when it
comes to data security.

01:40:17.370 --> 01:40:20.100
Microsoft Purview adds
built-in guardrails

01:40:20.100 --> 01:40:24.000
so that your agents don't
end up accessing, exposing,

01:40:24.000 --> 01:40:26.460
or leaking sensitive
data incorrectly,

01:40:26.460 --> 01:40:28.890
be it during development
or at runtime.

01:40:28.890 --> 01:40:31.230
Let's have a look.

01:40:31.230 --> 01:40:33.180
Here, I'm in Copilot Studio.

01:40:33.180 --> 01:40:35.820
I'm using the same
agent from Ryan.

01:40:35.820 --> 01:40:40.230
It's already set up with all
of the triggers and actions.

01:40:40.230 --> 01:40:43.410
And now, it's time to
train this agent to work

01:40:43.410 --> 01:40:47.520
against CSX organizational
data, like shipments,

01:40:47.520 --> 01:40:49.830
routes, all that fancy stuff.

01:40:49.830 --> 01:40:53.160
I've already created all of
these knowledge sources.

01:40:53.160 --> 01:40:55.240
Let's take a deeper look.

01:40:56.970 --> 01:41:01.390
Here, I'm looking at a customer
accounts table in Dataverse.

01:41:04.230 --> 01:41:07.560
Thanks to Purview's built-in
sensitivity labels,

01:41:07.560 --> 01:41:12.160
I can see that this data is
labeled and protected correctly.

01:41:14.100 --> 01:41:16.770
Now, let's look at a
different knowledge source.

01:41:16.770 --> 01:41:20.670
Here, I'm in SharePoint, and
this is where CSX is storing all

01:41:20.670 --> 01:41:23.170
of its organizational data.

01:41:28.950 --> 01:41:32.580
Here, again, I can see that
all of this data is labeled

01:41:32.580 --> 01:41:34.140
and protected correctly.

01:41:34.140 --> 01:41:37.620
And so, it's safe
for agents to use.

01:41:37.620 --> 01:41:40.560
With all of this set up,
now let's switch cabins

01:41:40.560 --> 01:41:43.590
and take a look at how all
of this works for the people

01:41:43.590 --> 01:41:47.610
at CSX using these agents.

01:41:47.610 --> 01:41:49.680
Here, I'm in Copilot Studio.

01:41:49.680 --> 01:41:53.100
I'm using the same agent again,
and I'm asking it for shipments

01:41:53.100 --> 01:41:54.360
that have been delayed.

01:41:54.360 --> 01:41:57.480
My agent has gone to work,
and it's got me some details.

01:41:57.480 --> 01:41:59.250
Let's unpack.

01:41:59.250 --> 01:42:02.970
First and foremost, my agent is
working against labeled data.

01:42:02.970 --> 01:42:07.020
So it's only going to return
to me what I'm allowed to see.

01:42:07.020 --> 01:42:10.890
Second, it's also
telling me very clearly

01:42:10.890 --> 01:42:14.160
in its answer what is the
label of this content

01:42:14.160 --> 01:42:16.680
and enforcing those protections.

01:42:16.680 --> 01:42:18.150
Why is that important?

01:42:18.150 --> 01:42:22.200
Well, now I know how to
handle this data as well.

01:42:22.200 --> 01:42:24.510
But wait, this offer
doesn't end here.

01:42:24.510 --> 01:42:27.400
Your agent has done even better.

01:42:28.770 --> 01:42:31.950
It's inherited the
most restrictive label

01:42:31.950 --> 01:42:35.220
of all the answers
for its output.

01:42:35.220 --> 01:42:36.420
What does that mean?

01:42:36.420 --> 01:42:39.690
You can take this output,
create a page out of it,

01:42:39.690 --> 01:42:42.600
create a Word document,
whatever you choose.

01:42:42.600 --> 01:42:48.060
The same label and corresponding
protections apply there as well.

01:42:48.060 --> 01:42:51.510
All AI-generated content
is automatically labeled

01:42:51.510 --> 01:42:53.070
and protected.

01:42:53.070 --> 01:42:57.180
With label inheritance, Purview
adds data security right

01:42:57.180 --> 01:42:58.620
into your agent's logic.

01:42:58.620 --> 01:43:00.600
Isn't that cool?

01:43:00.600 --> 01:43:02.250
All right.

01:43:02.250 --> 01:43:04.890
At our next arrival station,

01:43:04.890 --> 01:43:07.470
let's look at a data leak
prevention scenario.

01:43:07.470 --> 01:43:11.100
Here, I'm going to ask the
agent for some customer details

01:43:11.100 --> 01:43:15.250
that I know contains PII
and should not be shared.

01:43:16.800 --> 01:43:20.340
For the first time on stage,
I'm excited and happy

01:43:20.340 --> 01:43:22.020
to see an error message.

01:43:22.020 --> 01:43:24.480
The agent actually
did the right thing.

01:43:24.480 --> 01:43:26.550
This is Purview DLP in action

01:43:26.550 --> 01:43:30.240
for you that's preventing
your agent from summarizing

01:43:30.240 --> 01:43:32.310
and leaking sensitive data,

01:43:32.310 --> 01:43:36.360
all based on that
same built-in label.

01:43:36.360 --> 01:43:38.610
From development to deployment,

01:43:38.610 --> 01:43:42.060
we saw how your agents
can be secure by design,

01:43:42.060 --> 01:43:44.310
all powered by
Microsoft Purview.

01:43:44.310 --> 01:43:48.210
No hacks, no heavy
lifting, just smart,

01:43:48.210 --> 01:43:51.720
policy-driven enforcements
built right in.

01:43:51.720 --> 01:43:54.750
You know, your world's most
famous agent, James Bond,

01:43:54.750 --> 01:43:58.140
he doesn't go out there without
his gizmos and gadgetries.

01:43:58.140 --> 01:44:00.030
Why would you let your
agents go out there

01:44:00.030 --> 01:44:02.220
without Purview when
it's that easy?

01:44:02.220 --> 01:44:03.540
Over to you, Charles.

01:44:03.540 --> 01:44:07.061
[ Applause ]

01:44:07.086 --> 01:44:07.710
Charles Lamanna: Awesome.

01:44:07.710 --> 01:44:09.540
Thank you, Shilpa.

01:44:09.540 --> 01:44:11.190
And as we look at what
we're trying to do

01:44:11.190 --> 01:44:13.260
with all these security
capabilities, whether it's

01:44:13.260 --> 01:44:15.540
in Copilot or Studio or Foundry,

01:44:15.540 --> 01:44:18.420
it's all about making it
be secure by default.

01:44:18.420 --> 01:44:21.570
So Entra and Purview protect
your apps and your users,

01:44:21.570 --> 01:44:23.370
just like they've been
doing for decades.

01:44:23.370 --> 01:44:26.520
Additionally, they now
protect all the AI workflows

01:44:26.520 --> 01:44:28.380
and experiences that
you're developing.

01:44:28.380 --> 01:44:32.190
So all those existing security
models continue to work.

01:44:32.190 --> 01:44:36.750
So it's one model for
agents, people, and apps.

01:44:36.750 --> 01:44:39.300
And with all of this being
so simple and integrated

01:44:39.300 --> 01:44:42.810
into the platform, there's
no reason to wait.

01:44:42.810 --> 01:44:45.780
You can go build these
amazing agents today,

01:44:45.780 --> 01:44:47.970
no matter what your IT
landscape looks like,

01:44:47.970 --> 01:44:51.480
and there's no reason to not
go be ambitious and bold

01:44:51.480 --> 01:44:52.950
with how they show up.

01:44:52.950 --> 01:44:57.330
So all of these AI capabilities
that you've seen so far today,

01:44:57.330 --> 01:45:01.440
they need world-class
cloud and infrastructure.

01:45:01.440 --> 01:45:04.020
And to show all of that in
action, Scott's going to step

01:45:04.020 --> 01:45:07.530
through some of the incredible
details of how the cloud runs.

01:45:07.530 --> 01:45:10.410
So I'm going to hand it off to
Scott, but just a huge "thank you"

01:45:10.410 --> 01:45:12.180
for sticking together
for our entire demos.

01:45:12.180 --> 01:45:20.655
[ Applause ]

01:45:20.680 --> 01:45:21.660
Scott Guthrie:
Well, good morning,

01:45:21.660 --> 01:45:24.780
everyone, and welcome to Build.

01:45:24.780 --> 01:45:26.640
Yesterday, Satya talked

01:45:26.640 --> 01:45:29.790
about how we're offering
the lowest-cost,

01:45:29.790 --> 01:45:32.460
highest-scale infrastructure
for both cloud

01:45:32.460 --> 01:45:35.040
and next-generation
AI workloads.

01:45:35.040 --> 01:45:36.630
Today, I'm going to dive deeper

01:45:36.630 --> 01:45:39.690
into the infrastructure that's
powering everything you've seen

01:45:39.690 --> 01:45:42.660
over the last two days, and give
you a behind-the-scenes tour

01:45:42.660 --> 01:45:43.770
of some of the innovations

01:45:43.770 --> 01:45:47.280
and optimizations we're
bringing to Microsoft Azure.

01:45:47.280 --> 01:45:52.440
So today, Microsoft has over 70
Azure regions live worldwide,

01:45:52.440 --> 01:45:54.720
more than any other
cloud provider.

01:45:54.720 --> 01:45:55.650
And we're continuing

01:45:55.650 --> 01:45:58.470
to dramatically expand
our data center capacity

01:45:58.470 --> 01:46:00.480
and provide new data
residency options

01:46:00.480 --> 01:46:02.280
so that you can
put your services

01:46:02.280 --> 01:46:03.780
and your applications closer

01:46:03.780 --> 01:46:06.780
to your customers everywhere
around the world.

01:46:06.780 --> 01:46:10.560
This year alone, we'll add more
incremental data center capacity

01:46:10.560 --> 01:46:12.510
than we had across all
of our data centers

01:46:12.510 --> 01:46:15.090
in Azure just three years ago.

01:46:15.090 --> 01:46:17.700
And much of this data center
capacity is optimized

01:46:17.700 --> 01:46:20.010
specifically for AI.

01:46:20.010 --> 01:46:22.080
We've taken
AI-optimized innovation

01:46:22.080 --> 01:46:24.060
to an entirely new level.

01:46:24.060 --> 01:46:26.790
Let's zoom in on one of our
new, AI-optimized regions

01:46:26.790 --> 01:46:30.400
that will go live in
the coming months.

01:46:30.425 --> 01:47:04.897
[ Music ]

01:47:04.922 --> 01:47:06.360
So that video was one

01:47:06.360 --> 01:47:09.330
of our new Azure AI data
centers, and we're building

01:47:09.330 --> 01:47:12.240
out multiple other data
centers of the same size

01:47:12.240 --> 01:47:15.930
and the same design in
parallel around the world.

01:47:15.930 --> 01:47:19.740
These data centers run the most
advanced AI supercomputers,

01:47:19.740 --> 01:47:22.290
and that in turn
enables all of you

01:47:22.290 --> 01:47:25.170
to leverage even more
intelligent AI models

01:47:25.170 --> 01:47:27.450
at even lower cost.

01:47:27.450 --> 01:47:29.520
We recognize also
that with this power

01:47:29.520 --> 01:47:31.890
and scale comes responsibility.

01:47:31.890 --> 01:47:34.110
Microsoft is now one
of the largest buyers

01:47:34.110 --> 01:47:36.120
of renewable energy
in the world,

01:47:36.120 --> 01:47:39.540
already sourcing 34 gigawatts
of renewable energy,

01:47:39.540 --> 01:47:42.090
as well as other
zero carbon sources.

01:47:42.090 --> 01:47:43.380
And we're on track
to meet our goal

01:47:43.380 --> 01:47:46.800
to have our data centers powered
by 100% renewable energy

01:47:46.800 --> 01:47:48.840
by the end of this
calendar year.

01:47:48.840 --> 01:47:50.460
And this includes the
data center you just saw

01:47:50.460 --> 01:47:52.140
in this video, as
well as the others

01:47:52.140 --> 01:47:54.840
that we're building
out around the world.

01:47:54.840 --> 01:47:56.580
And we're not just
using renewable energy.

01:47:56.580 --> 01:47:58.350
We're also using
innovative approaches

01:47:58.350 --> 01:48:00.960
to further optimize
the sustainability

01:48:00.960 --> 01:48:02.970
of this AI infrastructure.

01:48:02.970 --> 01:48:05.040
One example is the use of wood

01:48:05.040 --> 01:48:07.470
in the construction
of our data centers.

01:48:07.470 --> 01:48:09.210
Now, wood may sound
kind of quaint

01:48:09.210 --> 01:48:12.780
and strangely old-fashioned,
but we're actually starting

01:48:12.780 --> 01:48:15.570
to use a hybrid data center
construction approach using

01:48:15.570 --> 01:48:17.490
cross-laminated timber.

01:48:17.490 --> 01:48:20.310
And this timber is a
fire-resistant wood material

01:48:20.310 --> 01:48:23.580
that we expect will reduce
the embodied carbon

01:48:23.580 --> 01:48:27.630
by 65% compared to typical
building structures.

01:48:27.630 --> 01:48:30.510
And we're piloting alternatives
to concrete foundations

01:48:30.510 --> 01:48:33.240
with the goal of lowering
the embodied carbon by more

01:48:33.240 --> 01:48:36.390
than 50% compared
to other sources

01:48:36.390 --> 01:48:38.100
and traditional concrete.

01:48:38.100 --> 01:48:41.280
Now, let's double-click into
the data center building,

01:48:41.280 --> 01:48:46.380
which will run a single, large
cluster of hundreds of thousands

01:48:46.380 --> 01:48:50.460
of interconnected
NVIDIA GB200 GPUs.

01:48:50.460 --> 01:48:53.310
GB200s are the
latest NVIDIA GPUs

01:48:53.310 --> 01:48:55.680
and are the most
advanced in the world.

01:48:55.680 --> 01:48:58.110
And Microsoft was the
first cloud provider

01:48:58.110 --> 01:49:01.920
to bring online the first
server, the first rack,

01:49:01.920 --> 01:49:07.050
and the first data center
running NVIDIA GB200s.

01:49:07.050 --> 01:49:09.630
And this provides the
most advanced AI training

01:49:09.630 --> 01:49:12.480
and inferencing
platform in the world.

01:49:12.480 --> 01:49:15.390
We have multiple customers,
including OpenAI,

01:49:15.390 --> 01:49:17.280
already running
production workloads

01:49:17.280 --> 01:49:19.470
on this infrastructure today.

01:49:19.470 --> 01:49:21.510
And there's some cloud
providers, like AWS,

01:49:21.510 --> 01:49:25.530
that still haven't
launched a GB200 offering.

01:49:25.530 --> 01:49:27.000
An interesting characteristic

01:49:27.000 --> 01:49:32.460
about the NVIDIA GB200s is the
density at which these GPUs run.

01:49:32.460 --> 01:49:35.220
They're literally packed
together in a single rack.

01:49:35.220 --> 01:49:39.510
There are 72 GB200 GPUs in a
single rack, all interconnected

01:49:39.510 --> 01:49:41.640
in a single NV-linked domain.

01:49:41.640 --> 01:49:45.690
And this allows you to train
and run a much larger AI model

01:49:45.690 --> 01:49:48.630
than previous
generations of hardware.

01:49:48.630 --> 01:49:50.280
But the challenge,
when you put lots

01:49:50.280 --> 01:49:53.010
of heat-generating components
together in a small space,

01:49:53.010 --> 01:49:55.350
is that you need
a lot of cooling.

01:49:55.350 --> 01:49:58.710
And these AI systems
are now so power-dense

01:49:58.710 --> 01:50:00.780
that you can't use
traditional air cooling,

01:50:00.780 --> 01:50:02.490
which is what almost
every data center has

01:50:02.490 --> 01:50:04.320
historically leveraged.

01:50:04.320 --> 01:50:06.990
Instead, you need to
use liquid cooling

01:50:06.990 --> 01:50:09.030
to efficiently
dispense the heat.

01:50:09.030 --> 01:50:11.700
And so on the left-hand
side here of this picture,

01:50:11.700 --> 01:50:14.220
you can see what a server rack
looks like with liquid cooling.

01:50:14.220 --> 01:50:16.140
You notice all the hoses.

01:50:16.140 --> 01:50:19.830
These hoses are continuously
circulating in cold liquid

01:50:19.830 --> 01:50:21.900
into the servers,
which cools them down,

01:50:21.900 --> 01:50:24.240
and then extracts
the hot liquid out.

01:50:24.240 --> 01:50:26.880
And the picture on the
right is of the trunk pipes

01:50:26.880 --> 01:50:29.490
and the ceiling above the
racks in the data center.

01:50:29.490 --> 01:50:32.370
These circulate the cold water
for the entire row of racks

01:50:32.370 --> 01:50:36.090
and then extract the hot
liquid from the data center.

01:50:36.090 --> 01:50:38.820
And this hot liquid then exits
the data center and goes

01:50:38.820 --> 01:50:41.160
through a cooling loop
where we cool the liquid

01:50:41.160 --> 01:50:44.010
down before we then feed it
back into the data center

01:50:44.010 --> 01:50:46.740
on a continuous,
closed-loop system.

01:50:46.740 --> 01:50:48.120
You can see in this
picture here one

01:50:48.120 --> 01:50:51.720
of the liquid cooling systems
attached to the data center.

01:50:51.720 --> 01:50:54.570
Each of these 80 units
contains a 20-foot fan

01:50:54.570 --> 01:50:58.170
that blows cold air on the
liquid as it circulates.

01:50:58.170 --> 01:51:00.600
And if you want to get a sense
of the size and scale of each

01:51:00.600 --> 01:51:03.360
of these fans, look at the
giant trucks in the background

01:51:03.360 --> 01:51:05.700
of this picture and look
how small they are compared

01:51:05.700 --> 01:51:08.160
to each of those fans.

01:51:08.160 --> 01:51:09.660
Now, the great thing about
a closed-loop system

01:51:09.660 --> 01:51:12.210
over traditional, evaporative
cooling techniques is

01:51:12.210 --> 01:51:14.190
that the water isn't wasted.

01:51:14.190 --> 01:51:17.160
It will continually circulate
between the servers and chillers

01:51:17.160 --> 01:51:20.040
to dissipate the heat without
requiring any additional

01:51:20.040 --> 01:51:21.300
water supply.

01:51:21.300 --> 01:51:24.210
In fact, all new Microsoft data
center designs going forward

01:51:24.210 --> 01:51:27.990
will use a zero-waste
water cooling method.

01:51:27.990 --> 01:51:35.460
[ Applause ]

01:51:35.460 --> 01:51:37.890
Now, as AI models
get more intelligent

01:51:37.890 --> 01:51:40.080
and AI workloads get bigger,

01:51:40.080 --> 01:51:42.810
they also need more
GPUs interconnected

01:51:42.810 --> 01:51:44.550
and operating as one.

01:51:44.550 --> 01:51:46.140
And one of the really
differentiated things

01:51:46.140 --> 01:51:48.960
about this data center
is that it operates

01:51:48.960 --> 01:51:52.740
as one, contiguous,
interconnected cluster of

01:51:52.765 --> 01:51:55.680
hundreds of thousands of GB200s.

01:51:55.680 --> 01:51:58.050
And our network had
to be hyper-optimized

01:51:58.050 --> 01:52:00.420
to enable this type
of interconnection.

01:52:00.420 --> 01:52:03.810
You know, as context, there's
enough network fiber cables

01:52:03.810 --> 01:52:07.290
inside this one data center
to wrap around the world four

01:52:07.290 --> 01:52:10.440
and a half times, just
inside that one building.

01:52:10.440 --> 01:52:11.820
And this is the type of scale

01:52:11.820 --> 01:52:13.620
and AI infrastructure
optimization

01:52:13.620 --> 01:52:17.820
that supports the most demanding
AI workloads in the world.

01:52:17.820 --> 01:52:19.800
Now, what makes this even
more impressive is the fact

01:52:19.800 --> 01:52:23.130
that we can combine multiple
Azure AI data centers

01:52:23.130 --> 01:52:27.720
around the world using our AI
Wide Area Network, or WAN.

01:52:27.720 --> 01:52:31.440
And this AI WAN supports
up to 400 terabits

01:52:31.440 --> 01:52:34.020
of network bandwidth,
making it the fastest

01:52:34.020 --> 01:52:36.630
and most scalable AI
WAN in the world.

01:52:36.630 --> 01:52:40.140
And this enables large,
large-scale distributed training

01:52:40.140 --> 01:52:42.600
across multiple Azure
regions, allowing you

01:52:42.600 --> 01:52:46.650
to use one giant AI
supercomputer for your jobs.

01:52:46.650 --> 01:52:48.870
Now, data is the
fuel that powers AI.

01:52:48.870 --> 01:52:51.270
And so along with all these
GPUs, you also need a lot

01:52:51.270 --> 01:52:54.510
of storage, a lot of databases,
and a lot of compute systems

01:52:54.510 --> 01:52:55.830
that can be used with it.

01:52:55.830 --> 01:53:00.390
And every one of our Azure AI
regions has exabytes of storage

01:53:00.390 --> 01:53:03.090
and literally millions of
CPU compute cores

01:53:03.090 --> 01:53:05.280
that are co-located together.

01:53:05.280 --> 01:53:06.090
And this highlighted part

01:53:06.090 --> 01:53:08.400
of the data center here
runs some of these systems.

01:53:08.400 --> 01:53:10.980
And if this building looks
long, it's because it is.

01:53:10.980 --> 01:53:13.870
It's actually five
football fields in length.

01:53:15.060 --> 01:53:17.550
And this picture here shows
you now what's inside part

01:53:17.550 --> 01:53:18.690
of this building.

01:53:18.690 --> 01:53:20.190
And Azure, again, as mentioned,

01:53:20.190 --> 01:53:23.430
provides high-performance,
exabyte-level storage.

01:53:23.430 --> 01:53:25.980
And this allows customers like
OpenAI to use the storage

01:53:25.980 --> 01:53:30.150
with training data and run those
GPUs at super-high velocity.

01:53:30.150 --> 01:53:33.750
In fact, we can now drive over 2
million read or write operations

01:53:33.750 --> 01:53:35.370
and transactions per second

01:53:35.370 --> 01:53:38.130
on a single blob storage
account within Azure.

01:53:38.130 --> 01:53:39.660
And you can also
now create millions

01:53:39.660 --> 01:53:41.010
of blob storage accounts.

01:53:41.010 --> 01:53:45.780
And collectively, this provides
unparalleled storage performance

01:53:45.780 --> 01:53:50.520
to any AI training or
inferencing workload.

01:53:50.520 --> 01:53:51.870
Now, when you have
a storage system

01:53:51.870 --> 01:53:54.180
that can support this level of
performance, though, and scale,

01:53:54.180 --> 01:53:56.190
the next question is, how
do you take advantage

01:53:56.190 --> 01:53:59.820
of this performance from
within your compute VMs?

01:53:59.820 --> 01:54:03.120
And that's where our Azure Boost
technology comes into play.

01:54:03.120 --> 01:54:05.460
Azure Boost is our
IO accelerator

01:54:05.460 --> 01:54:09.240
and management system integrated
into every new Azure server.

01:54:09.240 --> 01:54:11.880
It offloads server
virtualization processes

01:54:11.880 --> 01:54:14.160
typically done on the
CPU of the server

01:54:14.160 --> 01:54:18.660
onto custom-built silicon,
enabling faster storage

01:54:18.660 --> 01:54:20.310
and networking performance.

01:54:20.310 --> 01:54:23.760
And it's what's giving Azure now
industry-leading IO performance

01:54:23.760 --> 01:54:25.980
for mission-critical workloads.

01:54:25.980 --> 01:54:29.430
We can now drive over 400,000
network connections per second

01:54:29.430 --> 01:54:34.170
to each VM, 6.6 million
IOPS for local storage,

01:54:34.170 --> 01:54:37.080
and 800,000 IOPS
for remote storage.

01:54:37.080 --> 01:54:38.580
And Azure Boost
now comes standard

01:54:38.580 --> 01:54:40.230
in every new Azure server,

01:54:40.230 --> 01:54:45.120
regardless of whether it's being
used for AI or non-AI workloads.

01:54:45.120 --> 01:54:46.920
We're also doing more
silicon innovation

01:54:46.920 --> 01:54:48.780
with our Azure Cobalt Silicon,

01:54:48.780 --> 01:54:51.390
which is now the
industry-leading ARM64

01:54:51.390 --> 01:54:54.090
price-performance
CPU in the cloud.

01:54:54.090 --> 01:54:57.330
Cobalt-based VMs provide up
to two times the performance

01:54:57.330 --> 01:55:01.860
of other VMs with.NET apps,
and it's 20% less expensive

01:55:01.860 --> 01:55:05.250
than AMD or Intel-based VMs.

01:55:05.250 --> 01:55:09.300
And developers from Databricks,
Snowflake, Elastic, Adobe,

01:55:09.300 --> 01:55:11.220
and Microsoft Teams are
already taking advantage

01:55:11.220 --> 01:55:15.150
of Azure Cobalt in
production today.

01:55:15.150 --> 01:55:16.920
So we walked through a
handful of the innovations

01:55:16.920 --> 01:55:18.480
and optimizations
that we're doing

01:55:18.480 --> 01:55:20.910
across our Azure
AI infrastructure.

01:55:20.910 --> 01:55:23.190
All of these combined
are really engineered

01:55:23.190 --> 01:55:25.830
to be a whole system that's
unleashing incredible

01:55:25.830 --> 01:55:27.510
AI innovation.

01:55:27.510 --> 01:55:30.030
And to give you a sense of just
how impressive this one Azure AI

01:55:30.030 --> 01:55:33.000
data center will be once it
goes live in a few months,

01:55:33.000 --> 01:55:34.710
it'll actually be
10x the performance

01:55:34.710 --> 01:55:38.160
of today's fastest
supercomputer in the world.

01:55:38.160 --> 01:55:40.290
This sort of step
change is what's going

01:55:40.290 --> 01:55:43.470
to accelerate the next wave
of AI model development

01:55:43.470 --> 01:55:45.660
and the next wave
of AI innovation.

01:55:45.660 --> 01:55:48.390
And this is just one of many
data centers we're bringing live

01:55:48.390 --> 01:55:51.660
around the world right now.

01:55:51.660 --> 01:55:53.610
Now, AI infrastructure
like this also is going

01:55:53.610 --> 01:55:57.090
to enable exponential
reduction of AI cost.

01:55:57.090 --> 01:55:59.400
If you look at where we were
just even two years ago,

01:55:59.400 --> 01:56:04.020
the price of, say, GPT-4
has plummeted by 93%.

01:56:04.020 --> 01:56:07.410
And this innovation,
model improvement,

01:56:07.410 --> 01:56:10.680
and cost reduction is what's
going to power a new era

01:56:10.680 --> 01:56:12.990
of AI apps and AI agents.

01:56:12.990 --> 01:56:15.510
And it's going to enable
all of you in this room

01:56:15.510 --> 01:56:18.900
and watching online to integrate
AI into every workflow

01:56:18.900 --> 01:56:21.660
and build transformative
AI solutions

01:56:21.660 --> 01:56:24.750
that weren't possible before.

01:56:24.750 --> 01:56:26.670
Now, when I think about the
canonical app for this new era,

01:56:26.670 --> 01:56:27.780
there's one app that stands

01:56:27.780 --> 01:56:30.750
out in particular,
and that's ChatGPT.

01:56:30.750 --> 01:56:35.520
ChatGPT has over 500 million
weekly, active users,

01:56:35.520 --> 01:56:38.310
and it's the fastest
growing app in history.

01:56:38.310 --> 01:56:41.280
And ChatGPT is built
entirely on Azure,

01:56:41.280 --> 01:56:43.500
using the exact
same Azure services

01:56:43.500 --> 01:56:45.480
that you can use as well.

01:56:45.480 --> 01:56:49.500
Services like Azure
GPU VMs, Cosmos DB,

01:56:49.500 --> 01:56:54.210
Azure Kubernetes Service, Azure
Postgres, and Azure Storage.

01:56:54.210 --> 01:56:56.070
I've talked about all
the innovation happening

01:56:56.070 --> 01:56:57.540
within our Azure
AI infrastructure.

01:56:57.540 --> 01:56:59.700
Now, let's walk through some
of the work happening in some

01:56:59.700 --> 01:57:02.010
of these other services
that are also needed

01:57:02.010 --> 01:57:03.930
to build great AI solutions.

01:57:03.930 --> 01:57:07.890
Let's start by talking
about the data tier.

01:57:07.890 --> 01:57:10.650
ChatGPT needed a database
that would enable petabytes

01:57:10.650 --> 01:57:14.010
of data storage, trillions
of database transactions,

01:57:14.010 --> 01:57:16.320
and could support
tremendous growth.

01:57:16.320 --> 01:57:20.130
And to do that, ChatGPT
uses Azure Cosmos DB.

01:57:20.130 --> 01:57:23.670
Cosmos DB is a globally-distributed,
multi-model database

01:57:23.670 --> 01:57:26.760
service that delivers
turnkey scale-out

01:57:26.760 --> 01:57:30.180
with guaranteed millisecond
latency and uptime.

01:57:30.180 --> 01:57:32.640
And with Cosmos DB, we've
built a database service

01:57:32.640 --> 01:57:35.970
that can automatically replicate
data to any Azure region

01:57:35.970 --> 01:57:38.850
around the world to give users
lightning-fast performance,

01:57:38.850 --> 01:57:42.390
regardless of wherever they're
accessing an application.

01:57:42.390 --> 01:57:45.090
And ChatGPT has users
interacting with the app.

01:57:45.090 --> 01:57:47.070
Conversations, prompts,

01:57:47.070 --> 01:57:51.150
and metadata are all
stored using Cosmos DB.

01:57:51.150 --> 01:57:55.440
And this enables ChatGPT to
maintain context across sessions

01:57:55.440 --> 01:57:57.390
for 500 million users,

01:57:57.390 --> 01:58:00.900
delivering a natural user
experience with low latency

01:58:00.900 --> 01:58:04.230
and high reliability
at truly global scale.

01:58:04.230 --> 01:58:07.200
And with real-time replicas
of the database distributed

01:58:07.200 --> 01:58:09.540
across Azure regions
around the world,

01:58:09.540 --> 01:58:12.270
ChatGPT can put data
closer to its users,

01:58:12.270 --> 01:58:15.780
resulting in much
faster responses.

01:58:15.780 --> 01:58:18.780
Cosmos DB allows you to
elastically scale your storage

01:58:18.780 --> 01:58:22.680
and performance throughput with
zero application downtime.

01:58:22.680 --> 01:58:25.800
You can start with gigabytes
of data and then scale it

01:58:25.800 --> 01:58:28.020
up to manage petabytes of it.

01:58:28.020 --> 01:58:29.670
And you can start by
processing, just say,

01:58:29.670 --> 01:58:32.490
100 operations per second,
and then scale to millions

01:58:32.490 --> 01:58:35.130
of operations per second
around the world.

01:58:35.130 --> 01:58:38.100
And best of all, with Cosmos DB,
you only pay for the storage

01:58:38.100 --> 01:58:40.500
and performance
throughput that you use.

01:58:40.500 --> 01:58:43.770
And it's what's offering ChatGPT
the flexibility and scalability

01:58:43.770 --> 01:58:46.560
to handle its unprecedented
user growth and trillions

01:58:46.560 --> 01:58:49.320
of database transactions.

01:58:49.320 --> 01:58:52.590
Cosmos DB delivers incredibly
fast response times

01:58:52.590 --> 01:58:55.170
and five-nines of availability,

01:58:55.170 --> 01:58:58.080
meeting ChatGPT's demanding
performance and uptime needs.

01:58:58.080 --> 01:59:03.420
And it's been essential in terms
of ChatGPT's growth and success.

01:59:03.420 --> 01:59:07.230
So I've covered how ChatGPT
scales their data tier

01:59:07.230 --> 01:59:08.430
with Cosmos DB.

01:59:08.430 --> 01:59:10.050
Let's now talk about
the application layer

01:59:10.050 --> 01:59:12.420
and the compute
that's used in it.

01:59:12.420 --> 01:59:15.510
Now, ChatGPT needs to be able
to scale their application tier

01:59:15.510 --> 01:59:19.320
across more than 10 million
compute cores around the world.

01:59:19.320 --> 01:59:22.380
And what's amazing is they
only have a dozen engineers

01:59:22.380 --> 01:59:25.260
that actually manage
that whole process.

01:59:25.260 --> 01:59:27.450
And that's where another one
of our key services comes

01:59:27.450 --> 01:59:30.660
into play, which is our
Azure Kubernetes service.

01:59:30.660 --> 01:59:33.180
ChatGPT is built on top of AKS,

01:59:33.180 --> 01:59:35.940
which provides a highly
scalable Kubernetes service

01:59:35.940 --> 01:59:38.310
for cloud-native applications.

01:59:38.310 --> 01:59:41.340
AKS is a fully-managed
Kubernetes service available

01:59:41.340 --> 01:59:43.380
in every Azure region,

01:59:43.380 --> 01:59:47.370
and it streamlines
operations at any scale.

01:59:47.370 --> 01:59:51.570
AKS offers automated
deployments, auto-healing,

01:59:51.570 --> 01:59:55.260
automated patching, and
built-in security safeguards.

01:59:55.260 --> 01:59:57.780
And this is what enables
applications like ChatGPT

01:59:57.780 --> 02:00:01.860
to scale without significant
operational resources.

02:00:01.860 --> 02:00:04.740
And AKS truly gives you
cloud-native scale.

02:00:04.740 --> 02:00:06.180
You can now deploy
your solutions either

02:00:06.180 --> 02:00:07.980
on a single AKS cluster,

02:00:07.980 --> 02:00:10.320
or you can also now use
our new AKS fleet manager,

02:00:10.320 --> 02:00:13.050
which enables you to have
any number of AKS clusters

02:00:13.050 --> 02:00:15.630
around the world and
employ standard policies

02:00:15.630 --> 02:00:17.580
and standard operational models

02:00:17.580 --> 02:00:19.980
so that your operations team
doesn't have to scale linearly

02:00:19.980 --> 02:00:23.430
with the number of compute
nodes that you're running.

02:00:23.430 --> 02:00:25.410
It's another example
of the unique innovation

02:00:25.410 --> 02:00:28.350
that we're driving at Microsoft.

02:00:28.350 --> 02:00:31.350
And we're doing that innovation
both in our own services as well

02:00:31.350 --> 02:00:34.440
as by contributing to
open-source projects.

02:00:34.440 --> 02:00:37.590
And we're proud that last year
Azure became the largest cloud

02:00:37.590 --> 02:00:42.030
contributor to open-source CNCF
projects around the world.

02:00:42.030 --> 02:00:44.550
And this slide here shows some
of the examples of projects

02:00:44.550 --> 02:00:47.280
that we've made significant
contributions to.

02:00:47.280 --> 02:00:48.960
ChatGPT is taking
advantage of many

02:00:48.960 --> 02:00:53.010
of these services,
as can all of you.

02:00:53.010 --> 02:00:56.040
And collectively, all this
technology is powering a new

02:00:56.040 --> 02:00:59.400
generation of AI
apps and agents.

02:00:59.400 --> 02:01:03.300
Everything that you've seen at
Build, so far at this conference,

02:01:03.300 --> 02:01:05.850
yesterday and today,
is all running on top

02:01:05.850 --> 02:01:07.980
of this Azure infrastructure.

02:01:07.980 --> 02:01:10.020
And we're seeing great companies

02:01:10.020 --> 02:01:13.920
like these building
differentiated AI solutions.

02:01:13.920 --> 02:01:15.090
And we'd love to see your logo

02:01:15.090 --> 02:01:17.610
on the wall this time
next year as well.

02:01:17.610 --> 02:01:21.180
So I hope you have a wonderful
rest of Build and look forward

02:01:21.180 --> 02:01:22.500
to seeing what you build.

02:01:22.500 --> 02:01:23.251
Thank you.

02:01:23.276 --> 02:01:26.830
[ Applause ]